[{"body":"","categories":"","description":"Execute the following exerciss in order.","excerpt":"Execute the following exerciss in order.","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_single_host/","tags":"","title":"APM for a Single Host"},{"body":"Identify your token and realm from the Splunk Observability Cloud Portal:\nOrganization Settings-\u003eAccess Tokens and Your Name-\u003eAccount Settings\n If using your own k8s cluster on an Ubuntu host\nRemove the Otel Collector if its running on the same host as your k8s cluster:\nsudo sh /tmp/splunk-otel-collector.sh --uninstall Use this setup script to bootstrap your Debian based k8s environment with everything needed for the k8s workshop:\n bash \u003c(curl -s https://raw.githubusercontent.com/signalfx/otelworkshop/master/setup-tools/k8s-env-only.sh)  Ensure you have helm and lynx installed.\nSkip to: 2: Deploy APM for containerized apps: Python and Java\nIf you are using k8s anywhere else you can still do this workshop but will need to ensure helm, lynx are available.\n  1: Use Data Setup Wizard for Splunk Otel Collector Pod on k3s  IMPORTANT: If you have the Otel Collector and prior lab examples running on a host, them at this time:\nStop all the prior labs apps by using ctrl-c in each terminal window and then closing the window.\nRemove the host based otel collector: sudo sh /tmp/splunk-otel-collector.sh --uninstall\n 1a: Splunk Observability Cloud Portal In Splunk Observability Cloud: Data Setup-\u003eKubernetes-\u003eAdd Connection\nChoose the following:\n   Key Value     Access Token Select from list   Cluster Name Your initials-cluster i.e. SL-cluster   Provider Other   Distribution Other   Add Gateway No   Log Collection True    And then select Next\nFollow the steps on the Install Integration page.\nA result will look like this:\nNAME: splunk-otel-collector-1620505665 LAST DEPLOYED: Sat May 8 20:27:46 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Note the name of the deployment when the install completes i.e.: splunk-otel-collector-1620505665\n1b: Update k3s For Splunk Log Observer (Ignore if you are using k8s) k3s has a different format that standard k8s for logging and we need to update our deployment for this.\nYou’ll need the Collector deployment from the Data Setup Wizard install.\nYou can also dervice this from using helm list i.e.:\nNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION splunk-otel-collector-1620504591 default 1 2021-05-08 20:09:51.625419479 +0000 UTC deployed splunk-otel-collector-0.25.0 The deployment name would be: splunk-otel-collector-1620504591\nPrepare values for Collector update If you run into any errors from helm, fix with:\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml sudo chmod 755 /etc/rancher/k3s/k3s.yaml Prep values for collector update:\nhelm list\nhelm get values NAME\ni.e. helm get values splunk-otel-collector-1620609739\nmake note of:\nclusterNAME\nsplunkAccessToken\nsplunkRealm\nPrepare values.yaml file for updating the Helm chart Start in k8s directory:\ncd ~/otelworkshop/k8s Edit k3slogs.yaml with thes values above.\nUpdate the Collector Install the Collector configuration chart:\nhelm upgrade \\ YOURCOLLECTORHERE \\ --values k3slogs.yaml \\ splunk-otel-collector-chart/splunk-otel-collector i.e.\nhelm upgrade \\ splunk-otel-collector-1620609739 \\ --values k3slogs.yaml \\ splunk-otel-collector-chart/splunk-otel-collector  2: Deploy APM For Containerized Apps: Python and Java !!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the py-deployment.yaml below and add your initials to the environment i.e. change all instances:\ndeployment.environment=apm-workshop\nto deployment.environment=sjl-apm-workshop\nDeploy the Flask server deployment/service and the python-requests (makes requests of Flask server) pod:\ncd ~/otelworkshop/k8s kubectl apply -f py-deployment.yaml !!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the java-deployment.yaml below and add your initials to the environment i.e. change all instances:\ndeployment.environment=apm-workshop\nto deployment.environment=sjl-apm-workshop\nDeploy the Java OKHTTP requests pod (makes requests of Flask server):\nkubectl apply -f java-deployment.yaml Study the results:\nThe APM Dashboard will show the instrumented Python-Requests and Java OKHTTP clients posting to the Flask Server.\nMake sure you select the apm-workshop ENVIRONMENT to monitor.\nStudy the deployment.yaml files:\nExample in Github or:\n~/otelworkshop/k8s/py-deployment.yaml ~/otelworkshop/k8s/java-deployment.yaml The .yaml files show the environment variables telling the instrumentation to send spans to the OpenTelemetry Collector.\nNormally we use an environment variable pointing to localhost on a single host application where the Collector is running. In k8s we have separate pods in a cluster for apps and the Collector.\nThe Collector pod is running with node wide visibility, so to tell each application pod where to send spans:\n- name: SPLUNK_OTEL_AGENT valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(SPLUNK_OTEL_AGENT):4317\"  3: Monitor JVM Metrics For a Java Container JVM Metrics are emitted by the Splunk OpenTelemetry Java instrumentation and send to the Collector.\nDownload this file to your local machine: JVM Metrics Dashboard Template\nSelect the + Icon on top right and create a new Dashboard Group called test\nClick the + Icon again and select Import-\u003eDahsboard\nand select the downloaded dashboard_JVMMetrics.json file.\nFilter by Application by adding service:SERVICENAMEHERE\nComplete JVM metrics available at this link\n 4: Manually instrument a Java App And Add Custom Attributres (Tags) Let’s say you have an app that has your own functions and doesn’t only use auto-instrumented frameworks- or doesn’t have any of them!\nYou can easily manually instrument your functions and have them appear as part of a service, or as an entire service.\nExample is here:\ncd ~/otelworkshop/k8s/java/manual-inst\nDeploy an app with ONLY manual instrumentation:\n!!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the java-reqs-manual-inst.yaml below and add your initials to the environment i.e. change all instances:\ndeployment.environment=apm-workshop\nto deployment.environment=sjl-apm-workshop\nkubectl apply -f java-reqs-manual-inst.yaml When this app deploys, it appears as an isolated bubble in the map. It has all metrics and tracing just like an auto-instrumented app does.\nTake a look at the traces and their spans to see the manually added values of Message, Logs etc.\nYou will see the function called ExampleSpan with custom Logging messages and a message:myevent span/tag.\nSee the custom attribute my.key and value myvalue.\nThis could be a transaction ID, user ID, or any custom value that you want to correlate and even metricize.\nStudy the manual instrumentation code example here.\nThere are two methods shown- the decorator @WithSpan method (easiest), and using the GlobalTracer method (more complicated/powerful)…\nNote that this is the most minimal example of manual instrumentation- there is a vast amount of power available in OpenTelemetry- please see the documentation and in depth details\n 5: Process Spans with the Otel Collector The Otel Collector has many powerful configuration options ranging from splitting telemetry to multiple destinations to sampling to span processing.\nProcessor documentation\nCollector config examples\nFull documentation\nPrepare values for Collector update helm list helm get values NAME i.e. helm get values splunk-otel-collector-1620609739\nmake note of:\nclusterNAME\nsplunkAccessToken\nsplunkRealm\nSpan Processing Example: Redacting Data from a Span Attribute Change to the example directory:\ncd ~/otelworkshop/k8s/collectorconfig Prepare values.yaml file for updating the Helm chart Edit spanprocessor.yaml with thes values from Step 1.\nUpdate the Collector Install the Collector configuration chart:\nhelm upgrade --install \\ YOURCOLLECTORHERE \\ --values spanprocessor.yaml \\ splunk-otel-collector-chart/splunk-otel-collector i.e.\nhelm upgrade --install \\ splunk-otel-collector-1620609739 \\ --values spanprocessor.yaml \\ splunk-otel-collector-chart/splunk-otel-collector Study the results:\nSplunk Observability Portal -\u003e APM -\u003e Explore -\u003e java-otel-manual-inst -\u003e Traces\nExample my.key and you’ll see that the value is redacted after applying the spanprocessor.yaml example\nIf you want to make changes and update the spanprocessor.yaml or add more configurations, use:\nhelm upgrade --reuse-values\n 6: Receive Prometheus Metrics at the Otel Collector Add a Prometheus endpoint pod Change to the k8s Collector Config directory:\ncd ~/otelworkshop/k8s/collectorconfig Add the Prometheus pod (source code is in the k8s/python directory):\nkubectl apply -f prometheus-deployment.yaml Update Otel Collector to Scrape the Prometheus Pod Update realm/token/cluster in the otel-prometheus.yaml\nVerify your helm deployment of the collector:\nhelm list Upgrade the Collector deployment with the values required for scraping Prometheus metrics from the Prometheus pod deployed in the previous step:\nhelm upgrade --reuse-values splunk-otel-collector-YOURCOLLECTORVALUE --values otel-prometheus.yaml splunk-otel-collector-chart/splunk-otel-collector Find Prometheus Metric and Generate Chart Splunk Observabilty -\u003e Menu -\u003e Metrics -\u003e Metric Finder\nSearch for: customgauge\nClick CustomGauge\nChart appears with value 17\nExamine the collector update otel-prometheus.yaml to see how this works.\n 7: Configure Otel Collector to Transform a Metric Name This example uses the Metrics Transform Processor\nChange to the k8s Collector Config directory:\ncd ~/otelworkshop/k8s/collectorconfig Update realm/token/cluster in the metricstransform.yaml with your token/realm/cluster\nUpgrade the Collector deployment with the values required for scraping Prometheus metrics from the Prometheus pod deployed in the previous step:\nhelm upgrade --reuse-values splunk-otel-collector-YOURCOLLECTORVALUE --values metricstransform.yaml splunk-otel-collector-chart/splunk-otel-collector Find Transformed Prometheus Metric and Generate Chart Splunk Observabilty -\u003e Menu -\u003e Metrics -\u003e Metric Finder\nSearch for: transformedgauge\nClick TransformedGauge\nYou’ll now see the new chart for the metric formerly known as CustomGauge that has been transformed using the metrics transform processor.\nExamine the collector update metricstransform.yaml to see how this works.\n Monitoring and Troubleshooting View Otel Collector POD stats kubectl get pods Note the pod name of the OpenTelemetry Collector pod i.e.:\nsplunk-otel-collector-1620505665-agent-sw45w\nSend the Zpages stats to the lynx browser:\nkubectl exec -it YOURAGENTPODHERE -- curl localhost:55679/debug/tracez | lynx -stdin i.e.\nkubectl exec -it splunk-otel-collector-1620505665-agent-sw45w -- curl localhost:55679/debug/tracez | lynx -stdin Examine Otel Collector Config get your Collector agent pod name via:\nkubectl get pods i.e.\nsplunk-otel-collector-1626453714-agent-vfr7s\nShow current Collector config:\nkubectl exec -it YOURAGENTPODHERE -- curl localhost:55554/debug/configz/effective Show initial Collector config:\nkubectl exec -it YOURAGENTPODHERE -- curl localhost:55554/debug/configz/initial  Bonus Instrumentation Examples: Istio and .NET .NET: containerized example is located here Istio: service mesh lab here  Clean up deployments and services To delete all k8s lab work:\nin ~/otelworkshop/k8s/\nsource delete-all-k8s.sh source delete-prometheus.sh To delete the Collector from k8s:\nhelm list helm delete YOURCOLLECTORHERE i.e.\nhelm delete splunk-otel-collector-1620505665 k3s:\n/usr/local/bin/k3s-uninstall.sh ","categories":"","description":"","excerpt":"Identify your token and realm from the Splunk Observability Cloud …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/k8s/","tags":"","title":"APM for K8s"},{"body":"1. Namespaces in Kubernetes Namespaces are a way to organize kubernetes clusters into virtual sub-clusters. They can be helpful when different teams or projects share a Kubernetes cluster which usually is the case with larger customers/prospects.\nAny number of namespaces are supported within a cluster, each logically separated from others but with the ability to communicate with each other. Components are only “visible” when selecting a NameSpace or when adding the –all-namespaces flag instead allowing you to view just the components relevant to your project by selecting your NameSpace.\nMost customers will want to install the Splunk OpenTelemetry Collector in a separate NameSpace. This workshop will follow that practice.\n2. Obtain Access Token You will need to obtain your Access Token from the Splunk UI. You can find the workshop Access Token by clicking » bottom left and then selecting Settings → Access Tokens.\nExpand the workshop token that your host has instructed you to use e.g. O11y-Workshop-ACCESS, then click on Show Token to expose your token. Click the Copy    button to copy to clipboard. Please do not use the Default token!\nYou will also need to obtain the name of the Realm for your Splunk account. At the top of the side menu, click on your name. This will direct you to the Account Settings Page. Click the Organizations-tab. The Realm can be found at the top of the displayed information in the tab.\n3. Installation using Helm using ‘splunk’ as a Namespace Create the ACCESS_TOKEN and REALM environment variables to use in the proceeding Helm install command.\nExport Variables   export ACCESS_TOKEN=\u003creplace_with_Workshop_ACCESS_TOKEN\u003e export REALM=\u003creplace_with_REALM\u003e  Install the OpenTelemetry Collector using the Splunk Helm chart. First, add the Splunk Helm chart repository and update.\nHelm Repo Add  Helm Repo Add Output   helm repo add splunk-otel-collector-chart https://splunk.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 \"splunk-otel-collector-chart\" has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"splunk-otel-collector-chart\" chart repository Update Complete. ⎈Happy Helming!⎈  Install the OpenTelemetry Collector Helm chart into the splunk namespace with the following commands, do NOT edit this:\nHelm Install  Helm Install Single Line   helm install splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$(hostname)-k3s-cluster\" \\ --set=\"splunkObservability.logsEnabled=true\" \\ --set=\"clusterReceiver.eventsEnabled=true\" \\ --set=\"splunkObservability.infrastructureMonitoringEventsEnabled=true\" \\ splunk-otel-collector-chart/splunk-otel-collector \\ --namespace splunk \\ --create-namespace \\ -f ~/splunk-defaults.yaml helm install splunk-otel-collector --set=\"splunkObservability.realm=$REALM\" --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" --set=\"clusterName=$(hostname)-k3s-cluster\" --set=\"splunkObservability.logsEnabled=true\" --set=\"clusterReceiver.eventsEnabled=true\" --set=\"splunkObservability.infrastructureMonitoringEventsEnabled=true\" splunk-otel-collector-chart/splunk-otel-collector --namespace splunk --create-namespace  3. Verify Deployment You can monitor the progress of the deployment by running kubectl get pods and adding -n splunk to the command to see the pods in the splunk NameSpace which should typically report that the new pods are up and running after about 30 seconds.\nEnsure the status is reported as Running before continuing.\nKubectl Get Pods  Kubectl Get Pods Output   kubectl get pods -n splunk NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-2sk6k 0/1 Running 0 10s splunk-otel-collector-k8s-cluster-receiver-6956d4446f-gwnd7 0/1 Running 0 10s   Note If you are using the Kubernetes Integration setup from the Data Management page from the O11y UI , you find that the guide will use --generate-name splunk-otel-collector-chart/splunk-otel-collector instead of just splunk-otel-collector-chart/splunk-otel-collector as we do in the above example.\nThis will generate an unique name/label for the collector install and Pods by adding a unique number at the end of the object name, allowing you to install multiple collectors in your Kubernetes environment with different configurations.\nJust make sure you use the correct label that is generated by the helm chart if you wish to use the helm and kubectl commands from this workshop on an install done with the --generate-name option.\n Use the label set by the helm install to tail logs (You will need to press ctrl + c to exit). Or use the installed k9s terminal UI.\nKubectl Logs   kubectl logs -l app=splunk-otel-collector -f --container otel-collector -n splunk  Deleting a failed installation\nIf you make an error installing the Splunk OpenTelemetry Collector you can start over by deleting the installation using:\nhelm delete splunk-otel-collector -n splunk    Workshop Question\nFind your Cluster in the Observability Kubernetes Navigator, and identify the nasmespace for the collector and its workload.\nTip: you may need to refresh the screen a few time to allow the cluster data to correlated in the back ground data.\n  ","categories":"","description":"","excerpt":"1. Namespaces in Kubernetes Namespaces are a way to organize …","ref":"/observability-workshop/v4.41/tko/session-5/docs/deploy-otel/","tags":"","title":"Deploying the OpenTelemetry Collector in Kubernetes using a NameSpace"},{"body":"A collection of the common questions and their answers associated with Observability, DevOps, Incident Response and Splunk On-Call.\nQ: Alerts v. Incident Response v. Incident Management A: Alerts, Incident Response and Incident Management are related functions. Together they comprise the incident response and resolution process.\nMonitoring and Observability tools send alerts to incident response platforms. Those platforms take a collection of alerts and correlate them into incidents.\nThose incidents are recorded into incident management (ITSM) platforms for record. Alerts are the trigger that something has happened, and provide context to an incident.\nIncidents consist of the alert payload, all activity associated with the incident from the time it was created, and the on-call policies to be followed. ITSM is the system of record for incidents that are active and after they have been resolved.\nAll these components are necessary for successful incident response and management practices.\nOn-Call    Q: Is Observability Monitoring A: The key difference between Monitoring and Observability is the difference between “known knowns” and “unknown knowns” respectively.\nIn monitoring the operator generally has prior knowledge of the architecture and elements in their system. They can reliably predict the relationship between elements, and their associated metadata. Monitoring is good for stateful infrastructure that is not frequently changed.\nObservability is for systems where the operators ability to predict and trace all elements in the system and their relationships is limited.\nObservability is a set of practices and technology, which include traditional monitoring metrics.\nThese practices and technologies combined give the operator the ability to understand ephemeral and highly complex environments without prior knowledge of all elements of a system. Observability technology can also account for fluctuations in the environment, and variation in metadata (cardinality) better than traditional monitoring which is more static.\nObservability    Q: What are Traces and Spans A: Traces and spans, combined with metrics and logs, make up the core types of data that feed modern Observability tools. They all have specific elements and functions, but work well together.\nBecause microservices based architectures are distributed, transactions in the system touch multiple services before completing. This makes accurately pinpointing the location of an issue difficult. Traces are a method for tracking the full path of a request through all the services in a distributed system. Spans are the timed operations in each service. Traces are the connective tissue for the spans and together they give more detail on individual service processes. While metrics give a good snapshot of the health of a system, and logs give depth when investigating issues, traces and spans help navigate operators to the source of issues with greater context. This saves time when investigating incidents, and supports the increasing complexity of modern architectures.\nAPM    Q: What is the Sidecar Pattern? A: The sidecar pattern is a design pattern for having related services contected directly by infrastructure. Related services can be adding functionality or supporting the application logic they are connected to. It is used heavily as a method for deploying agents associated with the management plan along with the application service they support.\nIn Observability the sidecar services are the application logic, and the agent collecting data from that service. The setup requires two containers one with the application service, and one running the agent. The containers share a pod, and resources such as disk, network, and namespace. They are also deployed together and share the same lifecycle.\nObservability    ","categories":"","description":"","excerpt":"A collection of the common questions and their answers associated with …","ref":"/observability-workshop/v4.41/resources/faq/","tags":"","title":"Frequently Asked Questions"},{"body":"The goal is to walk through the basic steps to configure the following components of the Splunk Observability platform:\n Splunk Infrastructure Monitoring (IM) Splunk Zero Configuration Auto Instrumentation for Java (APM)  Database Query Performance AlwaysOn Profiling   Splunk Real User Monitoring (RUM) Splunk LogsObserver (LO)  We will also show the steps about how to clone (download) a sample Java application (Spring PetClinic), as well as how to compile, package and run the application.\nOnce the application is up and running, we will instantly start seeing metrics and traces via the Zero Configuration Auto Instrumentation for Java that will be used by the Splunk APM product.\nAfter that, we will instrument the PetClinic’s end user interface (HTML pages rendered by the application) with the Splunk OpenTelemetry Javascript Libraries (RUM) that will generate RUM traces around all the individual clicks and page loads executed by an end user.\nLastly, we will configure the Spring PetClinic application to write application logs to the filesystem and also configure the Splunk OpenTelemetry Collector to read (tail) the logs and report to Splunk Observability Cloud.\nPrerequisites\nA Splunk run workshop where an host/instance is provided OR a self led workshop on own host / multipass instance For your own system you will need the following installed and enabled:\n Java installed Port 8080 open inbound/outbound    ","categories":"","description":"","excerpt":"The goal is to walk through the basic steps to configure the following …","ref":"/observability-workshop/v4.41/pet-clinic/docs/intro/","tags":"","title":"Getting Started"},{"body":"Ubuntu Virtual Machine Multipass deploys and runs Ubuntu virtual machines easily on Mac and Windows.\nMake sure multipass is the CURRENT version:\nbrew upgrade multipass Workshop examples have been tested on this configuration:\nmultipass launch -n primary -d 16G -m 6G Make sure to always run sudo apt-get -y update before executing any step in the workshop.\nK8s Cluster Setup Hints K3s is a lightweight Kubernetes deployment from Rancher: https://k3s.io/\nTo K3s install on Linux:\ncurl -sfL https://get.k3s.io | sh - Make a .kube directory in your home directory and create the config file e.g.:\nmkdir /home/ubuntu/.kube \u0026\u0026 kubectl config view --raw \u003e /home/ubuntu/.kube/config Set the correct permissions and owndership on the newly created config file e.g.:\nchmod 400 /home/ubuntu/.kube/config chown -R ubuntu:ubuntu /home/ubuntu The stock configuration of K3s and this workshop’s K8s examples have been tested on the following configurations:\n K3s cluster (default settings) on Ubuntu VM:  Macbook Pro 32GB RAM, Windows 10 Laptop 12GB RAM: Multipass started with multipass launch -n primary -d 8G -m 4G AWS EC2    The Kubernetes lab has also been tested on:\n Azure: Kubernetes 1.17.9 Azure Kubernetes Service EKS / GKE: Not tested yet but 99.9% chance will have no issues Workshop will NOT work on: Macbook Pro Docker Desktop Kubernetes  To tear down a Multipass VM:\nmultipass delete primary --purge Using tmux tmux is recommended to split your terminal into several panes so that you can run an application in each pane without having to containerize applications- and you can keep a separate pane open for checking status of spans, the host, etc.\nImportant: each pane runs as its own bash shell so environment variables must be set in each pane. The workshop includes setup shell scripts to make it easy to do this.\nTo install tmux:\nsudo apt-get install tmux Tmux works by using ++ctrl+b++ as a command key followed by: \" make a new horizontal pane % make a new vertical pane Arrow keys: move between panes.\n","categories":"","description":"","excerpt":"Ubuntu Virtual Machine Multipass deploys and runs Ubuntu virtual …","ref":"/observability-workshop/v4.41/otelw/appendix/appendix/","tags":"","title":"Helpful Tips"},{"body":"Splunk Observability -\u003e Data Setup -\u003e Linux\nChoose the following:\n   Key Value     Access Token Select from list   Mode Agent   Log Collection No    Follow Data Setup Wizard for instructions on Linux installation:\nCheck status of collector:\nsudo systemctl status splunk-otel-collector Should output something like:\n● splunk-otel-collector.service - Splunk OpenTelemetry Collector Loaded: loaded (/lib/systemd/system/splunk-otel-collector.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/splunk-otel-collector.service.d └─service-owner.conf Active: active (running) since Sun 2021-10-31 13:07:27 UTC; 1min 11s ago Main PID: 37949 (otelcol) Tasks: 9 (limit: 19200) Memory: 100.2M CGroup: /system.slice/splunk-otel-collector.service └─37949 /usr/bin/otelcol Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.556Z info builder/receivers_builder.go:73 \u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.556Z info builder/receivers_builder.go:68 \u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.556Z info builder/receivers_builder.go:73 \u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.556Z info healthcheck/handler.go:129 \u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.556Z info service/telemetry.go:92 Se\u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.557Z info service/telemetry.go:116 S\u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.557Z info service/collector.go:230 S\u003e Oct 31 13:07:27 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:27.557Z info service/collector.go:132 E\u003e Oct 31 13:07:37 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:37.826Z info hostmetadata/metadata.go:75 \u003e Oct 31 13:07:37 ip-172-31-70-180 otelcol[37949]: 2021-10-31T13:07:37.826Z info hostmetadata/metadata.go:83 \u003e Your machine will be visible in Splunk Observability in Infrastructure either in the public cloud platform you are using or My Data Center if you are using Multipass or any other non public cloud machine.\n","categories":"","description":"","excerpt":"Splunk Observability -\u003e Data Setup -\u003e Linux\nChoose the following: …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_single_host/host/","tags":"","title":"Install Otel Collector On Host"},{"body":" Introduction to the Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Saving charts in a dashboard Introduction to SignalFlow   1. Dashboards Dashboards are groupings of charts and visualizations of metrics. Well-designed dashboards can provide useful and actionable insight into your system at a glance. Dashboards can be complex or contain just a few charts that drill down only into the data you want to see.\nDuring this module we are going to create the following charts and dashboard and connect it to your Team page.\n 2. Your Teams' Page Click on the from the navbar. As you have already been assigned to a team, you will land on the team dashboard.\nWe use the Example Team as an example here. The one in your workshop will be different!\nThis page shows the total number of team members, how many active alerts for your team and all dashboards that are assigned to your team. Right now they are no dashboards assigned but as stated before, we will add the new dashboard that you will create to your Teams page later.\n 3. Sample Charts To continue, click on All Dashboards on the top right corner of the screen. This brings you to the view that shows all the available dashboards, including the pre-built ones.\nIf you are already receiving metrics from a Cloud API integration or another service through the Splunk Agent you will see relevant dashboards for these services.\n 4. Inspecting the Sample Data Among the dashboards you will see a Dashboard group called Sample Data. Expand the Sample Data dashboard group by clicking on it, and then click on the Sample Charts dashboard.\nIn the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.\nHave a look through all the dashboards in this dashboard group (PART 1, PART 2, PART 3 and INTRO TO SPLUNK OBSERVABILITY CLOUD)\n","categories":"","description":"","excerpt":" Introduction to the Dashboards and charts Editing and creating charts …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/intro/","tags":"","title":"Working with Dashboards, Charts and Metrics"},{"body":"Introduction During this technical workshop you will learn how to:\n efficiently deploy complex environments capture metrics from these environments to Splunk Observability auto-instrument a python application auto-instrument a java application enable AlwaysOn profiling for a java application  In order to simplify the workshop modules, a pre-configured AWS EC2 instance is provided.\nBy the end of this technical workshop you will have an approach to demonstrating metrics collection for complex environments and services and be able to describe, at a high-level, what is required to instrument an application for distributed tracing.\n","categories":"","description":"","excerpt":"Introduction During this technical workshop you will learn how to: …","ref":"/observability-workshop/v4.41/tko/session-2/docs/intro/","tags":"","title":"GDI - Real Time Enrichment Workshop"},{"body":"CAVEAT: THIS LAB IS DESIGNED FOR THE UBUNTU SANDBOX CREATED AT THE START OF THE APM WORKSHOP AND IS TESTED IN THAT ENVIRONMENT ONLY THIS LAB IS A WORK IN PROCESS AND YOUR RESULTS MAY VARY\nThis exercise will install an Istio service mesh on a Kubernetes cluster that directs external requests to a Python Flask server. Both the service mesh and the Flask server will emit spans. The result will show tracing of the external request to the node and through the mesh to the Flask server.\n1: Install OpenTelemetry Collector If you have an existing collector running remove it.\nFollow Data Setup wizard but add:\n--set autodetect.istio=true` i.e.\nhelm install \\ --set splunkAccessToken='YOURTOKENHERE' \\ --set clusterName='YOURCLUSTERNAMEHERE' \\ --set splunkRealm='YOURREALMHERE' \\ --set autodetect.istio=true \\ --set provider=' ' \\ --set distro=' ' \\ --set otelCollector.enabled='false' \\ --generate-name \\ splunk-otel-collector-chart/splunk-otel-collector 2: Set Up Istio Download Istio:\ncd ~ curl -L https://istio.io/downloadIstio | sh - Follow instructions from the installer script that are now in your terminal to add Istio’s bin path to your env then:\nistioctl install 3: Deploy Istio configurations and example Flask microservice Enable automatic Istio proxy injection. More info here\nkubectl label namespace default istio-injection=enabled Change to the APM Workshop Istio directory:\ncd ~/otelworkshop/k8s/istio Install the Splunk tracing profile for Istio:\nistioctl install -f tracing.yaml Set and validate ingress ports for Nodeport example and configure ingress host for local k3s workshop example:\nsource setup-envs.sh You should see a result that looks like:\nTCP_INGRESS_PORT= INGRESS_PORT=30785 INGRESS_HOST=172.31.19.248 SECURE_INGRESS_PORT=32071 Deploy Flask service configured for Istio:\n!!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the flask-deployment-istio.yaml below and add your initials to the environment i.e. change all instances:\ndeployment.environment=apm-workshop\nto deployment.environment=sjl-apm-workshop\nkubectl apply -f flask-deployment-istio.yaml Single test Flask service:\nsource test-flask.sh\nResults should show a direct request to the Flask server:\nYou getted: b'' Request headers: Host: localhost:30001 User-Agent: curl/7.68.0 Accept: */* Server: 1 Single test Istio:\nsource test-istio.sh When hitting the service mesh from outside the cluster, you’ll receive the mesh diagnostic data plus the B3 Trace/Span ID:\nYou getted: b'' Request headers: Host: 172.31.19.248:31177 User-Agent: curl/7.68.0 Accept: */* Server: 1 X-Forwarded-For: 10.42.0.1 X-Forwarded-Proto: http X-Envoy-Internal: true X-Request-Id: 447af547-7b8f-96db-a0b5-08efce526a8d X-Envoy-Decorator-Operation: server-flask-otel-k8s.default.svc.cluster.local:5000/echo X-Envoy-Peer-Metadata: ChQKDkFQUF9DT05UQUlORVJTEgIaAAoaCgpDTFVTVEVSX0lEEgwaCkt... 3NnYXRld2F5 X-Envoy-Peer-Metadata-Id: router~10.42.0.11~istio-ingressgateway-7d97f78f5-dg5zc.istio-system~istio-system.svc.cluster.local X-Envoy-Attempt-Count: 1 X-B3-Traceid: 5035304e854aa834e990df295b1d98e9 X-B3-Spanid: e990df295b1d98e9 X-B3-Sampled: 1 To generate many requests so that the example appears in the APM service map, use the load generator:\nLoad gen Istio for two minutes:\nsource loadgen.sh You will see a service map with the Istio mesh and the Flask server:\nTraces will show the request hitting the service mesh and the mesh hitting the service itself:\nIstio2\nStop loadgen:\n++ctrl+c++\nCleanup:\nremove k8s examples:\nsource delete-all.sh Remove Istio:\nFrom the Istio bin directory:\nistioctl x uninstall --purge ","categories":"","description":"","excerpt":"CAVEAT: THIS LAB IS DESIGNED FOR THE UBUNTU SANDBOX CREATED AT THE …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/examples/istio/","tags":"","title":"Istio Setup"},{"body":"","categories":"","description":"**10 minutes**\n\nDeploy the instrumented Online Boutique microservice application into Kubernetes\n","excerpt":"**10 minutes**\n\nDeploy the instrumented Online Boutique microservice …","ref":"/observability-workshop/v4.41/apm/docs/online-boutique/","tags":"","title":"Online Boutique K8s Workshop"},{"body":"","categories":"","description":"**10 分**\n\n計装済みのOnline Boutiqueマイクロサービス・アプリケーションをKubernetesにデプロイします。\n","excerpt":"**10 分**\n\n計装済みのOnline Boutiqueマイクロサービス・アプリケーションをKubernetesにデプロイします。\n","ref":"/observability-workshop/v4.41/ja/apm/docs/online-boutique/","tags":"","title":"Online Boutique K8s Workshop"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/","tags":"","title":"OpenTelemetry"},{"body":" Splunk Helm chartを使用して、K3s に OpenTelemetry Collector をインストールします Kubernetes Navigatorでクラスタを探索します   1. Access Tokenの取得 Kubernetes が起動したら、Splunk の UI から Access Token1 を取得する必要があります。Access Token は、左下にある » を開き、 Settings → Access Tokens を選択すると表示されます。\n主催者が指示したワークショップトークン（例： O11y-Workshop-ACCESS 等）を開き、 Show Token をクリックしてトークンを公開します。 Copy    ボタンをクリックし、クリップボードにコピーしてください。 Default のトークンは使用しないでください。\n独自のトークンを新たに作成しないようにしてください\nこのワークショップのために設定のトークンを作成し、IngestとAPIの両方の権限を割り当てています。実運用でのベストプラクティスは、1つのTokenにはIngestまたはAPIまたはRUMのような単一のパーミッションを割り当て、必要な場合は複数のトークンを使用することです。   また、Splunk アカウントの Realm2 の名前を取得する必要があります。サイドメニューの最上部の名前をクリックし、Account Settings ページに移動します。Organizations タブをクリックします。Realm はページの中央に表示されています。 この例では「us0」となっています。\n2. Helmによるインストール 環境変数 ACCESS_TOKEN と REALM を作成して、進行中の Helm のインストールコマンドで使用します。例えば、Realm が us1 の場合は、export REALM=us1 と入力し、eu0 の場合は、export REALM=eu0 と入力します。\nExport Variables  Export Access Token  Export Realm   export ACCESS_TOKEN=\u003creplace_with_O11y-Workshop-ACCESS_token\u003e export REALM=\u003creplace_with_splunk_realm\u003e export ACCESS_TOKEN= export REALM=  Splunk Helm チャートを使って OpenTelemetry Collector をインストールします。まず、Splunk Helm chart のリポジトリを Helm に追加してアップデートします。\nHelm Repo Add  Helm Repo Add Output   helm repo add splunk-otel-collector-chart https://splunk.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 \"splunk-otel-collector-chart\" has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"splunk-otel-collector-chart\" chart repository Update Complete. ⎈Happy Helming!⎈  以下のコマンドでOpenTelemetry Collector Helmチャートをインストールします。これは 変更しないでください。\nHelm Install  Helm Install Single Line  Helm Install Output   helm install splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$(hostname)-k3s-cluster\" \\ --set=\"splunkObservability.logsEnabled=true\" \\ --set=\"splunkObservability.profilingEnabled=true\" \\ --set=\"environment=$(hostname)-apm-env\" \\ splunk-otel-collector-chart/splunk-otel-collector \\ -f ~/workshop/k3s/otel-collector.yaml helm install splunk-otel-collector --set=\"splunkObservability.realm=$REALM\" --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" --set=\"clusterName=$(hostname)-k3s-cluster\" --set=\"splunkObservability.logsEnabled=true\" --set=\"splunkObservability.profilingEnabled=true\" --set=\"environment=$(hostname)-apm-env\" splunk-otel-collector-chart/splunk-otel-collector -f ~/workshop/k3s/otel-collector.yaml Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 NAME: splunk-otel-collector LAST DEPLOYED: Fri May 7 11:19:01 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None  約30秒程度待ってから kubectl get pods を実行すると、新しいポッドが稼働していることが報告され、デプロイメントの進捗を監視することができます。\n続行する前に、ステータスがRunningと報告されていることを確認してください。\nKubectl Get Pods  Kubectl Get Pods Output   kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-2sk6k 0/1 Running 0 10s splunk-otel-collector-k8s-cluster-receiver-6956d4446f-gwnd7 0/1 Running 0 10s  OpenTelemetry Collector podのログを確認して、エラーがないことを確認します。出力は、以下の出力例にあるログに似ているはずです。\nログを確認するには、helm のインストールで設定したラベルを使用してください（終了するには ctrl+c を押します）。もしくは、インストールされている k9s ターミナル UI を使うとボーナスポイントがもらえます！\nKubectl Logs  Kubectl Logs Output   kubectl logs -l app=splunk-otel-collector -f --container otel-collector 2021-03-21T16:11:10.900Z INFO service/service.go:364 Starting receivers... 2021-03-21T16:11:10.900Z INFO builder/receivers_builder.go:70 Receiver is starting... {\"component_kind\": \"receiver\", \"component_type\": \"prometheus\", \"component_name\": \"prometheus\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {\"component_kind\": \"receiver\", \"component_type\": \"prometheus\", \"component_name\": \"prometheus\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:70 Receiver is starting... {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/watcher.go:195 Configured Kubernetes MetadataExporter {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\", \"exporter_name\": \"signalfx\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.009Z INFO healthcheck/handler.go:128 Health Check state change {\"component_kind\": \"extension\", \"component_type\": \"health_check\", \"component_name\": \"health_check\", \"status\": \"ready\"} 2021-03-21T16:11:11.009Z INFO service/service.go:267 Everything is ready. Begin running and processing data. 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/receiver.go:59 Starting shared informers and wait for initial cache sync. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.281Z INFO k8sclusterreceiver@v0.21.0/receiver.go:75 Completed syncing shared informer caches. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"}  インストールに失敗した場合に削除する\nOpenTelemetry Collectorのインストールに失敗した場合は、次のようにしてインストールを削除することで、最初からやり直すことができます。 helm delete splunk-otel-collector    3. UI でメトリクスを確認する Splunk の UI で左下の » を開いて Infrastructure をクリックします。\nContainers の下にある Kubernetes をクリックして Kubernetes Navigator Cluster Map を開き、メトリクスが送信されていることを確認します。\nクラスタが検出され、レポートされていることを確認するには、自分のクラスタを探します（ワークショップでは、他の多くのクラスタが表示されます）。クラスタ名を見つけるには、以下のコマンドを実行し、出力をクリップボードにコピーしてください。\nEcho Cluster Name   echo $(hostname)-k3s-cluster  次に、UIで、Splunkロゴのすぐ下にある「Cluster: - 」メニューをクリックし、先程コピーしたクラスタ名を検索ボックスに貼り付け、チェックボックスをクリックしてクラスタを選択し、最後にメニューのその他の部分をクリックしてフィルタを適用します。\nノードの状態を確認するには、クラスターの淡いブルーの背景にカーソルを置き、左上に表示される青い虫眼鏡 をクリックしてください 。\nこれで、ノードレベルまでドリルダウンできます。 次に、サイドバーボタンをクリックしてサイドバーを開き、Metricsサイドバーを開きます。\nサイドのスライダーを使って、CPU、メモリ、ネットワーク、イベントなど、クラスタ/ノードに関連する様々なチャートを見ることができます。\n  Access Tokens (Org Tokensと呼ばれることもあります)は、長期間利用を前提とした組織レベルのトークンです。デフォルトでは、これらのトークンは 5 年間保存されます。そのため、長期間にわたってデータポイントを送信するエミッターに組み込んだり、Splunk API を呼び出す長期的なスクリプトに使用したりするのに適しています。 ↩︎\n Realm とは、Splunk内部の管理単位ので、その中で組織がホストされます。異なる Realm には異なる API エンドポイントがあります (たとえば、データを送信するためのエンドポイントは、us1 realm では ingest.us1.signalfx.com 、eu0 レルムでは ingest.eu0.signalfx.com となります)。このrealm名は、Splunk UI のプロファイルページに表示されます。エンドポイントを指定する際にレルム名を含めない場合、Splunk は us0 レルムを指していると解釈します。 ↩︎\n   ","categories":"","description":"","excerpt":" Splunk Helm chartを使用して、K3s に OpenTelemetry Collector をインストー …","ref":"/observability-workshop/v4.41/ja/imt/docs/gdi/k3s/","tags":"","title":"Kubernetes環境にOpenTelemetry Collectorをデプロイする"},{"body":"This Lab walks your through using the Chrome Selenium IDE extension to create a synthetic transaction against a Splunk demo instance and creating a Splunk Synthetic Monitoring Real Browser Check (RBC). In addition you also get to learn other Splunk Synthetic Monitoring checks like REST API checks and Uptime Checks.\n1. Prerequisites Ensure you can login with your username and password at https://monitoring.rigor.com and https://optimization.rigor.com. Also, make sure you are assigned to your own account for example: O11y Workshop.\nEdit your Splunk Synthetic Monitoring account personal information and adjust your timezone and email notifications. Splunk Synthetic Monitoring will default to start sending you notifications, you can turn them off at the monitor configuration level.\nAdd the Chrome Selenium IDE extension to your Chrome Browser. Once installed click on the extension and you will see the following screen:\n2. Using Selenium IDE You can now go ahead and record a web transaction using Selenium IDE to check on http://splunk.o11ystore.com.\nClick on Record a new test in a new project, name the project [YOUR_INITIALS] - O11y Store e.g. RWC - O11y Store.\n!!! question “What is Selenium IDE?” - Selenium IDE is an open source record and playback test automation for the web. - Selenium is a portable framework for testing web applications. - Selenium provides a playback tool for authoring functional tests without the need to learn a test scripting language (Selenium IDE). - It also provides a test domain-specific language (Selenese) to write tests in a number of popular programming languages, including C#, Groovy, Java, Perl, PHP, Python, Ruby and Scala. - The tests can then run against most modern web browsers. - Selenium runs on Windows, Linux, and macOS. - It is open-source software released under the Apache License 2.0.\nEnter http://splunk.o11ystore.com as your base URL.\nClick Start Recording   , a new window should open up with splunk.o11ystore.com. Click Vintage Camera Lens, click Add To Cart and then click Place Order.\nClose the window and then stop the recording by navigating back to Selenium IDE. Finally name the test: [YOUR_INITIALS] - Checkout Flow (Desktop) e.g. RWC - Checkout Flow (Desktop).\nYour Selenium IDE Project will look something like this:\nTest your recording by pressing on the play button, make sure your recording successfully completes the transaction:\nSave your Selenium IDE Project to your Downloads folder as Workshop.side\n3. Create Real Browser Check Login to Splunk Synthetic Monitoring using https://monitoring.rigor.com. Click on REAL BROWSER and click +New{: .label-button .sfx-ui-button-blue}.\nClick on “From File” and select your recording then click on Import\nSet the Frequency to 5 Minutes\nClick on Steps and make the following adjustments to your recording provide a friendly name to Steps 1 (Click Camera), 2 (Add to Cart) \u0026 3 (Place Order).\nNext, click + Add Step, with this new step we will add some validation to the monitor. This is to ensure the checkout completed successfully.\nEnter Confirm Order for the Name and change the Action to Wait for text present and finally enter Your order is complete! for the Value. You will now have a Start Url and 4 steps in your monitor configuration.\nTip\nAs you are creating the steps think about how to go about using the Business Transaction feature in Splunk Synthetic Monitoring which is very powerful. “Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.\"\n  Click on Advanced and make sure the Viewport Size is set to Default desktop: 1366 x 768\nClick on “Test” to test your monitor. Once the test has successfully completed make sure to click on “AFTER” in Step 4 to validate the monitor was able to get to the order complete screenshot.\nClick on Create{: .label-button .sfx-ui-button-blue} to save your Real Browser Monitor. After 5-10 minutes validate your monitor is working and producing successful checks e.g.\nTip\nYou can force to run your monitor now using Run Now\n  Change your view to Segment by location and observe the difference. You can turn off/on locations by clicking on them.\n!!! question “Question?” Which Location has the poorest Response Time?\nClick on one of the successful circles to drilldown into that Run:\nTake a moment to explore the metrics with the CONFIGURE METRICS/HIDE METRICS dropdown.\nClick Page 2 in the dropdown, and scroll down to view the Filmstrip and the Waterfall Chart.\nClick on Click Here to Analyze with Optimization which will prompt you to login to your Splunk Synthetic Monitoring Optimization Account. If you don’t have this option, navigate to this page.\nClick the “Best Practices Score” tab. Scroll down, and review all the findings\nSpend some time to review the findings. Click into any line item\n4. Create Mobile Check Copy the RBC you created above:\nRename it, for example: RWC - Checkout Flow (Tablet)\nUnder the Advanced tab, update the following three settings and create your new mobile RBC.\nTest \u0026 Validate the new monitor\nTip\nAs you are creating the steps try using the Business Transaction feature in Splunk Synthetic Monitoring. “Business Transactions are a combined group of contiguous steps in a Real Browser script that are to be measured as a whole. These transactions logically group similar parts of a flow together, so that users can view the performance of multiple steps and page(s) grouped under one Business Transaction.\"\n  5. Resources   Getting Started With Selenium IDE\n  Splunk Synthetic Monitoring Scripting Guide\n  How Can I Fix A Broken Script?\n  Introduction to the DOM (Document Object Model (DOM)\n  Selenium IDE\n  ","categories":"","description":"Scripting and configuring a Real Browswer Check\n","excerpt":"Scripting and configuring a Real Browswer Check\n","ref":"/observability-workshop/v4.41/synthetics/docs/real-browser-checks/","tags":"","title":"Real Browser Check"},{"body":"このラボでは Chrome Selenium IDE エクステンションを使用したSplunkデモインスタンスに対する合成トランザクションと、Splunk Synthetic Monitoring Real Browser Check (RBC)を作成します。\n1. 前提 https://monitoring.rigor.com と https://optimization.rigor.com にログインできることを確認します。また、 O11y Workshop のようなアカウントにアサインされていることを確認します。\nSplunk Synthetic Monitoring アカウントの個人情報を編集し、タイムゾーンとメール通知を編集します。Splunk Synthetic Monitoring はデフォルトで通知しますが、モニターの設定で通知をオフにすることができます。\nChrome Selenium IDE エクステンションをあなたの Chrome ブラウザーに追加します。インストールした後、エクステンションをクリックすることで次の画面が表示されます。\n2. Selenium IDE の使用 http://splunk.o11ystore.com にアクセスし、Selenium IDEを使いウェブトランザクションを記録する準備が整いました。\nRecord a new test in a new project をクリックしプロジェクト名に [あなたのイニシャル] - O11y Store （例：RWC - O11y Store）と入力します。\n!!! 質問 「Selenium IDEとは何ですか？」 - Selenium IDE は、オープンソースの Web 用の記録と再生のテスト自動化ツールです。 - SeleniumはWebアプリケーションをテストするためのポータブルなフレームワークです。 - Selenium はテストスクリプト言語 (Selenium IDE) を学ぶ必要なしに機能テストを作成するための再生ツールを提供します。 - C#、Groovy、Java、Perl、PHP、Python、Ruby、Scalaなどの多くの一般的なプログラミング言語でテストを記述するためのテストドメイン固有の言語（Selenese）を提供します。 - テストはほとんどの最新のWebブラウザで実行できます。 - Seleniumは、Windows、Linux、macOS上で動作します。 - Apache License 2.0の下で公開されているオープンソースソフトウェアです。\nBase URLに http://splunk.o11ystore.com と入力します。\nStart Recording{: .label-button .sfx-ui-button-grey} をクリックすると splunk.o11ystore.com が開かれた新しいウインドウが立ち上がります。 Vintage Camera Lens をクリックし、 Add To Cart をクリックし、次に Place Order をクリックします。\nウインドウを閉じ、Selenium IDEに戻りレコーディングを停止します。最後にテストケースに名前を付けます。 [あなたのイニシャル] - Checkout Flow (Desktop) （例：RWC - Checkout Flow (Desktop)）\nあなたのSelenium IDEプロジェクトは、このようになります。\n再生ボタンを押してレコーディングをテストし、レコーディングがトランザクションを正常に完了することを確認してください。\nSelenium IDE プロジェクトをダウンロードフォルダに Workshop.side という名前で保存します。\n3. Real Browser Check の作成 https://monitoring.rigor.com からSplunk Synthetic Monitoringにログインします。 REAL BROWSER をクリックし、 +New{: .label-button .sfx-ui-button-blue} をクリックします。\n「From File」をクリックしレコーディングファイルを選択し、Importをクリックします。\nFrequency を 5 Minutes にセットします。\n各Stepをクリックし、次のように分かりやすい名前を付けてあげます。\nStep 1: Click Camera\nStep 2: Add to Cart\nStep 3: Place Order\n次に + Add Step をクリックし、バリデーション用のステップを追加します。これはチェックアウトが成功したかどうかを確かめるものです。\nName に Confirm Order と入力し、 Action を Wait for text present に変更し、 Value に Your order is complete! と入力します。ここまでで Start Url と4つのステップが作られました。\nTip\nStep作成時には非常に強力な Business Transaction 機能の利用もご検討ください。「Business Transactionとは、Real Browserスクリプト内の連続したステップをまとめたものです。これらのトランザクションは、フローの類似部分を論理的にグループ化し、ユーザーは複数のステップとページ（複数可）のパフォーマンスを1つのビジネストランザクションにまとめて表示できるようにします。\"\n  Advanced をクリックし、 Viewport Size が Default desktop: 1366 x 768 であることを確認します。\n「Test」をクリックしモニター設定をテストします。テストが正常に完了した後、Step 4の「AFTER」をクリックし、注文完了のスクリーンショットを取得できたことを確認してください。\nCreate{: .label-button .sfx-ui-button-blue} をクリックし、Real Browser Monitorを保存します。5から10分後にモニターが動作し、以下のようなチェック成功が表示されることを確認します。\nTip\nRun Now を実行することでモニターを即座に実行できます。\n  Segment by location をクリックし、見た目の変化を確認してください。クリックすることで各ロケーションのon/offが可能です。\n!!! 問題です！ Response Time が一番低いロケーションはどこでしょうか？\n成功した円のうちどれかをクリックし、実行結果にドリルダウンします。\nCONFIGURE METRICS/HIDE METRICS ドロップダウンで、取得しているメトリクスを確認してみてください。\nドロップダウンの Page 2 をクリックし、 Filmstrip と Waterfall Chart までスクロールダウンして結果を確認してください。\nClick Here to Analyze with Optimization をクリックするとSplunk Synthetic Monitoring Optimizationへのログインができます。もし このオプションが表示されない場合 、この ページ にアクセスしてください。\n「Best Practices Score」タブをクリックします。スクロールダウンし、結果を確認します。\n時間をとって、結果をレビューしてみてください。他の項目もクリックしてみてください。\n4. Mobile Check の作成 作成したRBC (Real Browser Check）をコピーします。\n名前を RWC - Checkout Flow (Tablet) のように変更します。\nAdvanced タブ配下で以下の3つの設定を変更し、新しいモバイル用のRBCを作成します。\n新しいモニター設定をテスト＆確認します。\nTip\nStep作成時には非常に強力な Business Transaction 機能の利用もご検討ください。「Business Transactionとは、Real Browserスクリプト内の連続したステップをまとめたものです。これらのトランザクションは、フローの類似部分を論理的にグループ化し、ユーザーは複数のステップとページ（複数可）のパフォーマンスを1つのビジネストランザクションにまとめて表示できるようにします。\"\n  5. リソース   Getting Started With Selenium IDE   Splunk Synthetic Monitoring Scripting Guide   How Can I Fix A Broken Script?   Introduction to the DOM (Document Object Model (DOM)\n  Selenium IDE   ","categories":"","description":"Real Browswer Check のスクリプトと設定\n","excerpt":"Real Browswer Check のスクリプトと設定\n","ref":"/observability-workshop/v4.41/ja/synthetics/docs/real-browser-checks/","tags":"","title":"Real Browser Check"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/session-1/","tags":"","title":"1. Role Play Qualification / Discovery - with SRE and ITOPs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/session-2/","tags":"","title":"2. Getting Data In (GDI) \u0026 OTEL"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/session-3/","tags":"","title":"3. ITOps Monitoring Monitoring Monitoring"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/session-4/","tags":"","title":"4. ITOps - Understanding Event Analytics in Realistic Business Services"},{"body":"This workshop will equip you with the basic understanding of monitoring Kubernetes using the Splunk OpenTelemetry Collector. During the workhop you will deploy PHP/Apache and a load generator.\nYou will learn about OpenTelemetry Receivers, Kubernetes ReplicaSets, Kubernetes Horizontal Pod AutoScaling and how to monitor all this using the Splunk Observability Cloud. The main learnings from the workshop will be a better understanding of the Kubernetes Navigator (and Dashboards) in Splunk Observability Cloud. Along, with seeing Kubernetes metrics, events and Auto-Detectors.\nIn order to part take in this workshop you will need to have a access to a Splunk Observability Cloud account in US Splunk Show, your laptop and hopefully a stable wi-fi connection.\nIn preparation for the workshop, Splunk has prepared an Ubuntu Linux instance in AWS/EC2.\nTo get access to the instance that you will be using in the workshop please visit the URL to access the Google Sheet provided by the workshop leader.\n","categories":"","description":"","excerpt":"This workshop will equip you with the basic understanding of …","ref":"/observability-workshop/v4.41/tko/session-5/","tags":"","title":"5. How Platform Engineers Observe Kubernetes - Workshop"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/session-6/","tags":"","title":"6. O11y - Distributed Tracing for modern applications"},{"body":"","categories":"","description":"Environment Configuration and Hands-On Exercises\n","excerpt":"Environment Configuration and Hands-On Exercises\n","ref":"/observability-workshop/v4.41/imt/docs/","tags":"","title":"Setup and Exercises"},{"body":"During this technical Splunk Observability Cloud Infrastructure Monitoring and APM Workshop you will build out an environment based on a lightweight Kubernetes1 cluster.\nIn order to simplify the workshop modules, a pre-configured AWS/EC2 instance is provided.\nThe instance is pre-configured with all the software required to deploy the Splunk OpenTelemetery Connector2 in Kubernetes, deploy a NGINX3 ReplicaSet4 and finally deploy a microservices based application which has been instrumented using OpenTelemetry to send metrics, traces, spans and logs5.\nThe workshops also introduce you to dashboards, editing and creating charts, creating detectors to fire alerts, Monitoring as Code6 and the Service Bureau6\nBy the end of these technical workshops you will have a good understanding of some of the key features and capabilities of the Splunk Observability Cloud.\nHere are the instructions on how to access you pre-configured AWS/EC2 instance\n  Kubernetes is a portable, extensible, open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. ↩︎\n The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) sending to multiple open-source or commercial back-ends. ↩︎\n NGINX is a web server that can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. ↩︎\n Kubernetes ReplicaSet ↩︎\n Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies. It is used for monitoring and troubleshooting microservices-based distributed systems ↩︎\n Monitoring as Code and Service Bureau ↩︎\n   ","categories":"","description":"","excerpt":"During this technical Splunk Observability Cloud Infrastructure …","ref":"/observability-workshop/v4.41/imt/","tags":"","title":"Introduction"},{"body":"この テクニカル Splunk Observability Cloud ワークショップでは、 lightweight Kubernetes1 クラスタをベースにした環境を構築します。\nワークショップのモジュールを簡素化するために、あらかじめ設定されたAWS/EC2インスタンスが提供されます。\nこのインスタンスには、ワークショップに必要となるソフトウェアが予め設定されています。これに対してOpenTelemetery Collector2 を Kubernetes 上でデプロイし、 NGINX3 の ReplicaSet4 をデプロイし、最後に OpenTelemetry を使用して計装されたマイクロサービスベースのアプリケーションをデプロイして、メトリクス、トレース、スパン、ログ5を送信していきます。\nさらにこのワークショップでは、ダッシュボード、チャートの編集と作成、アラートを発するためのディテクターの作成、Monitoring as Code6 および Service Bureau6 についても紹介します。\nこのテクニカルワークショップを終える頃には、Splunk Observability Cloudの主要な機能や性能を十分に理解していることでしょう。\n事前に設定された AWS/EC2 インスタンス へのアクセス方法をご紹介します。\n  Kubernetes は、コンテナ化されたワークロードやサービスを管理するためのポータブルで拡張可能なオープンソースのプラットフォームで、宣言的な構成と自動化の両方を促進します。 ↩︎\n OpenTelemetry Collector は、遠隔測定データの受信、処理、およびエクスポートの方法について、ベンダーに依存しない実装を提供します。さらに、複数のオープンソースまたは商用バックエンドに送信するオープンソースの遠隔測定データ形式（Jaeger、Prometheusなど）をサポートするために、複数のエージェント/コレクターを実行、運用、保守する必要性を排除します。 ↩︎\n NGINX は、リバースプロキシ、ロードバランサー、メールプロキシ、HTTPキャッシュとしても使用できるWebサーバーです。 ↩︎\n Kubernetes ReplicaSet を使用しています。 ↩︎\n Jaeger は、Dapper や OpenZipkin にインスパイアされた、Uber Technologies がオープンソースとして公開している分散型トレースシステムです。マイクロサービスベースの分散システムの監視とトラブルシューティングに使用されています。 ↩︎\n Monitoring as Code and Service Bureau を使用しています。 ↩︎\n   ","categories":"","description":"","excerpt":"この テクニカル Splunk Observability Cloud ワークショップでは、 lightweight Kubernetes1 …","ref":"/observability-workshop/v4.41/ja/imt/","tags":"","title":"はじめに"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tko/","tags":"","title":"TKO Workshops"},{"body":" Check the original HEAD section of your Online-boutique webpage (or use the examples here) in your browser Find the Web address of your workshop hosts Online Boutique Compare the changes made to the hosts Online-Boutique and compare with the base one.   1. Review the original code of your NON RUM Online-Boutique If you have access to an EC2 instance and have previously installed the Online Boutique as part of the APM session, you can view it on port 81 of the EC2 instance’s IP address.\nIf you have not got access to an EC2 instance with the Online Boutique installed then your workshop instructor will provide you with the Online Boutique URL that does not have RUM installed so that you can complete the next steps.\n2. Obtain RUM Access Token As this Deployment we are about to do is also used as part of the RUM workshop section, you will need to obtain your RUM Access Token from the Splunk UI. You can find the workshop Access Token by clicking » bottom left or the menu option and then selecting Settings → Access Tokens.\nExpand the RUM workshop token that your host has instructed you to use e.g. O11y-Workshop-RUM-TOKEN, then click on Show Token to expose your token. Click the Copy    button to copy to clipboard. Please do not use the Default token! Make sure the token has RUM as its Authorization Scope.\nPlease do not attempt to create your own token\nWe have created a RUM Token specifically for this workshop with the appropriate settings for the exercises you will be performing   Create the RUM_TOKEN environment variable to use in the proceeding shell script to personalize your deployment.\nExport Variables   export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e  2. Deploy Online Boutique To deploy the Online Boutique application into K3s, run the apm config script, then apply the deployment:\nDeploy Online Boutique  Deployment Output   cd ~/workshop/apm ./apm-config.sh -r kubectl apply -f deployment.yaml deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/paymentservice created service/paymentservice created deployment.apps/emailservice created service/emailservice created deployment.apps/adservice created service/adservice created deployment.apps/cartservice created service/cartservice created deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created  In case of a message about a VARIABLE being unset\nPlease undeploy the APM environment by running kubectl delete -f deployment.yaml Before exporting the variable as described in the guide and rerunning the deployment script above.   Open your web browser and go to the Online Boutique. (The one you previously used, or the one provided by the Workshop instructor). You will see the Non RUM Online Boutique running.\nFollow the instructions for your preferred browser below:\n1.1 Chrome, FireFox \u0026 Microsoft Edge Users - Check the Web page source In Chrome \u0026 Firefox or Microsoft Edge you can right click on the Online-Boutique site, you will have an option to “View Page Source”\nSelecting it will show you the HTML page source code in a separate Tab.\nIf successful you can skip to 2 - Review the unchanged HEAD section.\n1.2 Safari Users - Check the Web page source For Safari users, you may have to enable the extra menu in Safari by selecting ‘Preferences’ under Safari in the OS X menu bar.\nThen in the dialog that pops up, under the ‘Advanced’ pane select the checkbox that says ‘Show Develop menu in menu bar. ‘ and close the Dialog box.\nYou can now right click on the Online-Boutique and you now will have an option ‘Show Page Source’.\nIf you select that option on the Online-Boutique you will see the HTML source code as shown below:\nIf successful you can skip to 2 - Review the unchanged HEAD section.\n1.3 Internet Explorer Users - Check the Web page source For Internet Explorer 11 Users, you may have trouble with this exercise as it will require a specific version of the Splunk Open Telemetry Javascript for Web/RUM.\nHowever you will be able to see the changes required by right clicking on the Online-Boutique site, you see an option to “View Source”\nIf you select that option on the Online-Boutique you will see the HTML source code as shown below:\n2 - Review the unchanged HEAD section The changes for RUM will be placed in the HEAD section of your Web page, Below are the original lines as you should have it in your local Base version.\nThere is no reference to the Splunk or Open Telemetry Beacon (The function that is used to send RUM Metrics and Traces )\n3. Find the web (URL) of the RUM enabled Online Boutique The Online Boutique we are going to use for RUM is viewable on port 81 of the RUM Enabled instance’s IP address and the url will be provided to you by the workshop instructor at this point.\nWe are all connecting to the extra RUM Enabled Online Boutique provided by the workshops instructor for this RUM session. Open a new web browser and go to http://{==RUM-HOST-EC2-IP==}:81/ where you will then be able to see the RUM enabled Online Boutique running. Again, view the source of the HTML Page as described in the previous section:\n4. Review the Changes made to enable RUM in the HEAD section of the RUM enabled Online-Boutique The changes needed for RUM are placed in the HEAD section of the hosts Web page, Below is the hosts updated HEAD section with the changes required to enable RUM:\nThe first three lines (marked in red) have been added to the HEAD section of the host Web page to enable RUM Tracing, the last three (marked in blue) are optional and used to enable Custom RUM events.\n\u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" type=\"text/javascript\"\u003e\u003c/script\u003e \u003cscript\u003ewindow.SplunkRum \u0026\u0026 window.SplunkRum.init({beaconUrl: \"https://rum-ingest.eu0.signalfx.com/v1/rum\", rumAuth: \"1wCqZVUWIP5XSdNjPoQRFg\", app: \"ksnq-rum-app\", environment: \"ksnq-rum-env\"});\u003c/script\u003e \u003cscript\u003e const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); \u003c/script\u003e  The first part is to indicate where to download the Splunk Open Telemetry Javascript file from: https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js (This can also be loaded locally if so required) The second line defines the location where to send the traces to in the beacon url: {beaconUrl: \"https://rum-ingest.eu0.signalfx.com/v1/rum\" It also adds an Access Token to : rumAuth: \"1wCqZVUWIP5XSdNjPoQRFg\" (this of course is an example, you can create multiple RUM Access Tokens for all your applications) And it is used to add identification tags like the application Name and environment to the RUM trace for use in the SPLUNK RUM UI: app: \"ksnq-rum-app\", environment: \"ksnq-rum-env\"}  Info\nIn this example the app name is ksnq-rum-app, this will be different in the Workshop. Check with your host what the app name and environment to use in the RUM session will be and make a note of it!   The above two lines are all that is required to enable RUM on your website!\nThe (blue) optional section that uses var tracer=Provider.getTracer('appModuleLoader'); will add a custom event for every page change allow you to better track your website conversions and usage.\n","categories":"","description":"","excerpt":" Check the original HEAD section of your Online-boutique webpage (or …","ref":"/observability-workshop/v4.41/rum/docs/setup/","tags":"","title":"Example of RUM enablement in your Website"},{"body":" ダッシュボードとチャートの紹介 チャートの編集と作成 フィルタリングと分析関数 数式の使用 ダッシュボードでのチャートの保存 SignalFlowの紹介   1. ダッシュボード ダッシュボードとは、チャートをグループ化し、メトリクスを視覚化したものです。適切に設計されたダッシュボードは、システムに関する有益で実用的な洞察を一目で提供します。ダッシュボードは複雑なものもあれば、見たいデータだけを掘り下げたいくつかのチャートだけのものもあります。\nこのモジュールでは、次のようなチャートとダッシュボードを作成し、それをチームページに接続します。\n 2. あなたのチームのページ 左のナビゲーションから を開きます。あなたはすでにチームに割り当てられているので、チームダッシュボードが表示されます。\nここでは、チーム Example Team を例に挙げています。実際のワークショップでは、別のチーム名かも知れません。\nこのページには、チームメンバーの総数、チームのアクティブなアラートの数、チームに割り当てられているすべてのダッシュボードが表示されます。現在、ダッシュボードは割り当てられていませんが、この後で、あなたが作成する新しいダッシュボードをチームページに追加していきます。\n 3. サンプルチャート 続けて、画面右上の All Dashboards をクリックします。事前に作成されたものも含め、利用可能なすべてのダッシュボードが表示されます。\nすでにSplunk Agentを介してCloud APIインテグレーションや他のサービスからメトリクスを受信している場合は、これらのサービスに関連するダッシュボードが表示されます。\n 4. サンプルデータの確認 ダッシュボードの中に、 Sample Data というダッシュボードグループがあります。Sample Data ダッシュボードグループをクリックして展開し、Sample Charts ダッシュボードをクリックします。\nSample Charts ダッシュボードでは、ダッシュボードでチャートに適用できる様々なスタイル、色、フォーマットのサンプルを示すチャートが表示されます。\nこのダッシュボードグループのすべてのダッシュボード（PART 1、PART 2、PART 3、INTRO TO SPLUNK OBSERVABILITY CLOUD）に目を通してみてください。\n","categories":"","description":"","excerpt":" ダッシュボードとチャートの紹介 チャートの編集と作成 フィルタリングと分析関数 数式の使用 ダッシュボードでのチャー …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/intro/","tags":"","title":"ダッシュボード、チャート、メトリクスを使う"},{"body":"","categories":"","description":"ここでは、環境設定とハンズオン演習を行います\n","excerpt":"ここでは、環境設定とハンズオン演習を行います\n","ref":"/observability-workshop/v4.41/ja/imt/docs/","tags":"","title":"セットアップと演習"},{"body":" ブラウザでOnline BoutiqueのウェブページのオリジナルのHEADセクション（またはここにある例を使用）をチェックします ワークショップ Online Boutique の Webアドレスを検索します Online Boutiqueに加えられた変更を確認します   1. RUMなしのOnline Boutiqueのオリジナルコードを確認する APMセッションの一部でEC2インスタンスにOnline Boutiqueをインストールしていれば、ポート番号81でサイトにアクセスできます。\nOnline BoutiqueがインストールされたEC2インスタンスにアクセスできない場合は、講師からRUMがインストールされていないOnline BoutiqueのURLを教えてもらい、次のステップに進んでください。\n2. RUM Access Tokenの入手 これから行うデプロイメントは、RUM ワークショップセクションの一部としても使用されます。Splunk UIからRUM Access Tokenを取得する必要があります。ワークショップのアクセストークンは、左下の » をクリックし メニューをクリックして、 Settings → Access Tokens を選択すると見つけることができます。\n講師が使用するように指示したRUMワークショップトークン（例： O11y-Workshop-RUM-TOKEN ）を展開し、 Show Token をクリックしてトークンを公開します。 Copy    ボタンをクリックし、クリップボードにコピーしてください。 Default のトークンは使用しないでください。トークンのAuthorization ScopeがRUMであることを確認してください。\n新規にトークンを作らないでください\nこのワークショップのために、皆さんが行う演習に適した設定をしたRUM Tokenを作成しています。   EC2にSSHアクセスしているシェルスクリプトで環境変数 RUM_TOKEN を作成し、デプロイメントをパーソナライズします。\nExport Variables   export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e  2. Online Boutiqueのデプロイ Online BoutiqueアプリケーションをK3sにデプロイするには、apm configスクリプトを実行し、デプロイを適用してください。\nDeploy Online Boutique  Deployment Output   cd ~/workshop/apm ./apm-config.sh -r kubectl apply -f deployment.yaml deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/paymentservice created service/paymentservice created deployment.apps/emailservice created service/emailservice created deployment.apps/adservice created service/adservice created deployment.apps/cartservice created service/cartservice created deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created  変数未セットに関するメッセージが表示された場合\nkubectl delete -f deployment.yaml コマンドを実行しAPM環境のデプロイ削除します。 次にガイド、メッセージに表示されていた変数をexportし上記のデプロイスクリプトを再実行します。   ウェブブラウザーを起動し、Online Boutiqueにアクセスします。 (以前使用したもの、または新しくワークショップ講師が提供したもの）。RUMなしのOnline Boutiqueが起動していることが確認できます。\n下記のお使いのブラウザの説明に従ってください。\n1.1 Chrome, FireFox \u0026 Microsoft Edge ユーザー - ページのソースを確認 Chrome、Firefox、Microsoft Edgeでは、Online Boutiqueのサイト上で右クリックすると、 「ページのソースを表示」 のオプションが表示されます。\nこれを選択すると、HTMLページのソースコードが別のタブで表示されます。\n成功すれば、 2 - 変更前のHEADセクションの確認 へ進みます。\n1.2 Safari ユーザー - ページのソースを確認 Safariでは機能を有効化する必要がある場合があります。OS Xメニューバーの Safari の配下にある 「設定」 をクリックします。\nダイアログがポップアップしますので、 「詳細」 ペイン内の 「メニューバーに\"開発\"メニューを表示」 にチェックをいれ、ダイアログボックスを閉じます。\nOnline Boutiqueを右クリックすると、「ページのソースを表示する」オプションが表示されるようになります。\nOnline Boutiqueでそのオプションを選択すると、以下のようなHTMLソースコードが表示されます。\n成功すれば、 2 - 変更前のHEADセクションの確認 へ進みます。\n1.3 Internet Explorer ユーザー - ページのソースを確認 Internet Explorer 11 をお使いの場合、この演習では Web/RUM 用のSplunk Open Telemetry JavaScriptの特定のバージョンが必要になるため、問題が発生する可能性があります。 ただし、Online Boutiqueサイトを右クリックすると、「ソースを表示」 のオプションが表示され、必要な変更を確認することができます。\nOnline Boutiqueでそのオプションを選択すると、以下のようなHTMLソースコードが表示されます。\n2 - 変更前のHEADセクションの確認 RUMのための変更は、WebページのHEADセクションで実施します。以下は、あなたのローカルのBaseバージョンにあるべきオリジナルの行です。\nSplunk または Open Telemetry Beacon (RUM Metrics と Traces を送信するために使用される関数) への参照はありません。\n3. RUM有効Online Boutiqueのウェブ（URL）を探す RUMで使用するOnline Boutiqueは、RUM有効インスタンスのIPアドレスの81番ポートで見ることができます。URLはワークショップの講師から提供されます。\nこのRUMのセッションでは、講師が用意したRUM有効Online Boutiqueにアクセスできます。新しいウェブブラウザを開き、 http://{==RUM-HOST-EC2-IP==}:81/ にアクセスすると、RUM有効Online Boutiqueが動作しているのが見えます。ここでも、前のセクションで説明したように、HTMLページのソースを表示します。\n4. RUMを有効にするために行った変更をHEADセクションで確認 RUMに必要な変更は、WebページのHEADセクションに配置されます。以下は、RUMを有効にするために必要な変更を加えたhostsの更新されたHEADセクションです。\n最初の3行（赤色でマーク）は、RUMトレースを有効にするためにWebページのHEADセクションに追加されています。最後の3行（青色でマーク）はオプションで、カスタムRUMイベントを有効にするために使用します。\n\u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" type=\"text/javascript\"\u003e\u003c/script\u003e \u003cscript\u003ewindow.SplunkRum \u0026\u0026 window.SplunkRum.init({beaconUrl: \"https://rum-ingest.eu0.signalfx.com/v1/rum\", rumAuth: \"1wCqZVUWIP5XSdNjPoQRFg\", app: \"ksnq-rum-app\", environment: \"ksnq-rum-env\"});\u003c/script\u003e \u003cscript\u003e const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); \u003c/script\u003e  最初の行は、Splunk Open Telemetry Javascript ファイルをダウンロードする場所を指定しています。https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js  (必要であれば、ローカルに読み込むこともできます) 2行目は、Beacon URLでトレースの送信先を定義しています。 {beaconUrl: \"https://rum-ingest.eu0.signalfx.com/v1/rum\" また、Access Tokenを追加しています。 rumAuth: \"1wCqZVUWIP5XSdNjPoQRFg\" (もちろんこれは例です。全てのアプリケーションに対して、複数のRUM Access Tokenを作成することができます。) * また、SPLUNK RUM UIで使用するために、アプリケーション名や環境などの識別タグをRUMトレースに追加するために使用されます。 app: \"ksnq-rum-app\", environment: \"ksnq-rum-env\"}  Info\nこの例ではアプリ名は ksnq-rum-app ですが、これはワークショップでは異なるでしょう。RUMセッションで使用するアプリ名と環境は講師に確認し、メモしておいてください。   上記の2行だけであなたのWebサイトでRUMを有効にすることができます。\n(青色の)オプションのセクションでは、 var tracer=Provider.getTracer('appModuleLoader'); を使用して、すべてのページ変更に対してカスタムイベントを追加し、ウェブサイトのコンバージョンと使用状況をよりよく追跡できるようにします。\n","categories":"","description":"","excerpt":" ブラウザでOnline BoutiqueのウェブページのオリジナルのHEADセクション（またはここにある例を使用）をチェックします ワーク …","ref":"/observability-workshop/v4.41/ja/rum/docs/setup/","tags":"","title":"自分のWebサイトでRUMを有効化する場合の例"},{"body":".NET CORE example uses the .NET http client to get non-responding URL so makes valid traces with 403 status code\nContainerized with these instructions from Microsoft\n.NET Core 5\ncd ~/otelworkshop/k8s/dotnet Deploy:\nsource deploy-client.sh Delete deployment:\nsource delete-all.sh .NET Core 2.1 .NET Core 2.1 located here\n","categories":"","description":"","excerpt":".NET CORE example uses the .NET http client to get non-responding URL …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/examples/dotnet/","tags":"","title":".Net Setup"},{"body":" How to retrieve the IP address of the AWS/EC2 instance assigned to you. Connect to your instance using SSH, Putty1 or your web browser. Verify your connection to your AWS/EC2 cloud instance.   1. AWS/EC2 IP Address In preparation for the workshop, Splunk has prepared an Ubuntu Linux instance in AWS/EC2.\nTo get access to the instance that you will be using in the workshop please visit the URL to access the Google Sheet provided by the workshop leader.\nSearch for your AWS/EC2 instance by looking for your first and last name, as provided during registration for this workshop.\nFind your allocated IP address, SSH command (for Mac OS, Linux and the latest Windows versions) and password to enable you to connect to your workshop instance.\nIt also has the Browser Access URL that you can use in case you cannot connect via ssh or putty - see EC2 access via Web browser\nImportant\nPlease use SSH or Putty to gain access to your EC2 instance if possible and make a note of the IP address as you will need this during the workshop.   2. SSH (Mac OS/Linux) Most attendees will be able to connect to the workshop by using SSH from their Mac or Linux device, or on Windows 10 and above.\nTo use SSH, open a terminal on your system and type ssh ubuntu@x.x.x.x (replacing x.x.x.x with the IP address found in Step #1).\nWhen prompted Are you sure you want to continue connecting (yes/no/[fingerprint])? please type yes.\nEnter the password provided in the Google Sheet from Step #1.\nUpon successful login you will be presented with the Splunk logo and the Linux prompt.\n3. SSH (Windows 10 and above) The procedure described above is the same on Windows 10, and the commands can be executed either in the Windows Command Prompt or PowerShell. However, Windows regards its SSH Client as an “optional feature”, which might need to be enabled.\nYou can verify if SSH is enabled by simply executing ssh\nIf you are shown a help text on how to use the ssh-command (like shown on the screenshot below), you are all set.\nIf the result of executing the command looks something like on the screenshot below, you want to enable the “OpenSSH Client” feature manually.\nTo do that, open the “Settings” menu, and click on “Apps”. While being in the “Apps \u0026 features” section, click on “Optional features”.\nHere, you are presented a list of installed features. On the top, you see a button with a plus icon to “Add a feature”. Click it. In the search input field, type “OpenSSH”, and find a feature called “OpenSSH Client”, or respectively, “OpenSSH Client (Beta)”, click on it, and click the “Install”-button.\nNow you are set! In case you are not able to access the provided instance in spite of enabling the OpenSSH feature, please do not shy away from reaching out to the course instructor, either via chat or directly.\nAt this point you are ready to continue and start the workshop\n 4. Putty (For Windows Versions prior to Windows 10) If you do not have ssh preinstalled or if you are on a Windows system, the best option is to install putty, you can find here.\nImportant\nIf you cannot install Putty, please go to Web Browser (All).   Open Putty and enter the in Host Name (or IP address) field the IP address provided in the Google Sheet.\nYou can optionally save your settings by providing a name and pressing Save.\nTo then login to your instance click on the Open button as shown above.\nIf this is the first time connecting to your AWS/EC2 workshop instance, you will be presented with a security dialog, please click Yes.\nOnce connected, login in as ubuntu and the password is the one provided in the Google Sheet.\nOnce you are connected successfully you should see a screen similar to the one below:\nAt this point you are ready to continue and start the workshop\n 4. Web Browser (All) If you are blocked from using SSH (Port 22) or unable to install Putty you may be able to connect to the workshop instance by using a web browser.\nNote\nThis assumes that access to port 6501 is not restricted by your company’s firewall.   Open your web browser and type http://x.x.x.x:6501 (where X.X.X.X is the IP address from the Google Sheet).\nOnce connected, login in as ubuntu and the password is the one provided in the Google Sheet.\nOnce you are connected successfully you should see a screen similar to the one below:\nUnlike when you are using regular SSH, copy and paste does require a few extra steps to complete when using a browser session. This is due to cross browser restrictions.\nWhen the workshop ask you to copy instructions into your terminal, please do the following:\nCopy the instruction as normal, but when ready to paste it in the web terminal, choose Paste from browser as show below:\nThis will open a dialog box asking for the text to be pasted into the web terminal:\nPaste the text in the text box as show, then press OK to complete the copy and paste process.\n Note\nUnlike regular SSH connection, the web browser has a 60 second time out, and you will be disconnected, and a Connect button will be shown in the center of the web terminal.\nSimply click the Connect button and you will be reconnected and will be able to continue.\n  At this point you are ready to continue and start the workshop.\n 5. Multipass (All) If you are unable to access AWS, but you want to install software locally, follow the instructions for using Multipass.\n  Download Putty ↩︎\n   ","categories":"","description":"**5 minutes**\n","excerpt":"**5 minutes**\n","ref":"/observability-workshop/v4.41/imt/docs/initial-setup/","tags":"","title":"How to connect to your workshop environment"},{"body":"API Checkは、APIエンドポイントの機能およびパフォーマンスをチェックする柔軟な方法を提供します。APIファーストの開発へのシフトにより、フロントエンドのコア機能を提供するバックエンドサービスを監視する必要性が高まっています。複数ステップのAPIインタラクションのテストに興味がある場合でも、エンドポイントのパフォーマンスを可視化したい場合でも、API Checkは目標の達成に役立ちます。\n1. グローバル変数の作成 API Checkを行うために使用するグローバル変数を表示します。 Admin Tools の下にある Global Variables をクリックします。 spotifyのAPIトランザクションを行うために使用するグローバル変数を確認してください。\n2. API Check の作成 新しい API Check を作成し、\u003cあなたのイニシャル\u003e の後に Splunk REST API Check をつけた名前にします （例: AP - Spotify API）\nチェックに名前を付けたら、notificationタブを開いて、どのような設定があるか眺めてみましょう。\n次に、以下のAPI Check Stepsを追加します。\n変数はこちらから選ぶことができます:\nRequest Step \n リクエストステップは、あるエンドポイントにHTTPリクエストを行い、そのレスポンスからデータを取得します。他のチェックタイプとは異なり、APIチェックでは、チェックを開始するための初期URLは必要ありません。すべてのHTTPリクエストは、リクエストステップ内で設定されます。  Extract Step \n  Extractステップでは、JSON、XML、HTML形式のデータからデータを抽出します。\n  JSONからデータを抽出するには、次の3つを用意します:\n  JSONを含むソース\n  データを抽出するためのJSONPath式\n  保存先のカスタム変数名\n  ソースはどのようなJSONでもかまいませんが、たいていはレスポンスのBodyから取得するでしょう。レスポンスヘッダから取得することもできますし、また、カスタムの値も可能です。ソースは、整形されたJSONでなければなりません。\n  Save Step \n  Saveステップでは、チェックの後で再利用するためのデータを保存します。データを保存するには、ソースと保存先のカスタム変数名を指定します。ソースは、応答ヘッダを含むプリセットから選択するか、カスタム値を指定します。\n  その他の使用例としては、他のステップで簡単に再利用できるように情報を追加したり、リクエストの結果を保存して別のリクエストで再利用できるようにするなどがあります。\n  リクエスト変数は、リクエストが作成された後にのみ使用可能であることを覚えておくことが重要です。もし、リクエストから値を保存しようとしても、まだリクエストを行っていない場合は、空の文字列が保存されます。\n  Assert Step \n Assertステップは、2つの値に対してアサーションを行います。アサーションを行うには、2つのパラメータと、その2つの比較方法を指定します。  Comparisons \n  現在、string（文字列）、 numeric（数値）、regular expression（正規表現） の3種類の比較をサポートしています。\n  string と numeric では、値が比較タイプに強制されます。\n  reqular expression での比較の場合、最初のパラメータは文字列で、2番目のパラメータは正規表現になります。\n  API Check に Splunk と API のタグを付けて SAVE します。\n3. REST API Checkのテスト edit configuration に戻り、ページの下にある ‘test’ を押して、エラーがないことを確認します。\nウィンドウを上にスライドさせると、正常に実行された場合の詳細が表示されます\nさて、モニターにもう少し機能を追加してみましょう。詳細ウィンドウを下にスライドさせ、手順5～8を追加します。\nBONUS：ステップ6を使用して、以下のレスポンスがタイムリーに戻ってきたことをアサートします（1000 ms)\nステップを追加したら、モニターをテストして保存します。\n4. リソース   How to Create an API Check   API Check Overview   How Do I Use Business Transactions?   ","categories":"","description":"API Check のスクリプトと設定\n","excerpt":"API Check のスクリプトと設定\n","ref":"/observability-workshop/v4.41/ja/synthetics/docs/api-checks/","tags":"","title":"API Check"},{"body":"The API Check provides a flexible way to check the functionality and performance of API endpoints. The shift toward API-first development has magnified the necessity to monitor the back-end services that provide your core front-end functionality. Whether you’re interested in testing the multi-step API interactions or you want to gain visibility into the performance of your endpoints, the API Check can help you accomplish your goals.\n1. Create a Global Variable View the global variable that we’ll use to perform our API check. Click on Global Variables under Admin Tools. View the global variable that we’ll use to make the spotify API transaction\n2. Create an API Check Create a new API Check and name it \u003cyour initials\u003e followed by Splunk REST API Check for example: AP - Spotify API\nTake a second to explore the notification tab after you’ve named your check\nAdd the following API Check Steps:\nAvailable Variables to choose from:\nRequest Step\n A Request Step makes an HTTP request to some endpoint and collects data from that interaction. Unlike other check types, API Checks do not require an initial URL to start the check. All HTTP requests are configured within Request Steps.  Extract Step\n  An Extract Step extracts data out of JSON, XML, or HTML formatted data.\n  To extract data out of JSON, supply three things:\n  The source containing the JSON,\n  The JSONPath expression to extract out the data, and\n  The name of the custom variable that you want to save to.\n  The source can be any JSON, but most likely will come from the response body. The source could also come from a response header or can be a custom value. The source must be well-formed JSON.\n  Save Step\n  A Save Step stores some data to be reused later in the check. To save data, supply the source and the name of the custom variable to save to. The source can be selected from the presets, including response headers, or by providing a custom value.\n  Some additional use cases are appending bits of information to easily reuse in other steps and saving the results from one request to be reused after another request is made.\n  It is important to remember that request variables are only available after a request is made. If you try to save a value from a request but haven’t made a request yet, then an empty string will be saved.\n  Assert Step\n An Assert Step makes an assertion on two values. To make an assertion, supply two parameters along with the comparison that you would like to perform between the two.  Comparisons\n  We currently support 3 types of comparisons: string, numeric, and regular expression.\n  For string and numeric comparisons, values are coerced to the comparison type before the comparison is made.\n  For a regular expression comparison, the first parameter is a string and the second parameter is a regular expression.\n  Tag your API Check with Splunk and API and SAVE it\n3. Test your REST API Check Press got back into the edit configuration and press ‘test’ at the bottom of the page to ensure there are no errors\nSlide the window up to view details about the successful run\nNow, let’s add some more functionality to the monitor. Slide the detailed window back down and add steps 5-8\nBONUS: use step 6 to assert that the following response came back in a timely manner (1000 ms)\nOnce the steps are added, test \u0026 save the monitor.\n4. Resources   How to Create an API Check\n  API Check Overview\n  How Do I Use Business Transactions?\n  ","categories":"","description":"Scripting and configuring an API Check\n","excerpt":"Scripting and configuring an API Check\n","ref":"/observability-workshop/v4.41/synthetics/docs/api-checks/","tags":"","title":"API Checks"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/","tags":"","title":"APM for Kubernetes"},{"body":" 各自に割り当てられたAWS/EC2インスタンスのIPアドレスを確認します SSH、Putty1、またはWebブラウザを使ってインスタンスに接続します クラウド上にある AWS/EC2 インスタンスへの接続を確認します   1. AWS/EC2 の IP アドレス ワークショップの準備として、Splunk は AWS/EC2 に Ubuntu Linux インスタンスを用意しています。\nワークショップで使用するインスタンスにアクセスするには、ワークショップの講師が提供する Google Sheets のURLにアクセスしてください。\nAWS/EC2 インスタンスの検索には、本ワークショップの登録時にご記入いただいたお名前（姓名）を入力してください。\nワークショップのインスタンスに接続するためのIPアドレス、SSHコマンド（Mac OS、Linux、最新のWindowsバージョン用）、パスワードが表示されています。\nまた、ssh や putty で接続できない場合に使用するブラウザアクセスのURLも記載されています。「ブラウザ経由でEC2に接続する 」を参照してください。\nImportant\n可能であれば、SSH または Putty を使用してEC2インスタンスにアクセスしてください。 ワークショップで必要になるので、IPアドレスをメモしておいてください。   2. SSH (Mac OS/Linux/Windows 10) Mac や Linux、または Windows10 以上の端末から SSH を使ってワークショップに接続することができます。\nSSH を使用するには、お使いのシステムでターミナルを開き、ssh ubuntu@x.x.x.xと入力してください（x.x.x.xをステップ1で見つけたIPアドレスに置き換えてください）。\nAre you sure you want to continue connecting (yes/no/[fingerprint])? というプロンプトが表示されたら yes と入力してください。\nステップ1の Google Sheets に記載されているパスワードを入力してください。\nログインに成功すると、Splunk のロゴと Linux のプロンプトが表示されます。\nこれで ワークショップを開始する に進む準備が整いました。\n 3. SSH (Windows 10以上) 上記の手順はWindows 10でも同様で、コマンドはコマンドプロンプトかPowerShellで実行できます。 しかしWindowsはSSHを「オプション機能」として用意しているため、場合によっては有効化が必要です。\nSSHが有効化されているかどうか確認するには単純に ssh を実行してください。\nsshコマンドに関するヘルプテキスト（下のスクリーンショット）が表示されれば、実行可能です。\nもしこのスクリーンショットとは異なる結果が表示された場合は「OpenSSH クライアント」機能の有効化が必要です。\n「設定」メニューを開き「アプリ」をクリックします。「アプリと機能」セクションの「オプション機能」をクリックします。\nここでインストール済みの機能の一覧が表示されます。上部にプラスアイコンが付いた「機能の追加」ボタンがあるためクリックします。 検索欄で「OpenSSH」と入力し「OpenSSH クライアント」を探し、チェックし、インストールボタンをクリックします。\nこれで設定作業完了です。もしOpenSSH機能を有効にしてもインスタンスにアクセスできない場合、講師までご連絡ください\nこれで ワークショップを開始する 準備が整いました。\n 4. Putty (Windows 10以前の場合) ssh がプリインストールされていない場合や、Windows システムを使用している場合、putty がおすすめです。Putty は こちら からダウンロードできます。\nImportant\nPutty がインストールできない場合は、 ブラウザ経由でEC2に接続する で進めてください。\n  Putty を開き、Host Name (or IP address) の欄に、Google Sheets に記載されているIPアドレスを入力してください。\n名前を入力して Save を押すと、設定を保存することができます。\nインスタンスにログインするには、Open ボタンをクリックします。\n初めて AWS/EC2 ワークショップインスタンスに接続する場合は、セキュリティダイアログが表示されますので、Yes をクリックしてください。\n接続されたら、ubuntu としてログインし、パスワードは Google Sheets に記載されているものを使用します。\n接続に成功すると、以下のような画面が表示されます。\nこれで ワークショップを開始する 準備が整いました。\n 5. ブラウザ経由でEC2に接続する SSH（ポート22） の使用が禁止されている場合や、Putty がインストールできない場合は、Webブラウザを使用してワークショップのインスタンスに接続することができます。\nNote\nここでは、6501番ポートへのアクセスが、ご利用のネットワークのファイアウォールによって制限されていないことを前提としています。   Webブラウザを開き、http:/x.x.x.x:6501 （X.X.X.Xは Google Sheetsに記載されたIPアドレス）と入力します。\n接続されたら、ubuntu としてログインし、パスワードは Google Sheets に記載されているものを使用します。\n接続に成功すると、以下のような画面が表示されます。\n通常のSSHを使用しているときとは異なり、ブラウザセッションを使用しているときは、コピー＆ペースト を使うための手順が必要です。これは、クロスブラウザの制限によるものです。\nワークショップで指示をターミナルにコピーするように言われたら、以下のようにしてください。\n通常通り指示をコピーし、ウェブターミナルにペーストする準備ができたら、以下のように Paste from browser を選択します。\nすると、ウェブターミナルに貼り付けるテキストを入力するダイアログボックスが表示されます。\n表示されているテキストボックスにテキストを貼り付け、OK を押すと、コピー＆ペーストができます。\nNote\n通常のSSH接続とは異なり、Webブラウザには60秒のタイムアウトがあり、接続が解除されると、Webターミナルの中央に Connect ボタンが表示されます。\nこの Connect ボタンをクリックするだけで、再接続され、次の操作が可能になります。\n  これで ワークショップを開始する 準備が整いました。\n 6. Multipass (全員) AWSへはアクセスできないが、ローカルにソフトウェアをインストールできる場合は、「Multipassを使用する 」の手順に従ってください。\n  Putty のダウンロード  ↩︎\n   ","categories":"","description":"**5 分**\n","excerpt":"**5 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/initial-setup/","tags":"","title":"ワークショップ環境へのアクセス"},{"body":" Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules   1. Introduction Splunk Observability Cloud uses detectors, events, alerts, and notifications to keep you informed when certain criteria are met. For example, you might want a message sent to a Slack channel or to an email address for the Ops team when CPU Utilization has reached 95%, or when the number of concurrent users is approaching a limit that might require you to spin up an additional AWS instance.\nThese conditions are expressed as one or more rules that trigger an alert when the conditions in the rules are met. Individual rules in a detector are labeled according to criticality: Info, Warning, Minor, Major, and Critical.\n2. Creating a Detector In Dashboards click on your Custom Dashboard Group (that you created in the previous module) and then click on the dashboard name.\nWe are now going to create a new detector from a chart on this dashboard. Click on the bell icon on the Latency vs Load chart, and then click New Detector From Chart.\nIn the text field next to Detector Name, ADD YOUR INITIALS before the proposed detector name.\nNaming the detector\nIt’s important that you add your initials in front of the proposed detector name.\nIt should be something like this: XYZ’s Latency Chart Detector.   Click on Create Alert Rule   \nIn the Detector window, inside Alert signal, the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert.\nClick on Proceed to Alert Condition   \n 3. Setting Alert condition In Alert condition, click on Static Threshold and then on Proceed to Alert Settings   \nIn Alert Settings, enter the value 290 in the Threshold field. In the same window change Time on top right to past day (-1d).\n 4. Alert pre-flight check A pre-flight check will take place after 5 seconds. See the Estimated alert count. Based on the current alert settings, the amount of alerts we would have received in 1 day would have been 3.\nAbout pre-flight checks\nOnce you set an alert condition, the UI estimates how many alerts you might get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day.\nImmediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using the Splunk Observability Cloud.\nTo read more about detector previewing, please visit this link Preview detector alerts.   Click on Proceed to Alert Message   \n 5. Alert message In Alert message, under Severity choose Major.\nClick on Proceed to Alert Recipients   \nClick on Add Recipient and then on your email address displayed as the first option.\nNotification Services\nThat’s the same as entering that email address OR you can enter another email address by clicking on E-mail….\nThis is just one example of the many Notification Services the suite has available. You can check this out by going to the Integrations tab of the top menu, and see Notification Services.\n   6. Alert Activation Click on Proceed to Alert Activation   \nIn Activate… click on Activate Alert Rule   \nIf you want to get alerts quicker you edit the rule and lower the value from 290 to say 280.\nIf you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metrics from the last 1 hour.\nClick on the in the navbar and then click on Detectors. You can optionally filter for your initials.\nYou will see you detector listed here. If you don’t then please refresh your browser.\nCongratulations! You have created your first detector and activated it!\n","categories":"","description":"","excerpt":" Create a Detector from one of your charts Setting Alert conditions …","ref":"/observability-workshop/v4.41/imt/docs/detectors/creating/","tags":"","title":"Working with Detectors - Lab Summary"},{"body":" Deploy a NGINX ReplicaSet into your K3s cluster and confirm the discovery of your NGINX deployment. Run a load test to create metrics and confirm them streaming into Splunk Observability Cloud!   1. Start your NGINX Verify the number of pods running in the Splunk UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster.\nNote the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node!\nNow switch back to the default cluster node view by selecting the MAP tab and select your cluster again.\nIn your AWS/EC2 or Multipass shell session change into the nginx directory:\nChange Directory   cd ~/workshop/k3s/nginx   2. Create NGINX deployment Create the NGINX configmap1 using the nginx.conf file:\nKubectl Configmap Create  Kubectl Create Configmap Output   kubectl create configmap nginxconfig --from-file=nginx.conf configmap/nginxconfig created  Then create the deployment:\nKubectl Create Deployment  Kubectl Create Deployment Output   kubectl create -f nginx-deployment.yaml deployment.apps/nginx created service/nginx created  Next we will deploy Locust2 which is an open source tool used for creating a load test against NGINX:\nKubectl Create Deployment  Kubectl Create Deployment Output   kubectl create -f locust-deployment.yaml deployment.apps/nginx-loadgenerator created service/nginx-loadgenerator created  Validate the deployment has been successful and that the Locust and NGINX pods are running.\nIf you have the Splunk UI open you should see new Pods being started and containers being deployed.\nIt should only take around 20 seconds for the pods to transition into a Running state. In the Splunk UI you will have a cluster that looks like below:\nIf you select the WORKLOADS tab again you will now see that there is a new ReplicaSet and a deployment added for NGINX:\n Let’s validate this in your shell as well:\nKubectl Get Pods  Kubectl Get Pods Output   kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-77784c659c-ttmpk 1/1 Running 0 9m19s splunk-otel-collector-agent-249rd 1/1 Running 0 9m19s svclb-nginx-vtnzg 1/1 Running 0 5m57s nginx-7b95fb6b6b-7sb9x 1/1 Running 0 5m57s nginx-7b95fb6b6b-lnzsq 1/1 Running 0 5m57s nginx-7b95fb6b6b-hlx27 1/1 Running 0 5m57s nginx-7b95fb6b6b-zwns9 1/1 Running 0 5m57s svclb-nginx-loadgenerator-nscx4 1/1 Running 0 2m20s nginx-loadgenerator-755c8f7ff6-x957q 1/1 Running 0 2m20s   3. Run Locust load test Locust, an open source load generator, is available on port 8080 of the EC2 instance’s IP address. Open a new tab in your web browser and go to http://{==EC2-IP==}:8080/, you will then be able to see the Locust running.\nSet the Spawn rate to be 2 and click Start Swarming.\nThis will start a gentle continuous load on the application.\nAs you can see from the above screenshot, most of the calls will report a fail, this is expected, as we have not yet deployed the application behind it, however NGINX is reporting on your attempts and you should be able to see those metrics.\nValidate you are seeing those metrics in the UI by selecting Dashboards → Built-in Dashboard Groups → NGINX → NGINX Servers. Using the Overrides filter on k8s.cluster.name:, find the name of your cluster as returned by echo $(hostname)-k3s-cluster in the terminal.\n  A ConfigMap is an API object used to store non-confidential data in key-value pairs. Pods can consume ConfigMaps as environment variables, command-line arguments, or as configuration files in a volume. A ConfigMap allows you to decouple environment-specific configuration from your container images, so that your applications are easily portable. ↩︎\n What is Locust? ↩︎\n   ","categories":"","description":"","excerpt":" Deploy a NGINX ReplicaSet into your K3s cluster and confirm the …","ref":"/observability-workshop/v4.41/imt/docs/gdi/nginx/","tags":"","title":"Deploying NGINX in K3s"},{"body":"1. DNS and Services in Kubernetes The Domain Name System (DNS) is a mechanism for linking various sorts of information with easy-to-remember names, such as IP addresses. Using a DNS system to translate request names into IP addresses makes it easy for end-users to reach their target domain name effortlessly.\nMost Kubernetes clusters include an internal DNS service configured by default to offer a lightweight approach for service discovery. Even when pods and services are created, deleted, or shifted between nodes, built-in service discovery simplifies applications to identify and communicate with services on the Kubernetes clusters.\nIn short the DNS system for kubernetes will make create a DNS entry for each pod and services. In general a Pod has the following DNS resolution:\npod-name.my-namespace.pod.cluster-domain.example For example, if a Pod in the default namespace has the Pod name my_pod, and the domain name for your cluster is cluster.local, then the Pod has a DNS name:\nmy_pod.default.pod.cluster.local Any Pods exposed by a Service have the following DNS resolution available:\nmy_pod.service-name.my-namespace.svc.cluster-domain.example More information can be found here : DNS for Service and Pods\n2. Create OpenTelemetry Collector receiver for PHP/Apache Create a new file called otel-apache.yaml with the following contents:\notel-apache.yaml   agent:config:receivers:receiver_creator:receivers:smartagent/apache:rule:type == \"port\" \u0026\u0026 pod.name matches \"apache\" \u0026\u0026 port == 80config:type:collectd/apacheurl:http://php-apache.apache.svc.cluster.local/server-status?auto  3. Observation Rules in the OpenTelemetry config The above file contains an observation rule for Apache using the OTel receiver_creator. This receiver can instantiate other receivers at runtime based on whether observed endpoints match a configured rule.\nThe configured rules will be evaluated for each endpoint discovered. If the rule evaluates to true then the receiver for that rule will be started as configured against the matched endpoint.\nIn the file above we tell the OpenTelemetry agent to look for Pods that match the name apache and have port 80 open. Once found, the agent will configure an Apache receiver to read Apache metrics from the configured URL. Note, the K8s DNS based URL in the above YAML for the service.\nTo use this the new apache configuration, you can upgrade the existing Splunk OpenTelemetry Collector Helm chart with the following command:\nHelm Upgrade  Helm Upgrade Single Line   helm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$(hostname)-k3s-cluster\" \\ --set=\"splunkObservability.logsEnabled=true\" \\ --set=\"clusterReceiver.eventsEnabled=true\" \\ --set=\"splunkObservability.infrastructureMonitoringEventsEnabled=true\" \\ splunk-otel-collector-chart/splunk-otel-collector \\ --namespace splunk \\ -f otel-apache.yaml helm upgrade splunk-otel-collector --set=\"splunkObservability.realm=$REALM\" --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" --set=\"clusterName=$(hostname)-k3s-cluster\" --set=\"splunkObservability.logsEnabled=true\" --set=\"clusterReceiver.eventsEnabled=true\" --set=\"splunkObservability.infrastructureMonitoringEventsEnabled=true\" splunk-otel-collector-chart/splunk-otel-collector --namespace splunk -f otel-apache.yaml  4. Kubernetes ConfigMaps A ConfigMap is an object in Kubernetes consisting of key-value pairs which can be injected into your application. With a ConfigMap you can separate configuration from your Pods.\nThis way, you can prevent hardcoding configuration data. ConfigMaps are useful for storing and sharing non-sensitive, unencrypted configuration information.\nThe OpenTelemetry collector/agent uses ConfigMaps to store the configuration of the agent and the K8s Cluster receiver. You can/will always verify the current configuration of an agent after a change by running the following commands:\nkubectl get cm -n splunk  Workshop Question\nCan you identify the ConfigMap(s) used by the collector??   When you have list of Configmaps from the namespace, select the one for the otel-agent and view it with the following command:\nNote: The option -o yaml will print the content of the ConfigMap in a YAML format.\nkubectl get cm splunk-otel-collector-otel-agent -n splunk -o yaml  Workshop Question\nIs the content of otel-apache.yaml saved in the ConfigMap for the collector agent?   5. Create PHP/Apache Deployment YAML In the terminal window create a new file called php-apache.yaml and copy the following YAML into the file:\nphp-apache.yaml   apiVersion:apps/v1kind:Deploymentmetadata:name:php-apachespec:selector:matchLabels:run:php-apachereplicas:1template:metadata:labels:run:php-apachespec:containers:- name:php-apacheimage:rcastley/php-apache:latestports:- containerPort:80resources:limits:memory:\"16Mi\"cpu:\"8\"requests:memory:\"10Mi\"cpu:\"6\"---apiVersion:v1kind:Servicemetadata:name:php-apachelabels:run:php-apachespec:ports:- port:80selector:run:php-apache  6. Deploy PHP/Apache Save the above file and deploy the PHP/Apache application to the cluster.\nCreate the apache namespace:\nkubectl create namespace apache Deploy the PHP/Apache application:\nkubectl apply -f php-apache.yaml -n apache  Workshop Question\nUsing the Observability Kubernetes Navigator, can you find the status of the php-apache workload?   ","categories":"","description":"","excerpt":"1. DNS and Services in Kubernetes The Domain Name System (DNS) is a …","ref":"/observability-workshop/v4.41/tko/session-5/docs/deploy-apache/","tags":"","title":"Deploying PHP/Apache"},{"body":" Deploy the Online Boutique application into Kubernetes (K3s) Verify the application is running Generate some artificial traffic using Locust See APM metrics in the UI   1. Check your EC2 server This assumes you are running this after you have run the IMT workshop, and still have access to your ec2 instance. If this is the case, continue with paragraph 3. Deploy Online Boutique, otherwise if you have received a fresh instance, please run the first two (2) sections of Deploying the OpenTelemetry Collector in Kubernetes to get the system ready for the APM workshop, then continue with the next section.\n2. Deploy Online Boutique To deploy the Online Boutique application into K3s, run the apm-config script, then apply the deployment:\nDeploy Online Boutique  Deployment Output   cd ~/workshop/apm ./apm-config.sh kubectl apply -f deployment.yaml APM Only Deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created  In case of a message about a VARIABLE being unset\nPlease undeploy the APM environment first by running kubectl delete -f deployment.yaml Then export the variable as described in the guide/message, followed by rerunning the deployment script above.   To ensure the Online Boutique application is running:\nGet Pods  Get Pods Output   kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-849cf595bf-l7mnq 1/1 Running 0 31m splunk-otel-collector-agent-pxrgp 2/2 Running 0 31m productcatalogservice-8464cd56d-n8f89 1/1 Running 0 1m redis-cart-bcf44df97-djv6z 1/1 Running 0 1m checkoutservice-8558fd7b95-b9pn8 1/1 Running 0 1m shippingservice-7cc4bdd6f4-xsvnx 1/1 Running 0 1m recommendationservice-647d57fd44-l7tkq 1/1 Running 0 1m frontend-66c5d589d-55vzb 1/1 Running 0 1m emailservice-6ff5bbd67d-pdcm2 1/1 Running 0 1m paymentservice-6866558995-8xmf2 1/1 Running 0 1m currencyservice-8668d75d6f-mr68h 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-cr4pr 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-qjr4b 1/1 Running 0 1m rum-loadgen-deployment-58ccf7bd8f-fvb4x 1/1 Running 0 1m cartservice-7b58c88c45-xvxhq 1/1 Running 0 1m loadgenerator-6bdc7b4857-9kxjd 1/1 Running 2 (49s ago) 1m adservice-7b68d5b969-89ft2 1/1 Running 0 1m  Info\nUsually it should only take around 1min 30secs for the pods to transition into a Running state.    4. Validate in the UI In the Splunk UI click on Infrastructure this will bring you to the Infrastructure Overview dashboard, then click on Kubernetes.\nUse the Cluster dropdown so select your cluster, you should see the new pods started and containers deployed.\nWhen you click on your cluster in the Splunk UI you should have a view that looks like below:\nIf you select the WORKLOADS tab again you should now see that there are a number of Deployments and ReplicaSets:\n 5. View Online Boutique The Online Boutique is viewable on port 81 of the EC2 instance’s IP address. The IP address is the one you used to SSH into the instance at the beginning of the workshop.\nOpen your web browser and go to http://{==EC2-IP==}:81/ where you will then be able to see the Online Boutique running.\n","categories":"","description":"","excerpt":" Deploy the Online Boutique application into Kubernetes (K3s) Verify …","ref":"/observability-workshop/v4.41/apm/docs/online-boutique/deploy/","tags":"","title":"Deploying the Online Boutique in K3s"},{"body":"Please note to begin the following lab, you must have gone through the following:\n Download and place the yelp dataset in /var/appdata/ Obtain a Splunk Observability Cloud access key Clone this repository Access to a K8 environment (e.g. k3s on multipass) python3  Follow these steps if using O11y Workshop EC2 instances\n#note: verify yelp data files are present ll /var/appdata/yelp* export SPLUNK_ACCESS_TOKEN=\u003cyour access token\u003e export SPLUNK_REALM=\u003cyour realm\u003e export ACCESS_TOKEN=\u003cyour access token\u003e export REALM=\u003cyour realm\u003e export clusterName=\u003cyour-cluster\u003e git clone https://github.com/leungsteve/realtime_enrichment.git cd realtime_enrichment/workshop python3 -m venv rtapp-workshop source rtapp-workshop/bin/activate Follow these steps if you are using MULTIPASS:\n#IMPORTANT NOTE: #run this on your mac #run this on your multipass ubuntu VM (e.g. multipass shell \u003cvm name\u003e) #1. Yelp dataset placed in /var/appdata/ #extract then move the yelp dataset (json) to /var/appdata sudo mkdir -p /var/appdata/ sudo chmod 777 /var/appdata/ mv \u003cyelp*json\u003e /var/appdata/ ll /var/appdata/yelp* *output* -rw-r--r--@ 1 stevel staff 124380583 Jan 28 2021 /var/appdata/yelp_academic_dataset_business.json -rw-r--r--@ 1 stevel staff 6936678061 Jan 28 2021 /var/appdata/yelp_academic_dataset_review.json -rw-r--r--@ 1 stevel staff 3684505303 Jan 28 2021 /var/appdata/yelp_academic_dataset_user.json *output* #3. Copy Workshop files to /var/appdata/Workshop on your Mac cd /var/appdata #4. a K8 environment (e.g. k3s on multipass) #create a multipass VM., present the yelp dataset to the VM multipass launch --name test4cpu16gb --cpus 4 --mem 16Gb --disk 32GB #makes the yelp dataset available to your VM multipass mount /var/appdata test4cpu16gb multipass shell test4cpu16gb ubuntu@test4cpu8gb:~$ ll /var/appdata/yelp* -rw-r--r-- 1 ubuntu ubuntu 124380583 Jan 28 2021 /var/appdata/yelp_academic_dataset_business.json -rw-r--r-- 1 ubuntu ubuntu 6936678061 Jan 28 2021 /var/appdata/yelp_academic_dataset_review.json -rw-r--r-- 1 ubuntu ubuntu 3684505303 Jan 28 2021 /var/appdata/yelp_academic_dataset_user.json curl -sfL https://get.k3s.io | sh - curl -s https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash sudo mkdir -p ~/.kube sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config sudo chown `whoami`. ~/.kube/config echo 'export KUBECONFIG=~/.kube/config' \u003e\u003e ~/.bashrc source ~/.bashrc #5. python3 #recommended to create and work in a virtual environment (on your mac. not in multipass) python3 --version Python 3.10.0 cd Workshop python3 -m venv rtapp-workshop source rtapp-workshop/bin/activate #new prompt: #(rtapp-workshop)  ","categories":"","description":"","excerpt":"Please note to begin the following lab, you must have gone through the …","ref":"/observability-workshop/v4.41/tko/session-2/docs/getting_started/","tags":"","title":"GDI - Real Time Enrichment Workshop"},{"body":"Install The Open Telemetry Collector The OpenTelemetry Collector is the core component of instrumenting infrastructure and applications. Its role is to collect and send:\n Infrastructure metrics (disk, cpu, memory, etc) Application Performance Monitoring (APM) traces Profiling data Host and application logs  Splunk Observability Cloud offers wizards to walk you through the setup of the Collector on both your infrastructure and applications. By default, the wizard will only provide the commands to only install the collector.\nIf you have already completed the Splunk IMT workshop you can take advantage of the existing environment variables. Otherwise, create the ACCESS_TOKEN and REALM environment variables to use in the proceeding OpenTelemetry Collector install command. For instance, if your realm is us1, you would type export REALM=us1 and for eu0 type export REALM=eu0 etc.\nExport Variables   export ACCESS_TOKEN=\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e export REALM=\u003creplace_with_Splunk_Realm\u003e  Delete any existing OpenTelemetry Collectors\nIf you have completed the Splunk IMT workshop, please ensure you have deleted the collector running in Kubernetes before continuing. This can be done by running the following command: helm delete splunk-otel-collector.   We can then go ahead and install the Collector. There are two additional parameters passed to the install script, they are --with-instrumentation and --deployment-environment. The --with-instrumentation option the installer will install the agent from the Splunk distribution of OpenTelemetry Java, which is then loaded automatically when the Pet Clinic Java application starts up. No configuration required!\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\  sudo sh /tmp/splunk-otel-collector.sh --with-instrumentation --deployment-environment $(hostname)-petclinic --realm $REALM -- $ACCESS_TOKEN This command will download and setup the OpenTelemetry Collector. Once the install is completed, you can navigate to the Infrastructure page to see the data from your host, Infrastructure → My Data Center → Hosts.\nClick Add Filter    select host.name and type or select the hostname of your virtual machine. Once you see data flowing for your host, we are then ready to get started with the APM component.\n","categories":"","description":"","excerpt":"Install The Open Telemetry Collector The OpenTelemetry Collector is …","ref":"/observability-workshop/v4.41/pet-clinic/docs/imt/","tags":"","title":"Install the OpenTelemetry Collector"},{"body":"The Splunk OpenTelemetry Workshop will teach you how to level up your Observability practice by using the OpenTelemetry Collector and APM Instrumentation to emit industry standard telemetry from your infrastructure and applications.\nSource repo is here: https://github.com/splunk/otelworkshop\nRequirements Audience  Intermediate and advanced developers, devops, and SREs who have already set up their Splunk Observability Cloud account and have tried out integrations and dashboards Skill level should include setting up and troubleshooting Linux and Kubernetes environments as well as deploying applications written in current versions of Java, Python, Node. This workshop is designed to run as a single user, or be run in a small group (upwards of 6) along with a leader guiding the group. If running as a group, a pre-workshop prep call is necessary to ensure that all group members can spin up and/or access an Ubuntu Linux lab environment. Details are below.  Prerequisites  Completion of Splunk Observability Workshop which trains on using metrics/APM and charts/dashboards/alerts or equivalent devops/SRE skills Splunk Observability Cloud Account Ability to use a multi-terminal IDE i.e. Microsoft Visual Studio Code or equivalent Ability to spin up a VM or access a host with a Debian Linux environment with the following specs: Debian (i.e. Ubuntu) Linux environment with minimum 12G RAM and 20G disk w/ lightweight Kubernetes (Rancher k3s) installed OR your own k8s cluster. The Prep section has some tools to help build a local or AWS environment.  Document Conventions Variables from your Splunk Observability account are displayed like this: YOURVARIABLEHERE. I.e. to change your REALM to us1 change api.YOURREALMHERE.signalfx.com to api.us1.signalfx.com\n K8s = Kubernetes K3s = a lightweight Kubernetes from Rancher signalfx = Splunk Observability domain name/endpoint/technology name otel = OpenTelemetry  Workshop Agenda  (Optional) Build a local Lab Environment Ubuntu Sandbox on Mac or Windows OpenTelemetry Collector and APM Labs  Linux Host  Set up OpenTelemetry Collector Agent on a Linux Host OpenTelemetry APM Instrumentation on Java, Python, and Node apps   Kubernetes (k8s) Click to start at k8s labs  Set up OpenTelemetry Collector Agent on a k8s cluster OpenTelemetry APM Instrumentation on k8s on Java, Python k8s pods Manual APM Instrumentation for Java JVM Metrics Span processing with redaction example APM for Istio service mesh OpenTelemetry Collector configuration / troubleshooting Prometheus scraping and custom metrics Collectd: receive metrics from any platform Troubleshooting the Collector   Option: Docker workshop w/ Otel Collector and APM Examples    Disclaimers  This is not product documentation: Click for Official documentation Breaking changes to OpenTelemetry and Splunk services may occur- please submit issues on the GitHub repo if any are encountered These examples are not commercial products and are for experimentation and educational purposes only  ","categories":"","description":"","excerpt":"The Splunk OpenTelemetry Workshop will teach you how to level up your …","ref":"/observability-workshop/v4.41/otelw/introduction/","tags":"","title":"Introduction"},{"body":" Online BoutiqueアプリケーションをKubernetes(K3s)にデプロイします アプリケーションが動作していることを確認します Locustを使って人工的なトラフィックを生成します UI で APM のメトリクスを見ましょう   1. EC2サーバーを確認 これからの操作は、IMTワークショップを実行した後で、まだEC2インスタンスにアクセスできる状態であることを想定しています。 もしアクセスできる場合は、3. オンラインブティック に進みます。 新しいインスタンスを受け取った場合は、 Deploying the OpenTelemetry Collector in Kubernetes の最初の2つのセクションを実行して、システムをAPMワークショップのために準備し、次のセクションを続行してください。\n2. Online Boutiqueをデプロイする Online BoutiqueアプリケーションをK3sにデプロイするには、以下のデプロイメントを適用します。\nDeploy Online Boutique  Deployment Output   cd ~/workshop/apm ./apm-config.sh kubectl apply -f deployment.yaml APM Only Deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created  変数未セットに関するメッセージが表示された場合\nkubectl delete -f deployment.yaml コマンドを実行しAPM環境のデプロイ削除します。 次にガイド、メッセージに表示されていた変数をexportし上記のデプロイスクリプトを再実行します。   Online Boutique アプリケーションが起動していることを確認するには:\nGet Pods  Get Pods Output   kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-56585564cc-xclzj 1/1 Running 0 84s splunk-otel-collector-agent-hkshj 1/1 Running 0 84s svclb-frontend-external-c74n6 1/1 Running 0 53s currencyservice-747b74467f-xxrl9 1/1 Running 0 52s redis-cart-74594bd569-2jb6c 1/1 Running 0 54s adservice-6fb948b8c6-2xlrc 0/1 Running 0 53s recommendationservice-b5df8776c-sbt4h 1/1 Running 0 53s shippingservice-6d6f7b8d87-5lg9g 1/1 Running 0 53s svclb-loadgenerator-jxwct 1/1 Running 0 53s emailservice-9dd74d87c-wjdqr 1/1 Running 0 53s checkoutservice-8bcd56b46-bfj7d 1/1 Running 0 54s productcatalogservice-796cdcc5f5-vhspz 1/1 Running 0 53s paymentservice-6c875bf647-dklzb 1/1 Running 0 53s frontend-b8f747b87-4tkxn 1/1 Running 0 53s cartservice-59d5979db7-bqf64 1/1 Running 1 53s loadgenerator-57c8b84966-7nr4f 1/1 Running 3 53s  Info\n通常、ポッドがRunning状態に移行するのに1分30秒程度かかります。    3. UIで検証する Splunk UIでInfrastructure をクリックします。Infrastructure Overviewダッシュボードに遷移しますので、 Kubernetes をクリックします。\nCluster のドロップダウンを使用してクラスタを選択すると、新しいポッドが開始され、コンテナがデプロイされていることが確認できます。\nSplunk UI で Cluster をクリックすると、次のような画面が表示されているはずです。\nもう一度 WORKLOADS タブを選択すると、いくつかのデプロイメントとレプリカセットがあることがわかるはずです。\n 4. Online Boutique を閲覧する Online Boutique は、EC2インスタンスのIPアドレスの81番ポートで閲覧できます。このIPアドレスは、ワークショップの冒頭でインスタンスにSSH接続したときに使用したものと同じIPアドレスです。\nウェブブラウザを開き、 http://{==EC2-IP==}:81/ にアクセスすると、Online Boutique が起動しているのが確認できます。\n","categories":"","description":"","excerpt":" Online BoutiqueアプリケーションをKubernetes(K3s)にデプロイします アプリケーションが動作していることを確認し …","ref":"/observability-workshop/v4.41/ja/apm/docs/online-boutique/deploy/","tags":"","title":"K3s環境にOnline Boutiqueをデプロイする"},{"body":" NGINX ReplicaSet を K3s クラスタにデプロイし、NGINX デプロイメントのディスカバリーを確認します。 負荷テストを実行してメトリクスを作成し、Splunk Observability Cloudにストリーミングすることを確認します！   1. NGINX の起動 Splunk UI で WORKLOADS タブを選択して、実行中の Pod の数を確認します。これにより、クラスタ上のワークロードの概要がわかるはずです。\nデフォルトの Kubernetes Pod のうち、ノードごとに実行されている単一のエージェントコンテナに注目してください。この1つのコンテナが、このノードにデプロイされているすべての Pod とサービスを監視します！\n次に、MAP タブを選択してデフォルトのクラスタノードビューに戻し、再度クラスタを選択します。\nMultipass または AWS/EC2 のシェルセッションで、nginx ディレクトリに移動します。\nChange Directory   cd ~/workshop/k3s/nginx   2. NGINXのデプロイメント作成 NGINX の configmap1 を nginx.conf ファイルを使って作成します。\nKubectl Configmap Create  Kubectl Create Configmap Output   kubectl create configmap nginxconfig --from-file=nginx.conf configmap/nginxconfig created  続いて、デプロイメントを作成します。\nKubectl Create Deployment  Kubectl Create Deployment Output   kubectl create -f nginx-deployment.yaml deployment.apps/nginx created service/nginx created  次に、NGINXに対する負荷テストを作成するため、 Locust2 をデプロイします。\nKubectl Create Deployment  Kubectl Create Deployment Output   kubectl create -f locust-deployment.yaml deployment.apps/nginx-loadgenerator created service/nginx-loadgenerator created  デプロイメントが成功し、Locust と NGINX Pod が動作していることを確認しましょう。\nSplunk UI を開いていれば、新しい Pod が起動し、コンテナがデプロイされているのがわかるはずです。\nPod が実行状態に移行するまでには 20 秒程度しかかかりません。Splunk UIでは、以下のようなクラスタが表示されます。\nもう一度 WORKLOADS タブを選択すると、新しい ReplicaSet と NGINX 用のデプロイメントが追加されていることがわかります。\n これをシェルでも検証してみましょう。\nKubectl Get Pods  Kubectl Get Pods Output   kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-77784c659c-ttmpk 1/1 Running 0 9m19s splunk-otel-collector-agent-249rd 1/1 Running 0 9m19s svclb-nginx-vtnzg 1/1 Running 0 5m57s nginx-7b95fb6b6b-7sb9x 1/1 Running 0 5m57s nginx-7b95fb6b6b-lnzsq 1/1 Running 0 5m57s nginx-7b95fb6b6b-hlx27 1/1 Running 0 5m57s nginx-7b95fb6b6b-zwns9 1/1 Running 0 5m57s svclb-nginx-loadgenerator-nscx4 1/1 Running 0 2m20s nginx-loadgenerator-755c8f7ff6-x957q 1/1 Running 0 2m20s   3. Locust の負荷テストの実行 Locust はオープンソースの負荷テストツールで、EC2 インスタンスの IP アドレスの8080番ポートで Locust が利用できるようになりました。Webブラウザで新しいタブを開き、http://{==EC2-IP==}:8080/にアクセスすると、Locust が動作しているのが確認できます。\nSpawn rate を 2 に設定し、Start Swarming をクリックします。\nこれにより、アプリケーションに緩やかな連続した負荷がかかるようになります。\n上記のスクリーンショットからわかるように、ほとんどのコールは失敗を報告しています。これはアプリケーションをまだデプロイしていないため予想されることですが、NGINXはアクセス試行を報告しており、これらのメトリックも見ることができます。\nサイドメニューから Dashboards → Built-in Dashboard Groups → NGINX → NGINX Servers を選択して、UIにメトリクスが表示されていることを確認します。さらに Overrides フィルターを適用して、 k8s.cluster.name: に、ターミナルの echo $(hostname)-k3s-cluster で返されるクラスタの名前を見つけます。\n  ConfigMap とは、キーと値のペアで非機密データを保存するために使用される API オブジェクトです。Pod は、環境変数、コマンドライン引数、またはボリューム内の構成ファイルとして ConfigMap を利用することができます。ConfigMap を使用すると、環境固有の構成をコンテナイメージから切り離すことができるため、アプリケーションの移植が容易になります。 ↩︎\n Locust とは？ . ↩︎\n   ","categories":"","description":"","excerpt":" NGINX ReplicaSet を K3s クラスタにデプロイし、NGINX デプロイメントのディスカバリーを確認します。 負荷テストを …","ref":"/observability-workshop/v4.41/ja/imt/docs/gdi/nginx/","tags":"","title":"K3s に NGINX をデプロイする"},{"body":"Overview of the RUM Workshop The aim of this Splunk Real User Monitoring (RUM) workshop is to let you:\n  Shop for some fantastic items on the Online Boutique to create traffic, and create a number of RUM user sessions1 that you can view in the Splunk Observability Suite.\n  See an overview of the performance of all your application(s) in the Application Summary Dashboard (Both Mobile and Web based)\n  Examine the performance of a specific website or Mobile App with RUM metrics.\n  Investigate issues with your website and backend services.\n  (Optionally) See how to add RUM to your website.\n  In order to reach this goal, we will use an online boutique to order various products. Whilst shopping on the online boutique you will create what is called a User Session1.\nYou may encounter some issues with this web site, and you will use Splunk RUM to identify the issues, so they can be resolved by the developers.\nIf this a standalone RUM workshop, the workshop host will provide you with a URL for an online boutique store that has RUM enabled.\nIf you are running this session as part of the IMT/APM workshop you will be able to use your current online boutique store after we enable RUM.\nEach of these Online Boutiques are also being visited by a few synthetic users, this will allow us to generate more live data to be analyzed later.\n  A RUM Users session is a “recording” of a collection of user interactions on an application, basically collecting a website or app’s performance measured straight from the browser or Mobile App of the end user. To do this a small amount of JavaScript is embedded in each page. This script then collects data from each user as he or she explores the page, and transfers that data back for analysis. ↩︎\n   ","categories":"","description":"","excerpt":"Overview of the RUM Workshop The aim of this Splunk Real User …","ref":"/observability-workshop/v4.41/rum/overview/","tags":"","title":"Overview"},{"body":"Each step should be performed in a separate terminal window.\nMake sure your Ubuntu environment was prepared properly as described in the Preparation section.\nConfigure Environment Variables for Otel and Run Python Flask Server Open the first terminal window in your Linux instance and set up environment and run Python Flask server using auto-instrumentation:\n!!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the run-server.sh script below and add your initials to the environment i.e. change:\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=apm-workshop\nto export OTEL_RESOURCE_ATTRIBUTES=deployment.environment=sjl-apm-workshop\ncd ~/otelworkshop/host/python source run-server.sh You will see the server startup text when this is run.\nRun Python Client Application Open a new terminal window in your Linux instance and run the Python client to sent POST requests to the Flask server:\nRun the client Python app via the splunk-py-trace command to send requests to the Flask server:\n!!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the run-client.sh script below and add your initials to the environment i.e. change:\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=apm-workshop\nto export OTEL_RESOURCE_ATTRIBUTES=deployment.environment=sjl-apm-workshop\ncd ~/otelworkshop/host/python source run-client.sh The python-requests.py client will make calls to the flask server with a random short sleep time.\nYou can stop the requests with ++ctrl+c++\nValidate span are being sent Open a new terminal window in your Linux instance to check OpenTelemetry Collector Statistics to see that spans are being sent.\nlynx localhost:55679/debug/tracez will show the metrics and spans being gathered and sent by the Collector.\nLynx is a text browser that was installed during with the setup-tools. Enabling a web browser to access your environment will allow for a full web GUI.\nAPM Dashboard Traces / services will now be viewable in the APM dashboard. A new service takes about 90 seconds to register for the first time, and then all data will be available in real time.\nThe Environment pulldown will let you see the APM map associated with your individual environment that you set with your initials if this was done earlier.\nAdditionally span IDs will print in the terminal where flask-server.py is running. You can use ++ctrl+c++ to stop the requests and server any time.\nThe Python server application will be called: py-otel-flask-server and the client will be called py-otel-client.\nNavigate to Splunk Overvability -\u003e APM\nService map of this python demo\nClick on one of the peaks in the grey graph within “Services By Latency (P90)” on the right hand side and then click the trace to see spans. Also try out Tag Spotlight to see how application operations are broken down in a granular way. You can also try the Tags menu on top to search for a single trace or group of traces by key:value.\nTo learn more about traces and spans see the Splunk APM documentation\nWhere is the OpenTelemetry Instrumentation? The run-server.sh and run-client.sh scripts set up the environment variables for OpenTelemetry and invoke the Python auto instrumentation:\nspluk-py-trace is the auto instrumenting function that runs Python3 with the instrumentation that automatically emits spans from the Python app. No code changes are necessary. Splunk Observability Cloud has a Data Setup Wizard to guide through instrumentation setup.\nOpenTelemetry repo for Python is here.\n!!! important Leave the Flask server running you’ll need need this process for the next client examples in the workshop.\n","categories":"","description":"","excerpt":"Each step should be performed in a separate terminal window.\nMake sure …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_single_host/python/","tags":"","title":"Python- Deploy HTTP Server and Client"},{"body":" Visit the RUM landing page and and check the overview of the performance of all your RUM enabled applications with the Application Summary Dashboard (Both Mobile and Web based)   1. Visit the RUM Landing Page Login into your Splunk IMT/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your the RUM Landing Page.\nThe goal of this page is to give you in a single page, a clear indication of the health, performance and potential errors found in your application(s) and allow you to dive deeper into the information about your User Sessions collected from your web page/App. You will have a pane for each of your active RUM applications. (The view below is the default expanded view)\nIf you have multiple applications, (which will be the case when every attendee is using their own ec2 instance for the RUM workshop), the pane view may be automatically reduced by collapsing the panes as shown below:\nYou can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.\nFirst find the right application to use for the workshop:\nIf you are participating in a stand alone RUM workshop, the workshop leader will tell you the name of the application to use, in the case of a combined workshop, it will follow the naming convention we used for IMT and APM and use the ec2 node name as a unique id like jmcj-rum-app as shown as the last app in the screenshot above.\n2. Configure the RUM Application Summary Dashboard Header Section RUM Application Summary Dashboard consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:\n A drop down for the Time Window you’re reviewing (You are looking at the past 15 minutes by default) A drop down to select the Environment1 you want to look at. This allows you to focus on just the subset of applications belonging to that environment, or Select all to view all available. A drop down list with the various Apps being monitored. You can use the one provided by the workshop host or select your own. This will focus you on just one application. A drop down to select the Source, Browser or Mobile applications to view. For the Workshop leave All selected. A hamburger menu located at the right of the header allowing you to configure some settings of your Splunk RUM application. (We will visit this in a later section).  For the workshop lets do a deeper dive into the Application Summary screen in the next section: Check Health Browser Application\n   A deployment environment is a distinct deployment of your system or application that allows you to set up configurations that don’t overlap with configurations in other deployments of the same application. Separate deployment environments are often used for different stages of the development process, such as development, staging, and production.A common application deployment pattern is to have multiple, distinct application environments that don’t interact directly with each other but that are all being monitored by Splunk APM or RUM: for instance, quality assurance (QA) and production environments, or multiple distinct deployments in different datacenters, regions or cloud providers.  ↩︎\n   ","categories":"","description":"","excerpt":" Visit the RUM landing page and and check the overview of the …","ref":"/observability-workshop/v4.41/rum/docs/rum-landing/","tags":"","title":"Reviewing the RUM Landing Page"},{"body":" RUMランディングページにアクセスし、アプリケーションサマリーダッシュボード（モバイルおよびウェブベース）でRUM対応アプリケーションすべてのパフォーマンスの概要を確認します。   1. RUMランディングページにアクセス Splunk IMT/APM/RUM ウェブサイトにログインします。左側のメニューバーから RUM を選択します 。RUMのランディングページが表示されます。\nこのページの目的は、アプリケーションの健全性、パフォーマンス、潜在的なエラーを1つのページで明確に示し、Webページ/アプリケーションから収集したユーザーセッションに関する情報をより深く掘り下げることができるようにすることです。アクティブなRUMアプリケーションごとにペインが表示されます。(以下のビューは、デフォルトの拡張ビューです。）\n複数のアプリケーションがある場合（RUMワークショップの参加者全員が自分のec2インスタンスを使用する場合）、以下のようにペインを折りたたむことで自動的にペインビューが縮小される場合があります。\nアプリケーション名の前にある左側の赤い矢印で強調されている または アイコン(アプリケーションの種類が モバイル か ブラウザー かによる）をクリックすると、RUM Application Summryビューをフルダッシュボードに展開することが可能です。\nまず、ワークショップに使用する適切なアプリケーションを見つけます。\n単独のRUMワークショップに参加する場合、ワークショップ講師が使用するアプリケーションの名前を教えてくれます。複合ワークショップの場合、IMTとAPMで使用した命名規則に従い、上のスクリーンショットの一番最後に表示されているように、 jmcj-rum-app のようにユニークIDとしてEC2ノードの名前に従います。\n2. RUM Application Summary ダッシュボード のヘッダーセクションを設定する RUM Application Summary ダッシュボードは5つの主要なセクションで構成されています。一つ目は選択ヘッダーで、多くのオプションを設定/フィルタリングすることができます。\n 表示対象時間のための タイム・ウィンドウ ドロップダウン（デフォルトでは過去15分間） Environment1 を選択するためのドロップダウン。これにより、その環境に属するアプリケーションのサブセットのみにフォーカスすることができます。 監視対象のさまざまな Apps を含むドロップダウンリスト。ワークショップ講師によって提供されたものを使用するか、あなた自身のものを選択することができます。これにより、1つのアプリケーションにフォーカスすることができます。 Source 、 Browser 、 Mobile アプリケーションを選択するためのドロップダウン。ワークショップの場合は、 All を選択したままにしてください。 ヘッダーの右側にあるハンバーガーメニューで、Splunk RUM アプリケーションのいくつかの設定を行うことができます(これについては、後のセクションで説明します)。  次のセクションでは「Application Summary」画面をより深く掘り下げて説明します。 Check Health Browser Application    デプロイメント環境（Environment）は、システムまたはアプリケーションの個別のデプロイメントであり、同じアプリケーションの他のデプロイメントの設定と重複しないように設定を行うことができます。開発、ステージング、本番など、開発プロセスの段階ごとに別々のデプロイメント環境を使用することがよくあります。  一般的なアプリケーションのデプロイメントパターンとして、互いに直接影響し合わない複数の異なるアプリケーション環境を持ち、それらをすべて Splunk APM または RUM で監視することがあります。たとえば、品質保証 (QA) 環境と本番環境、または異なるデータセンター、地域、クラウドプロバイダーでの複数の異なるデプロイメントが挙げられます。 ↩︎\n   ","categories":"","description":"","excerpt":" RUMランディングページにアクセスし、アプリケーションサマリーダッシュボード（モバイルおよびウェブベース）でRUM対応アプリケーションすべ …","ref":"/observability-workshop/v4.41/ja/rum/docs/rumlanding/","tags":"","title":"RUMランディングページの確認"},{"body":"Splunk APM is a NoSample™ Full-fidelity application performance monitoring and troubleshooting solution for cloud-native, microservices-based applications.\nBy collecting all traces, instead of a sampled subset, no anomaly goes undetected. Whether a user experiences an error or longer-than-usual latency, you’ll be able to know and act on it within seconds. Furthermore, not all bad behavior results in errors — as your developers create new applications they need to know whether their canary releases provide the expected results. Only by collecting all trace data will you ensure that your cloud-native applications behave the way they are supposed to.\nInfrastructure and application performance are interdependent. To see the full picture, Splunk APM provides seamless correlation between cloud infrastructure and the microservices running on top of it. If your application acts out because of memory leakage, a noisy neighbor container or any other infrastructure-related issue, Splunk will let you know. To complete the picture, in-context access to Splunk logs and events enable deeper troubleshooting and root-cause analysis.\n","categories":"","description":"","excerpt":"Splunk APM is a NoSample™ Full-fidelity application performance …","ref":"/observability-workshop/v4.41/apm/","tags":"","title":"Introduction"},{"body":"Splunk APM は、クラウドネイティブなマイクロサービスベースのアプリケーション向けの NoSample™ で 完全忠実なアプリケーションパフォーマンスモニタリングおよびトラブルシューティングソリューションです。\nサンプリングされた部分的な情報ではなく、すべてのトレースを収集することで、異常が検出されないことはありません。ユーザーがエラーを経験しても、通常より長いレイテンシーを経験しても、数秒以内にそれを知り、対処することができます。ときに、悪い動作がエラーとして扱われないこともあります。開発者が新しいアプリケーションを作成する際には、そのカナリアリリースが期待通りの結果をもたらすかどうかを知る必要があります。すべてのトレースデータを収集して、初めて、クラウドネイティブアプリケーションが想定通り動作していることを確信できるようになります。\nインフラとアプリケーションのパフォーマンスは相互に依存しています。全体像を把握するために、Splunk APM はクラウドのインフラとその上で動作するマイクロサービスをシームレスに相関付けます。メモリリーク、ノイズの多い隣のコンテナ、その他のインフラ関連の問題が原因でアプリケーションが動作した場合、Splunk がすぐに知らせてくれます。さらに、Splunk のログやイベントにインコンテキストでアクセスすることで、より詳細なトラブルシューティングや根本原因の分析が可能になります。\n","categories":"","description":"","excerpt":"Splunk APM は、クラウドネイティブなマイクロサービスベースのアプリケーション向けの NoSample™ で 完全忠実なアプリケーシ …","ref":"/observability-workshop/v4.41/ja/apm/","tags":"","title":"はじめに"},{"body":"","categories":"","description":"**15 分**\n\nSplunk APMの使い方概要\n","excerpt":"**15 分**\n\nSplunk APMの使い方概要\n","ref":"/observability-workshop/v4.41/ja/apm/docs/using-splunk-apm/","tags":"","title":"Splunk APMを利用する"},{"body":" APM Overview - RED metrics Using the Service Map Introduction to Tag Spotlight Example Traces Contextual Links to Infra  1. Traces and Spans explained A trace is a collection of spans that share the same trace ID, representing a unique transaction handled by your application and its constituent services.\nEach span has a name, representing the operation captured by this span, and a service name, representing within which service the operation took place.\nAdditionally, spans may reference another span as their parent, defining the relationships between the operations captured in the trace that were performed to process that transaction.\nEach span contains a lot of information about the method, operation, or block of code that it captures, including:\n the operation name the start time of the operation with microsecond precision how long the operation took to execute, also with microsecond precision the logical name of the service on which the operation took place the IP address of the service instance on which the operation took place  ","categories":"","description":"**15 minutes**\n\nAn overview of how to use Splunk APM\n","excerpt":"**15 minutes**\n\nAn overview of how to use Splunk APM\n","ref":"/observability-workshop/v4.41/apm/docs/using-splunk-apm/","tags":"","title":"Using Splunk APM"},{"body":" チャートからディテクターを作成する アラート条件を設定する プリフライトチェックを実行する ミューティングルールを設定する   1. はじめに Splunk Observability Cloud では、ディテクター（検出器）、イベント、アラート、通知を使用して、特定の条件が満たされたときに情報を提供することができます。たとえば、CPU使用率が95%に達したときや、同時ユーザー数が制限値に近づいてAWSインスタンスを追加で立ち上げなければならない可能性があるときに、Slack チャンネルや Ops チームのメールアドレスにメッセージを送信したいと考えるでしょう。\nこれらの条件は1つまたは複数のルールとして表現され、ルール内の条件が満たされたときにアラートが発生します。ディテクターに含まれる個々のルールは、重要度に応じてラベル付けされています。Info、Warning、Minor、Major、Criticalとなっています。\n2. ディテクターの作成 Dashboards で、前のモジュールで作成した Custom Dashboard Group をクリックし、ダッシュボードの名前をクリックします。\nこのチャートから、新しいディテクターを作成していきます。Latency vs Load チャート上のベルのアイコンをクリックし、 New Detector From Chart をクリックします。\nDetector Name の横にあるテキストフィールドで、提案されたディテクター名の最初に、あなたのイニシャル を追加してください。\nディテクターの名前を決める\n提案されたディテクター名の前に自分のイニシャルを追加することをお忘れなく。\n次のような名前にしてください: XYZ’s Latency Chart Detector    Create Alert Rule    をクリックします。\nDetector ウィンドウの Alert signal の中で、アラートするシグナルは Alert on 欄に青のベルが表示されています。このベルは、どのシグナルがアラートの生成に使用されているかを示しています。\n Proceed to Alert Condition    をクリックします。\n 3. アラート条件の設定 Alert condition で、Static Threshold をクリックし、 Proceed to Alert Settings    をクリックしてください。\nAlert Settings で、 Threshold フィールドに値 290 を入力します。同じウィンドウで、右上の Time を過去1日（-1d）に変更します。\n 4. プリフライトチェックの警告 5秒後にプリフライトチェックが行われます。Estimated alert count に、アラート回数の目安が表示されます。現在のアラート設定では、1日に受信するアラート量は 3 となります。\nプリフライトチェックについて\nアラート条件を設定すると、UIは現在の設定に基づいて、右上に設定された時間枠（ここでは過去1日）の中で、どのくらいのアラートが発生するかを予測します。\nすぐに、プラットフォームは現在の設定でシグナルの分析を開始し、「プリフライトチェック」と呼ばれる作業を行います。これにより、プラットフォーム内の過去のデータを使用してアラート条件をテストし、設定が妥当であり、誤って大量のアラートを発生させないようにすることができます。Splunk Observability Cloud を使用してのみ利用できるシンプルかつ非常に強力な方法で、アラートの設定から推測作業を取り除くことができます。\nディテクターのプレビューについての詳細は、こちらのリンクをご覧ください。 Preview detector alerts    Proceed to Alert Message    をクリックし、次に進みます。\n 5. アラートメッセージ Alert message の Severity で Major を選択します。\n Proceed to Alert Recipients    をクリックします。\nAdd Recipient（受信者の追加）をクリックし、最初の選択肢として表示されているメールアドレスをクリックします。\n通知サービス\nこれは、そのメールアドレスを入力したときと同じです。または、E-mail… をクリックして別のメールアドレスを入力することもできます。\nこれは、予め用意されている多くの Notification Services の一例です。全てを確認するには、トップメニューの Integrations タブに移動し、Notification Services を参照してください。\n   6. アラートの有効化  Proceed to Alert Activation    をクリックします。\nActivivate… で Activate Alert Rule    をクリックします。\nアラートをより早く取得したい場合は、Alert Settings をクリックして、値を 290 から 280 に下げてみてください。\nTime を -1h に変更すると、過去1時間のメトリクスに基づいて、選択した閾値でどれだけのアラートを取得できるかを確認できます。\nナビバーにある ボタンをクリックして、その後 Detectors をクリックすると、ディテクターの一覧が表示されます。あなたのイニシャルでフィルタして、作成したディテクターを確認しましょう。表示されない場合は、ブラウザをリロードしてみてください。\nおめでとうございます！ 最初のディテクターが作成され、有効化されました。\n","categories":"","description":"","excerpt":" チャートからディテクターを作成する アラート条件を設定する プリフライトチェックを実行する ミューティングルールを設定する   1. はじ …","ref":"/observability-workshop/v4.41/ja/imt/docs/detectors/creating/","tags":"","title":"ディテクターを利用する"},{"body":"RUM ワークショップの概要 このSplunk Real User Monitoring (RUM) ワークショップの目的は以下の通りです。\n  素敵な商品を買えるOnline Boutiqueサイトでトラフィックを発生させ、 RUM ユーザーセッション1を作成し、Splunk Observability Suiteで確認します\n  Application Summary Dashboard (モバイル、Web両方) で アプリケーション全体のパフォーマンスの概要を確認します\n  RUM メトリクスで、特定のWebサイトやモバイルアプリのパフォーマンスを検証します\n  Webサイトやバックエンドサービスの問題を調査します\n  (オプション) あなたのWebサイトへの RUM の追加方法を学びます\n  この目的のため、Online Boutiqueで様々な商品を注文することになります。Online Boutiqueで買い物をするとき、あなたはユーザーセッション1と呼ばれるものを作成します。\nこの Web サイトでいくつかの問題に遭遇することがなりますが、Splunk RUM を使用して問題を特定し、開発者が問題を解決できるようにします。\nRUM 単体のワークショップの場合、ワークショップ講師が RUM を導入しているOnline BoutiqueのURLをお知らせします。\nIMT/APM ワークショップの一環としてこのセッションを実施する場合、講師側でRUMを有効にした後、現在お使いのOnline Boutiqueを使用することが可能です。\nこれらのOnline Boutiqueには、それぞれ数人の合成ユーザー（シミュレートされたユーザーセッション）が訪問しており、これによって、後で分析するためのより多くのライブデータを生成することができます。\n  RUM ユーザーセッションは、アプリケーション上でのユーザーインタラクションの「記録」であり、基本的にはエンドユーザーのブラウザまたはモバイルアプリケーションから直接測定されたウェブサイトまたはアプリケーションのパフォーマンスを収集します。これを行うために、各ページに数行のJavaScriptが埋め込まれています。このスクリプトは、各ユーザーがページを探索する際にデータを収集し、解析のためにそのデータを転送します。 ↩︎\n   ","categories":"","description":"","excerpt":"RUM ワークショップの概要 このSplunk Real User Monitoring (RUM) ワークショップの目的は以下の通りです。 …","ref":"/observability-workshop/v4.41/ja/rum/overview/","tags":"","title":"概要"},{"body":".NET CORE example uses the .NET http client to get non-responding URL so makes valid traces with 403 status code\nContainerized with these instructions from Microsoft\nFor .NET Core 2.1\ncd ~/otelworkshop/k8s/dotnet21 Deploy:\nsource deploy-client.sh Delete deployment:\nsource delete-all.sh ","categories":"","description":"","excerpt":".NET CORE example uses the .NET http client to get non-responding URL …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/examples/dotnet21/","tags":"","title":".Net Core 2.1"},{"body":" Get familiar with the UI and options available from this landing page Identify Page Views/Errors and Request/Errors and Java Script Errors in a single view  Check the Web Vitals metrics and any Detector that has fired for in relation to your Browser Application   1. Application Summary Dashboard Overview 1.1. Header Bar As seen in the previous section the RUM Application Summary Dashboard consists of 5 major sections. The first section is the selection header, where you can collapse the Pane via the Browser icon or the \u003e in front of the application name, which is jmcj-rum-app in the example below. It also provides access to the Application Overview page if you click the link with your application name which is jmcj-rum-app in the example below.\nFurther, you can also open the Application Overview or App Health Dashboard via the triple dot menu on the right.\nFirst use the View Dashboard link to open the Browser App Health Dashboard which should open in a new tab. Then switch back to original RUM tab, and then use the Open Application Overview link, or click on the name of the app to launch the Application Overview dashboard.\nWe will looking at the Application Overview and Browser App Health Dashboards in detail in the following sections.\n2. Application Overview The RUM Application Overview Dashboard is focused on providing you with at a glance overview of the status of your application.\n2.1. Page Views / Errors \u0026 Network Requests / Errors The first section shows Page Views / Errors, \u0026 Network Requests and Errors charts show the quantity and trend of these issues in your application. This could be Javascript errors, or failed network calls to back end services.\nIn the example above you can see that there are no failed network calls in the Network chart, but in the Page View chart you can see that a number of pages do experience some errors. These are often not visible for regular users, but can seriously impact the performance of your web site.\nYou can see the count of the Page Views / Network Requests / Errors by hovering over the charts.\n2.2. JavaScript Errors With the second section of the RUM Application Summary Dashboard we are showing you an overview of the JavaScript errors occurring in your application, along with a count of each error.\nIn the example above you can see there are three JavaScript errors, one that appears 29 times in the selected time slot, and the other two each appear 12 times.\nIf you click on one of the errors a pop-out opens that will show a summary (below) of the errors over time, along with a Stack Trace of the JavaScript error, giving you an indication of where the problems occurred. (We will see this in more detail in one of the following sections)\n2.3. Web Vitals The third section of the RUM Application Summary Dashboard is showing you the crucial (google) Web Vitals, three metrics, that are used by Google in its ranking system, and give a very good indication of the speed of your site for your end users.\nAs you can see our site is well behaved and scores Good for all three Metrics. These metrics can be used to identify the effect changes to your application have, and help you improve the performance of your site.\nIf you click on any of the Metrics shown in the Web Vitals pane you will be taken to the corresponding Tag Spotlight Dashboard. e.g. clicking on the Largest Contentful Paint (LCP) chartlet, you will be taken to a dashboard similar to the screen shot below, that gives you timeline and table views for how this metric has performed. This should allow you to spot trends and identify where the problem may be more common, such as an OS or browser version, .\n2.4. Most Recent Detectors The fourth and final section of the RUM Application Summary Dashboard is focused on providing you an overview of any detector that has triggered for your application. We have created a detector for this screen shot but your pane will be empty for now, but we will add some detectors to your site and make sure they are triggered in one of the next sections.\nIn the screen shot you can see we have a critical alert for the RUM Aggregated View Detector, and a Count, how often this alert has triggered in the selected time window. If you happen to have an alert listed, you can click on the name of the Alert (that is shown as a blue link) and you will be taken to the Alert Overview page showing the details of the alert (Note: this will move you away from the current page, Please use the Back option of your browser to return to the overview page).\n Please take a few minutes to experiment with the RUM Application Summary Dashboard and the underlying chart and dashboards before going on to the next section.\n","categories":"","description":"","excerpt":" Get familiar with the UI and options available from this landing page …","ref":"/observability-workshop/v4.41/rum/docs/browser-app-summary/","tags":"","title":"Check Browser Applications health at a glance"},{"body":"Objective: Learn how to efficiently deploy complex infrastructure components such as Kafka and MongoDB to demonstrate metrics collection with Splunk O11y IM integrations\nDuration: 15 Minutes\nScenario A prospect uses Kafka and MongoDB in their environment. Since there are integrations for these services, you’d like to demonstrate this to the prospect. What is a quick and efficient way to set up a live environment with these services and have metrics collected?\n  Where can I find helm charts?\n Google “myservice helm chart” https://artifacthub.io/ (Note: Look for charts from trusted organizations, with high star count and frequent updates)    Review Apache Kafka packaged by Bitnami. We will deploy the helm chart with these options enabled:\n replicaCount=3 metrics.jmx.enabled=true metrics.kafka.enabled=true deleteTopicEnable=true    Review MongoDB(R) packaged by Bitnami. We will deploy the helm chart with these options enabled:\n version 12.1.31 metrics.enabled=true global.namespaceOverride=default auth.rootUser=root auth.rootPassword=splunk auth.enabled=false    Install Kafka and MongoDB with helm charts\nhelm repo add bitnami https://charts.bitnami.com/bitnami helm install kafka --set replicaCount=3 --set metrics.jmx.enabled=true --set metrics.kafka.enabled=true --set deleteTopicEnable=true bitnami/kafka helm install mongodb --set metrics.enabled=true bitnami/mongodb --set global.namespaceOverride=default --set auth.rootUser=root --set auth.rootPassword=splunk --set auth.enabled=false --version 12.1.31 ###verify the helm chart installation helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION kafka default 1 2022-11-14 11:21:36.328956822 -0800 PST deployed kafka-19.1.3 3.3.1 mongodb default 1 2022-11-14 11:19:36.507690487 -0800 PST deployed mongodb-12.1.31 5.0.10 ###verify the helm chart installation kubectl get pods NAME READY STATUS RESTARTS AGE kafka-exporter-595778d7b4-99ztt 0/1 ContainerCreating 0 17s mongodb-b7c968dbd-jxvsj 0/2 Pending 0 6s kafka-1 0/2 ContainerCreating 0 16s kafka-2 0/2 ContainerCreating 0 16s kafka-zookeeper-0 0/1 Pending 0 17s kafka-0 0/2 Pending 0 17s   Use information for each Helm chart and Splunk O11y Data Setup to generate values.yaml for capturing metrics from Kafka and MongoDB. Note: values.yaml for the different services will be passed to the Splunk Helm Chart at installation time. These will configure the OTEL collector to capture metrics from these services.\n  References:\n  Apache Kafka packaged by Bitnami\n  Configure application receivers for databases » Apache Kafka\n  Kafkametricsreceiver\n  Example kafka.values.yaml:\notelAgent:config:receivers:receiver_creator:receivers:smartagent/kafka:rule:type == \"pod\" \u0026\u0026 name matches \"kafka\"config:#endpoint: '`endpoint`:5555'port:5555type:collectd/kafkaclusterName:sl-kafkaotelK8sClusterReceiver:k8sEventsEnabled:trueconfig:receivers:kafkametrics:brokers:kafka:9092protocol_version:2.0.0scrapers:- brokers- topics- consumersservice:pipelines:metrics:receivers:#- prometheus- k8s_cluster- kafkametrics  Example mongodb.values.yaml:\notelAgent:config:receivers:receiver_creator:receivers:smartagent/mongodb:rule:type == \"pod\" \u0026\u0026 name matches \"mongo\"config:type:collectd/mongodbhost:mongodb.default.svc.cluster.localport:27017databases:[\"admin\",\"O11y\",\"local\",\"config\"]sendCollectionMetrics:truesendCollectionTopMetrics:true  Example zookeeper.values.yaml:\notelAgent:config:receivers:receiver_creator:receivers:smartagent/zookeeper:rule:type == \"pod\" \u0026\u0026 name matches \"kafka-zookeeper\"config:type:collectd/zookeeperhost:kafka-zookeeperport:2181  Install the Splunk OTEL helm chart:\nexport SPLUNK_ACCESS_TOKEN=\u003cyour access token\u003e export SPLUNK_REALM=\u003cyour realm\u003e export clusterName=\u003cyour cluster name\u003e cd ../otel_yamls helm repo add splunk-otel-collector-chart https://splunk.github.io/splunk-otel-collector-chart helm repo update helm install --set provider=' ' --set distro=' ' --set splunkObservability.accessToken=$SPLUNK_ACCESS_TOKEN --set clusterName=$clusterName --set splunkObservability.realm=$SPLUNK_REALM --set otelCollector.enabled='false' --set splunkObservability.logsEnabled='true' --set gateway.enabled='false' --values kafka.values.yaml --values mongodb.values.yaml --values zookeeper.values.yaml --values alwayson.values.yaml --values k3slogs.yaml --generate-name splunk-otel-collector-chart/splunk-otel-collector   Verify that the Kafka, MongoDB and Splunk OTEL Collector helm charts are installed. Note that names may differ.\n$helm list NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION kafka default 1 2021-12-07 12:48:47.066421971 -0800 PST deployed kafka-14.4.1 2.8.1 mongodb default 1 2021-12-07 12:49:06.132771625 -0800 PST deployed mongodb-10.29.2 4.4.10 splunk-otel-collector-1638910184 default 1 2021-12-07 12:49:45.694013749 -0800 PST deployed splunk-otel-collector-0.37.1 0.37.1 $ kubectl get pods NAME READY STATUS RESTARTS AGE kafka-zookeeper-0 1/1 Running 0 18m kafka-2 2/2 Running 1 18m mongodb-79cf87987f-gsms8 2/2 Running 0 18m kafka-1 2/2 Running 1 18m kafka-exporter-7c65fcd646-dvmtv 1/1 Running 3 18m kafka-0 2/2 Running 1 18m splunk-otel-collector-1638910184-agent-27s5c 2/2 Running 0 17m splunk-otel-collector-1638910184-k8s-cluster-receiver-8587qmh9l 1/1 Running 0 17m   Verify that out of the box dashboards for Kafka, MongoDB and Zookeeper are populated in the Infrastructure Monitor landing page. Drill down into each component to view granular details for each service.\n  Infrastructure Monitoring Landing page:\n  K8 Navigator:\n  MongoDB Dashboard:\n  Kafka Dashboard:\n      ","categories":"","description":"","excerpt":"Objective: Learn how to efficiently deploy complex infrastructure …","ref":"/observability-workshop/v4.41/tko/session-2/docs/deploy/","tags":"","title":"Deploy complex environments and capture meterics"},{"body":"Create aws ecs create-cluster --cluster-name YOURCLUSTERNAMEHERE\naws ecs register-task-definition --cli-input-json file://YOURTASKDEFINITIONHERE.json\naws ecs create-service --cluster test-cluster --service-name signalfx-demo --task-definition signalfx-demo:1 \\\n--desired-count 1 --launch-type \"FARGATE\" \\\n--network-configuration \"awsvpcConfiguration={subnets=[subnet-YOURSUBNETIDHERE],securityGroups=[sg-YOURSECURITYGROUPIDHERE],assignPublicIp=ENABLED}\"\nMonitor aws ecs list-task-definitions\naws ecs list-clusters\naws ecs list-services --cluster YOURCLUSTERNAMEHERE\naws ecs describe-services --cluster YOURCLUSTERNAMEHERE --services YOURSERVICENAMEHERE\nCleanup aws ecs deregister-task-definition --task-definition FAMILYNAMEHERE:VERSIONHERE\naws ecs delete-service --cluster YOURCLUSTERNAMEHERE --service YOURSERVICENAMEHERE --force\naws ecs delete-cluster --cluster YOURCLUSTERNAMEHERE\necs-cli down --cluster YOURCLUSTERNAMEHERE --region YOURREGIONHERE\n","categories":"","description":"","excerpt":"Create aws ecs create-cluster --cluster-name YOURCLUSTERNAMEHERE\naws …","ref":"/observability-workshop/v4.41/otelw/appendix/ecs-cli-commands/","tags":"","title":"ECS-CLI Commands"},{"body":"1. Editing a chart Select the SAMPLE CHARTS dashboard and then click on the three dots ... on the Latency histogram chart, then on Open (or you can click on the name of the chart which here is Latency histogram).\nYou will see the plot options, current plot and signal (metric) for the Latency histogram chart in the chart editor UI.\nIn the Plot Editor tab under Signal you see the metric demo.trans.latency we are currently plotting.\nYou will see a number of Line plots. The number 18 ts indicates that we are plotting 18 metric time series in the chart.\nClick on the different chart type icons to explore each of the visualizations. Notice their name while you swipe over them. For example, click on the Heat Map icon:\nSee how the chart changes to a heat map.\nNote\nYou can use different charts to visualize your metrics - you choose which chart type fits best for the visualization you want to have.\nFor more info on the different chart types see Choosing a chart type.   Click on the Line chart type and you will see the line plot.\n2. Changing the time window You can also increase the time window of the chart by changing the time to Past 15 minutes by selecting from the Time dropdown.\n3. Viewing the Data Table Click on the Data Table tab.\nYou now see 18 rows, each representing a metric time series with a number of columns. These columns represent the dimensions of the metric. The dimensions for demo.trans.latency are:\n demo_datacenter demo_customer demo_host  In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics.\nIf you move your cursor over the lines in the chart horizontally you will see the data table update accordingly. If you click on one of the lines in the chart you will see a pinned value appear in the data table.\n Now click on Plot editor again to close the Data Table and let’s save this chart into a dashboard for later use!\n","categories":"","description":"","excerpt":"1. Editing a chart Select the SAMPLE CHARTS dashboard and then click …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/editing/","tags":"","title":"Editing charts"},{"body":"1. Kubernetes Resources Especially in Production Kubernetes Cluster CPU and Memory are considered precious resources.And the Cluster operators will normally require you to specify in the deployment the amount of CPU and Memory your Pod or service will require, so they can have the cluster automatically manage on which Node(s) your solution will be placed.\nYou do this by placing a Resource section in the deployment of you application/Pod\nExample:\nresources:requests:# Request are the expected amount of CPU \u0026 memory for normal use memory:\"10Mi\"# Requesting 10 Megabyte of memorycpu:\"0.5\"# Requesting half of Core of a CPUlimits:# Maximum amount of CPU \u0026 memory for peek use memory:\"16Mi\"# Maximum allowed 16 Megabyte of memorycpu:\"1\"# Maximum of 1 core of CPU allowed at for peek useMore information can be found here : Resource Management for Pods and Containers\nIf your application or pod will go over the limits set in your deployment, Kubernetes will kill and restart your Pod to protect the other applications on the Cluster.\nAn other scenario that you will run into is when there is not enough Memory or CPU on a Node. In that case, the cluster will try to reschedule your pod(s) on a different node with more space.\nIf that fails, or if there is not enough space when you deploy your application, the Cluster will put your workload/deployment in schedule mode until there are enough room on any of the available nodes to deploy the pods according their limits.\n2. Fix PHP/Apache Deployment Workshop Question\nBefore we start, let’s check the current status of the PHP/Apache deployment. Which Auto-Detect detector has fired?   To fix the PHP/Apache deployment, edit the deployment and reduce the CPU resources further:\nkubectl edit deployment php-apache -n apache Find the resources section and reduce the CPU limits to 1 and the CPU requests to 0.5 e.g.\nresources:limits:memory:\"16Mi\"cpu:\"1\"requests:memory:\"10Mi\"cpu:\"0.5\"Save the above changes. The deployment will be updated and the pods will be restarted. You can validate the changes have been applied by running the following command:\n3. Validate the changes kubectl describe deployment php-apache -n apache Validate the pod is now running in Splunk Observability Cloud.\nWorkshop Question\nIs the Apache Web Servers dashboard showing any data?\nTip: Don’t forget to use filters and timeframes to narrow down your data.\n  ","categories":"","description":"","excerpt":"1. Kubernetes Resources Especially in Production Kubernetes Cluster …","ref":"/observability-workshop/v4.41/tko/session-5/docs/fix-apache/","tags":"","title":"Fix PHP/Apache Issue"},{"body":"1. Generate traffic The Online Boutique deployment contains a container running Locust that we can use to generate load traffic against the website to generate metrics, traces and spans.\nLocust is available on port 82 of the EC2 instance’s IP address. Open a new tab in your web browser and go to http://{==EC2-IP==}:82/, you will then be able to see the Locust running.\nSet the Spawn rate to be 2 and click Start Swarming, this will start a gentle continous load on the application.\n Now go to Dashboards → All Dashboards → APM Services → Service.\nFor this we need to know the name of your application environment. In this workshop all the environments use: {==hostname==}-apm-env.\nTo find the hostname, on the AWS/EC2 instance run the following command:\nEcho Hostname  Output Example   echo $(hostname)-apm-env  bdzx-apm-env   Select your environment you found in the previous step then select the frontend service and set time to Past 15 minutes.\nWith this automatically generated dashboard you can keep an eye out for the health of your service(s) using RED (Rate, Error \u0026 Duration) metrics. It provides various performance related charts as well as correlated information on the underlying host and Kubernetes pods (if applicable).\nTake some time to explore the various charts in this dashboard\n 2. Verify Splunk APM metrics In the left hand menu card click on APM this will bring you to the APM Overview dashboard:\nSelect the Explore on the right hand side and select your environment you found before and set the time to 15 minutes. This will show you the automatically generated Dependency/Service Map for the Online Boutique application.\nIt should look similar to the screenshot below:\nThe legend at the bottom of the page explains the different visualizations in the Dependency/Service Map.\n Service requests, error rate and root error rate. Request rate, latency and error rate  Also in this view you can see the overall Error and Latency rates over time charts.\n3. OpenTelemetry Dashboard Once the Open Telemetery Collector is deployed the platform will automatically provide a built in dashboard display OpenTelemetry Collector metrics.\nFrom the top left hamburger menu, select Dashboards → OpenTelemetry Collector, scroll all the way to the bottom of the page and validate metrics and spans are being sent:\n4. OpenTelemetry zpages To debug the traces being sent you can use the zpages extension. zpages are part of the OpenTelemetry collector and provide live data for troubleshooting and statistics. They are available on port 55679 of the EC2 instance’s IP address. Open a new tab in your web browser and enter in http://{==EC2-IP==}:55679/debug/tracez, you will then be able to see the zpages output.\nAlternatively, from your shell prompt you can run a text based browser:\nLynx Command   lynx http://localhost:55679/debug/tracez   ","categories":"","description":"","excerpt":"1. Generate traffic The Online Boutique deployment contains a …","ref":"/observability-workshop/v4.41/apm/docs/online-boutique/locust/","tags":"","title":"Generate traffic using Locust"},{"body":"","categories":"","description":"**15 minutes**\n","excerpt":"**15 minutes**\n","ref":"/observability-workshop/v4.41/imt/docs/gdi/","tags":"","title":"Get Data In"},{"body":"Make sure that you still have the Python Flask server from the Python Lab running. If you accidentally shut it down follow steps from the Python lab to restart the Python Flask server.\nStart in the Java example directory Open a new terminal window\ncd ~/otelworkshop/host/java Download Otel Java Instrumentation Download Splunk OpenTelemetry Java Auto-instrumentation to /opt:\nsource install-java-otel.sh Run the Java HTTP requests client Run the Java client example which uses OKHTTP requests to the Python Flask Server:\n!!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the run-client.sh script below and add your initials to the environment i.e. change:\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=apm-workshop\nto export OTEL_RESOURCE_ATTRIBUTES=deployment.environment=sjl-apm-workshop\nsource run-client.sh You will see requests printed to the terminal.\nAPM Dashboard Traces/services will now be viewable in the APM dashboard. A new service takes about 90 seconds to register for the first time, the Python and n all data will be available in real time.\nAdditionally the requests made by Java will print in the terminal where flask-server.py is running. You can use ++ctrl+c++ to stop the requests and server any time.\nYou should now see a new Java requests service alongside the Python one.\nWhere is the OpenTelemetry Instrumentation? In the run-client.sh script the java command:\njava \\ -Dexec.executable=\"java\" \\ -Dotel.resource.attributes=service.name=java-otel-client,deployment.environment=apm-workshop \\ -javaagent:/opt/splunk-otel-javaagent.jar \\ -jar ./target/java-app-1.0-SNAPSHOT.jar The splunk-otel-javaagent.jar file is the automatic OpenTelemetry instrumentation that will emit spans from the app. No code changes are necessary! The otel. resources set up the service name Aand environment. Config details can be found here\nSplunk’s OpenTelmetry autoinstrumentation for Java is here\n","categories":"","description":"","excerpt":"Make sure that you still have the Python Flask server from the Python …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_single_host/java/","tags":"","title":"Java- Deploy HTTP Client"},{"body":"1. トラフィックを発生させる Online Boutique のデプロイメントには、Locust が動作するコンテナが含まれており、これを使用してウェブサイトに対する負荷トラフィックを生成し、メトリクス、トレース、スパンを生成することができます。\nLocust は、EC2インスタンスのIPアドレスの82番ポートで利用できます。ウェブブラウザで新しいタブを開き、 http://{==EC2-IP==}:82/ にアクセスすると、Locust が動作しているのが確認できます。\nSpawn rate を 2 に設定し、Start Swarming をクリックすると、アプリケーションに緩やかな負荷がかかり続けます。\n それでは、Dashboards → All Dashboards → APM Services → Service を開きましょう。\nこのためには、アプリケーションの Environment 名を知る必要があります。このワークショップでは、{==hostname==}-apm-env のような Environment 名で定義されています。\nホスト名を調べるには、AWS/EC2インスタンス上で以下のコマンドを実行します:\nEcho Hostname  Output Example   echo $(hostname)-apm-env  bdzx-apm-env   前のステップで見つけた Environment を選択し、「frontend」サービスを選択し、時間を「Past 15 minutes」に設定します。\nこの自動生成されたダッシュボードでは、RED (Rate, Error \u0026 Duration) メトリクスを使用して、サービスの状態を監視することができます。このダッシュボードでは、パフォーマンスに関連したさまざまなチャートのほか、基盤となるホストやKubernetesポッド（該当する場合）の相関情報も提供されます。\nダッシュボードの様々なチャートを見てみましょう。\n 2. Splunk APM のメトリクスを確認する 画面左のメニューから「APM」 をクリックするとAPM Overviewダッシュボードが表示されます。\n右側の Explore を選択し、先ほど見つけた Environment を選択し、時間を15分に設定します。これにより、自動的に生成されたOnline BoutiqueアプリケーションのDependency/Service Mapが表示されます。\n以下のスクリーンショットのように表示されます:\nページの下部にある凡例では、依存関係/サービスマップでの表記について説明しています。\n サービスリクエスト、エラーレート、ルートエラーレート。 リクエストレート、レイテンシー、エラーレート  また、このビューでは、全体的なエラー率とレイテンシー率のタイムチャートを見ることができます。\n3. OpenTelemetry ダッシュボード Open Telemetery Collector がデプロイされると、プラットフォームは自動的に OpenTelemetry Collector のメトリクスを表示するダッシュボードを作成します。\n左上のハンバーガーメニューから、 Dashboards → OpenTelemetry Collector を選択し、メトリクスとスパンが送信されていることを確認しましょう。\n4. OpenTelemetry zpages 送信されたトレースをデバッグするには、zpages 拡張機能を使用できます。zpages は OpenTelemetry Collector の一種で、トラブルシューティングや統計用のライブデータを提供します。これらは、EC2インスタンスのIPアドレスのポート 55679 で利用できます。Webブラウザで新しいタブを開き、 http://{==EC2-IP==}:55679/debug/tracez と入力すると、zpages の出力を見ることができます。\nまた、シェルプロンプトから、テキストベースのブラウザを実行することもできます。\nLynx Command   lynx http://localhost:55679/debug/tracez   ","categories":"","description":"","excerpt":"1. トラフィックを発生させる Online Boutique のデプロイメントには、Locust が動作するコンテナが含まれており、これを …","ref":"/observability-workshop/v4.41/ja/apm/docs/online-boutique/locust/","tags":"","title":"Locustでトラフィックを発生させる"},{"body":" Online Boutiqueのアドレスを探します Online Boutiqueのウェブショップで買い物しトラフィックを生成させます   1. RUMが有効化されたOnline BoutiqueのURL 前のセクションで説明したように、RUMホスト上で動作するOnline Boutiqueを使用します。 RUMのみのワークショップに参加される方は、使用するシステムは既に準備されていますので、RUMインスタンスのURLを受け取った後、セクション4 Online Boutiqueを使ってシステムに負荷を与える まで進むことができます。\n2. RUM Access Token の入手 APMワークショップでサービスをインストールしました。これから、RUM機能もデプロイメントに追加していきます。\nまず、RUM Authorization スコープを持つ RUM_ACCESS_TOKEN を取得する必要があります。ワークショップのRUM Access Tokenは、 settings メニューボタンをクリックし、 Access Tokens を選択することで見つけることができます。\n講師が使用するように指示したRUMワークショップトークン（例： O11y-Workshop-RUM-TOKEN ）を展開し、 Show Token をクリックしてトークンを表示します。 Copy    ボタンをクリックし、クリップボードにコピーしてください。 Default トークンは使用しないでください。トークンのAuthorization ScopeがRUMであることを確認してください。\n自分のトークンを作らないでください\nこのワークショップのために、皆さんが行う演習に適した設定をしたRUM Tokenを作成ししています。   進行中のシェルスクリプトで環境変数 RUM_TOKEN を作成し、デプロイメントをパーソナライズします。\nExport Variables   export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e  3. RUMを組み込んだOnline Boutiqueのデプロイ EC2インスタンスのkubernetes（K3s）にOnline Boutiqueのアプリケーションをデプロイするには、元のデプロイメントを削除し、RUM用のapm configスクリプトを実行し、RUMのデプロイメントを適用します。\nDeploy Online Boutique with RUM  Partial Deployment Output   cd ~/workshop/apm kubectl delete -f deployment.yaml ./apm-config.sh -r kubectl apply -f deployment.yaml ...... Adding RUM_TOKEN to deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created  変数未セットに関するメッセージが表示された場合\nkubectl delete -f deployment.yaml コマンドを実行しAPM環境のデプロイ削除します。 次にガイド、メッセージに表示されていた変数をexportし上記のデプロイスクリプトを再実行します。   4. Online Boutiqueを使ってシステムに負荷を与える 皆さんと一緒にOnline Boutiqueに接続し買い物をシミュレートする合成ユーザーもいます。これにより、複数の場所からのトラフィックが発生し、よりリアルなデータが得られます。\nワークショップ講師からURLを受け取っているはずです。 新しいWebブラウザを立ち上げ http://{==RUM-HOST-EC2-IP==}:81/ にアクセスするとRUMが有効化されたOnline Boutiqueが表示されます。\n5. トラフィックを発生させる この演習の目的は、RUMが有効化されたOnline Boutiqueを閲覧し、さまざまな商品と数量の組み合わせで購入することです。 さらに別のブラウザやスマートフォンからアクセスすることもできます。\nこれにより複数のセッションが作成され、調査することができます。じっくりと吟味して、いろいろな商品を購入しカートに入れてください。\nHome Barista Kitよくないですか？… ショッピングを楽しんでください！\n","categories":"","description":"","excerpt":" Online Boutiqueのアドレスを探します Online Boutique …","ref":"/observability-workshop/v4.41/ja/rum/showcase/","tags":"","title":"Online BoutiqueでのRUMの利用"},{"body":"Log in to your Splunk Observability account to identify token/realm For individuals and groups- allow 30-45 minutes of prep time to identify account credentials and prepare a lab environment. When running as a group we recommend doing a separate prep meeting before running the workshop together.\nCheck your Splunk Observability Account (your welcome email has this link) and identify your TOKEN and REALM - these are available in the profile menu in your Splunk Observability account. Note that the realm component i.e. us1 may be different for your account based on how you signed up.\nHow to find realm:\nSplunk Observability Menu -\u003e Your Name -\u003e Account Settings\nHow to find token:\nCreate Lab Environment Splunk Observability is for server environments. This workshop uses Ubuntu Linux as the lab server environment. You can use any Ubuntu platform - bare metal, VM, or cloud VM.\nRecommended Environment For optimal learning we recommend that you use a fresh cloud VM running Ubuntu with minimum 12GB RAM and 20GB disk space.\nSplunk provdes AWS EC2 setup/bootstrap scripts via Terraform. Also, cloud-init YAML files are available for Multipass.\nIf you chose your own Ubuntu machine, you can set it up with the Workshop software with this command:\nbash \u003c(curl -s https://raw.githubusercontent.com/signalfx/otelworkshop/master/setup-tools/ubuntu.sh) How To Build An Ubuntu VM on your Windows or Mac PC If you cannot procure a cloud VM, you can create an Ubuntu Linux environment on a Mac or PC and install the necessary software components\nMac OS Install Homebrew:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Make sure Homebrew is fully upgraded:\nbrew upgrade Results should be at least 1.5:\nbrew --version We will use Multipass as a hypervisor for Mac:\nbrew cask install multipass If needed, further instructions are here. Do one final brew upgrade before spinning up VM:\nbrew upgrade Windows Follow Multipass Windows installation instructions\nLaunch Multipass Ubuntu VM Create your VM called “primary”:\nmultipass launch -n primary -d 20G -m 12G -c4 This will download Ubuntu and may take a few minutes the first time.\nBasic multipass commands:\n Shell into VM: multipass shell primary Exit VM: exit  To manage multipass VM:\n multipass stop primary stops the VM multipass delete primary deletes the VM from the hypervisor multipass purge purges created images but leaves the ubuntu template intace  Install OTel Workshop A bootstrap script will install everything needed and clone this repo.\nThis will take up to 10 minutes to execute- leave it running until complete.\nmultipass shell primary Once in your Multipass Ubuntu VM:\nbash \u003c(curl -s https://raw.githubusercontent.com/signalfx/otelworkshop/master/setup-tools/ubuntu.sh) Key OTel APM concepts Moving parts that make APM happen in OpenTelemetry:\n Application Spans: OpenTelemetry instrumentation causes spans to be emitted by your applications OpenTelmetry auto-instrumentation (no code changes) for most languages is availabile but you can use any framework/library that emits spans in formats accepted by the Otel Collector i.e zipkin, OpenTracing, or OpenTelemetry. The spans are received by the OpenTelemetry Collector which both doubles as an infrastructure metrics collection agent and a telemetry processor. The Collector then forwards all telemetry (metrics/traces/logs) to Splunk Observability Cloud. Instructructure metrics: Infrastructure metrics are collected by your OpenTelemetry Collector which is observing the application’s host or container cluster. The infrastructure agent is lightweight, open source, real-time, and designed for microservices, containers, and cloud as well as on premise servers or cloud virtual machines. Application spans will be sent to the OpenTelemetry Collector running on a host or k8s pod to correlate APM with host/cluster metrics. The Collector then relays the spans to Splunk Observability Cloud APM where they will be assembled into traces. The APM spans flow in real time and there is no sampling. Pre-made default Service Dashboards with application metrics for each app will appear once spans are received by Splunk APM. The APM view has directed troubleshooting. Environment variables control the setup of APM. These names vary based on instrumentation but they always include:  Endpoint: destination to send spans Service name: the name of the application as you want it to appear in a service map Environment: a value for segmenting betwen dev/prod etc. Can be set with instrumentation and not necessarily as part of an ENV variable.    ","categories":"","description":"","excerpt":"Log in to your Splunk Observability account to identify token/realm …","ref":"/observability-workshop/v4.41/otelw/setup/","tags":"","title":"Preparation"},{"body":"Service Map Click on paymentservice in the service map and select version from the breakdown drop down filter underneath paymentservice. This will filter our service map by the custom span tag version.\nYou will now see the service map has been updated like the below screenshot to show the different versions of the paymentservice.\n","categories":"","description":"","excerpt":"Service Map Click on paymentservice in the service map and select …","ref":"/observability-workshop/v4.41/apm/docs/using-splunk-apm/service_map/","tags":"","title":"Service Map"},{"body":" Find the Web address of your workshop hosts Online Boutique Generate traffic by shopping for bargains on your workshop hosted Online Boutique web shop.   1. URL of RUM enabled Online Boutique As discussed in the previous section we are going to use an Online Boutique running on a RUM host. If you’re participating in a RUM only workshop, after you have received the RUM instance URL, you can continue to Section 4: Using the Online Boutique to generate load on your system as the system your going to use is already prepared.\n2. Obtain RUM Access Token As part of the overall workshop you have installed services for the APM Workshop. We are now going to add the RUM capability to the deployment as well.\nThe first thing we need to do is obtain a RUM_ACCESS_TOKEN with a RUM Authorization scope. You can find the workshop RUM Access Token by clicking on the settings menu button and then selecting Access Tokens.\nExpand the RUM workshop token that your host has instructed you to use e.g. O11y-Workshop-RUM-TOKEN, then click on Show Token to expose your token. Click the Copy    button to copy to clipboard. Please do not use the Default token! Make sure the token has RUM as its Authorization Scope.\nPlease do not attempt to create your own token\nWe have created a RUM Token specifically for this workshop with the appropriate settings for the exercises you will be performing   Create the RUM_TOKEN environment variable to use in the proceeding shell script to personalize your deployment.\nExport Variables   export RUM_TOKEN=\u003creplace_with_O11y-Workshop-RUM-TOKEN\u003e  3. Deploy RUM based Online Boutique To deploy the Online Boutique application into your EC2 instance kubernetes (K3s) installation delete the original deployment, then run the apm config script for RUM, then apply the RUM deployment:\nDeploy Online Boutique with RUM  Partial Deployment Output   cd ~/workshop/apm kubectl delete -f deployment.yaml ./apm-config.sh -r kubectl apply -f deployment.yaml ...... Adding RUM_TOKEN to deployment deployment.apps/recommendationservice created service/recommendationservice created deployment.apps/productcatalogservice created service/productcatalogservice created deployment.apps/cartservice created service/cartservice created deployment.apps/adservice created service/adservice created deployment.apps/paymentservice created service/paymentservice created deployment.apps/loadgenerator created service/loadgenerator created deployment.apps/shippingservice created service/shippingservice created deployment.apps/currencyservice created service/currencyservice created deployment.apps/redis-cart created service/redis-cart created deployment.apps/checkoutservice created service/checkoutservice created deployment.apps/frontend created service/frontend created service/frontend-external created deployment.apps/emailservice created service/emailservice created deployment.apps/rum-loadgen-deployment created  In case of a message about a VARIABLE being unset\nPlease undeploy the APM environment by running kubectl delete -f deployment.yaml Before exporting the variable as described in the guide and rerunning the deployment script above.   4. Using the Online Boutique to generate load on your system, We are all connected to an Online Boutique, together with some synthetic users who are also shopping for this session. This will create more traffic from multiple locations, making the data more realistic.\nYou should have received the correct URL from your workshop host at this point. Open a new web browser and go to http://{==RUM-HOST-EC2-IP==}:81/ where you will then be able to see the RUM enabled Online Boutique running.\n5. Generate traffic The goal of this exercise is for you to browse the RUM enabled Online Boutique and buy different products and different quantities. For extra credit, you may even use the url from different browsers or from your smartphone.\nThis will create multiple sessions to investigate. Take your time to examine and buy the various products and put them in your cart:\nDoesn’t that HOME BARISTA KIT look tempting?… Your time to start shopping now!\n","categories":"","description":"","excerpt":" Find the Web address of your workshop hosts Online Boutique Generate …","ref":"/observability-workshop/v4.41/rum/showcase/","tags":"","title":"Showcase of RUM with the Online Boutique"},{"body":"Splunk Synthetic Monitoring offers the most comprehensive and in-depth capabilities for uptime and web performance optimization as part of the only complete observability suite, Splunk Observability Cloud.\nEasily set up monitoring for APIs, service endpoints and end-user-experience. With Splunk Synthetic monitoring, go beyond basic uptime and performance monitoring and focus on proactively finding and fixing issues, optimizing web performance, and ensuring customers get the best user experience.\nWith Splunk Synthetic Monitoring you can:\n Detect and resolve issues fast across critical user flows, business transactions and API endpoints Prevent web performance issues from affecting customers with an intelligence web optimization engine And improve performance of all page resources and third-party dependencies  ","categories":"","description":"","excerpt":"Splunk Synthetic Monitoring offers the most comprehensive and in-depth …","ref":"/observability-workshop/v4.41/synthetics/","tags":"","title":"Introduction"},{"body":"Splunk Synthetic Monitoring は、完全なオブザーバビリティスイートである Splunk Observability Cloud の一部として、アップタイムと Webパフォーマンスの最適化のための最も包括的で詳細な機能を提供します。\nAPI、サービスエンドポイント、エンドユーザーエクスペリエンスの監視を簡単に設定できます。Splunk Synthetic Monitoringを使用すれば、基本的な稼働時間やパフォーマンスの監視にとどまらず、問題の発見と修正、Web パフォーマンスの最適化、顧客が最高のユーザーエクスペリエンスを得られるようにすることに注力することができます。\nSplunk Synthetic Monitoringによって得られるもの:\n 重要なユーザーフロー、ビジネストランザクション、APIエンドポイントにおける問題を迅速に検出し解決 インテリジェンスなWeb最適化エンジンで、Webパフォーマンスの問題が顧客に影響を与えることを防止 すべてのページリソースとサードパーティの依存関係のパフォーマンスを向上  ","categories":"","description":"","excerpt":"Splunk Synthetic Monitoring は、完全なオブザーバビリティスイートである Splunk Observability …","ref":"/observability-workshop/v4.41/ja/synthetics/","tags":"","title":"はじめに"},{"body":"Spring PetClinic Application First thing we need to setup APM is… well, an application. For this exercise, we will use the Spring Pet Clinic application. This is a very popular sample java application built with Spring framework (Springboot).\nNext we will clone the PetClinic repository, then we will compile, build, package and test the application.\ngit clone https://github.com/spring-projects/spring-petclinic Change into the spring-petclinic directory:\ncd spring-petclinic Start a MySQL database for Pet Clinic to use:\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/mysql:5.7.8 Next, run the maven command to compile/build/package Pet Clinic:\n./mvnw package -Dmaven.test.skip=true  Information\nThis will take a few minutes the first time you run, maven will download a lot of dependencies before it actually compiles the app. Future executions will be a lot shorter.   Once the compilation is complete, you can run the application with the following command:\njava \\ -Dotel.service.name=$(hostname)-petclinic.service \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql If you check the logs of the Splunk OpenTelemetry collector you will see that the collector automatically detected the application running and auto-instrumented it. You can view the logs using the following command:\nsudo tail -f /var/log/syslog You can validate if the application is running by visiting http://\u003cVM_IP_ADDRESS\u003e:8080. Now generate some traffic, click around, generate errors, add visits, etc. Then you can visit the Splunk APM UI and examine the application components, traces, etc. Hamburger Menu → APM → Explore.\nOnce your validation is complete you can stop the application by pressing Ctrl-c .\nTo enable CPU and Memory Profiling on the application we can start the application by passing splunk.profiler.enabled=true and for metrics pass splunk.metrics.enabled=true. Make sure the application is stopped and run the following command to enable metrics and profiling.\njava \\ -Dotel.service.name=$(hostname)-petclinic.service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Let’s go visit our application again to generate some traffic http://\u003cVM_IP_ADDRESS\u003e:8080. Click around, generate errors, add visits, etc. Then you can visit the Splunk APM UI and examine the application components, traces, profiling, DB Query performance and metrics Hamburger Menu → APM → Explore.\nOnce your validation is complete you can stop the application by pressing Ctrl-c .\nAdding Resource Attributes to Spans Resource attributes can be added to every reported span. For example version=0.314. A comma separated list of resource attributes can also be defined e.g. key1=val1,key2=val2.\nLet’s launch the Pet Clinic again using a new resource attribute. Note, that adding resource attributes to the run command will override what was defined when we installed the collector. So, we also need to specify our deployment.environment resource attribute along with our new resource attribute. Below you will see we are setting deployment.environment=$(hostname)-petclinic and version=0.314.\njava \\ -Dotel.service.name=$(hostname).service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -Dotel.resource.attributes=deployment.environment=$(hostname)-petclinic,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Go back to the application and generate some more traffic. Then, back in the Splunk APM UI we can drill down on a recent trace and see the new version attribute in a span.\n","categories":"","description":"","excerpt":"Spring PetClinic Application First thing we need to setup APM is… …","ref":"/observability-workshop/v4.41/pet-clinic/docs/apm/","tags":"","title":"Zero Configuration Java application"},{"body":"1. チャートの編集 Sample Data ダッシュボードにある Latency histogram チャートの3点 ... をクリックして、Open をクリックします（または、チャートの名前をクリックしてください、ここでは Latency histogram です）。\nチャートエディターのUIには、Latency histogram チャートのプロットオプション、カレントプロット、シグナル（メトリック）が表示されます。\nPlot Editor タブの Signal には、現在プロットしている demo.trans.latency というメトリックが表示されます。\nいくつかの Line プロットが表示されます。18 ts という数字は、18個の時系列メトリックをチャートにプロットしていることを示しています。\n異なるチャートタイプのアイコンをクリックして、それぞれの表示を確認してください。スワイプしながらその名前を確認してください。例えば、ヒートマップのアイコンをクリックします。\nチャートがヒートマップに変わります。\nNote\n様々なチャートを使用してメトリクスを視覚化することができます。自分が望む視覚化に最も適したチャートタイプを選択してください。\n各チャートタイプの詳細については、 Choosing a chart type を参照してください。\n  チャートタイプの Line をクリックすると、線グラフが表示されます。\n2. タイムウィンドウの変更 また、Time ドロップダウンから Past 15 minutes に変更することで、チャートの時間枠を変更することができます。\n3. データテーブルの表示 Data Table タブをクリックします。\n18行が表示され、それぞれがいくつかの列を持つ時系列メトリックを表しています。これらの列は、メトリックのディメンションを表しています。demo.trans.latency のディメンジョンは次のとおりです。\n demo_datacenter demo_customer demo_host  demo_datacenter 列では、メトリクスを取得している2つのデータセンター、Paris と Tokyo があることがわかります。\nグラフの線上にカーソルを横に移動させると、それに応じてデータテーブルが更新されるのがわかります。チャートのラインの1つをクリックすると、データテーブルに固定された値が表示されます。\n ここでもう一度 Plot editor をクリックしてデータテーブルを閉じ、このチャートをダッシュボードに保存して、後で使用しましょう。\n","categories":"","description":"","excerpt":"1. チャートの編集 Sample Data ダッシュボードにある Latency histogram チャートの3点 ... をクリックし …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/editing/","tags":"","title":"チャートを編集する"},{"body":"","categories":"","description":"**15 分**\n","excerpt":"**15 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/gdi/","tags":"","title":"データを取り込む"},{"body":" APM の概要 - RED メトリクス サービスマップを利用する タグスポットライトの紹介 トレースの例 インフラとのリンク   トレースとスパンについて トレースは、同じトレースIDを共有するスパンの集合体であり、アプリケーションとその構成サービスが処理する固有のトランザクションを表します。\n各スパンには、そのスパンでキャプチャされた操作を表す名前と、その操作がどのサービス内で行われたかを表すサービス名があります。\nさらにスパンは、その親として別のスパンを参照することができ、そのトランザクションを処理するために実行されたトレースでキャプチャされた処理の関係を定義します。\n各スパンには、キャプチャされたメソッド、オペレーション、コードブロックに関する以下のような多くの情報が含まれています。例えば:\n 処理名 処理の開始時間（マイクロ秒単位の精度） 処理の実行時間（マイクロ秒単位の精度） 処理が行われたサービスの論理名 処理が行われたサービスインスタンスのIPアドレス  ","categories":"","description":"","excerpt":" APM の概要 - RED メトリクス サービスマップを利用する タグスポットライトの紹介 トレースの例 インフラとのリンク   トレース …","ref":"/observability-workshop/v4.41/ja/apm/docs/using-splunk-apm/trace_and_span/","tags":"","title":"トレースとスパン"},{"body":" ランディングページで利用できるUIとオプションに慣れる ページビュー/エラー、リクエスト/エラー、およびJavaScriptエラーを1つのビューで識別しする Web Vitalメトリクスと、ブラウザーアプリケーションに関連して発生したディテクターを確認する   1. Application Summary ダッシュボードの概要 1.1. ヘッダーバー 前のセクションで見たように、RUM Application Summary ダッシュボードは5つの主要セクションで構成されています。 最初のセクションは選択ヘッダーで、 ブラウザーアイコンまたはアプリケーション名の前の \u003e を使用してペインを折りたたむことができます。また、アプリケーション名(下の例では jmcj-rum-app )のリンクをクリックすると、Application Overview ページにアクセスできます。\nまた、右側のトリプルドット メニューから、 Application Overview や App Health ダッシュボード を開くことができます。\nまず View Dashboard リンクをクリックし Browser App Health ダッシュボード を開きます（別タブで開かれます）。 次に元のRUMタブに戻り Open Application Overview リンクか、アプリの名前をクリックして、Application Overview ダッシュボードを開きます。\nApplication Overview と Browser App Health ダッシュボードを次のセクションで詳しく見ていきます。\n2. Application Overview RUM Application Overview ダッシュボードでは 一目で アプリケーションの状態の概要を確認できます。\n2.1. Page Views / Network Requests / Errors 最初セクションに表示されている Page Views / Errors と Network Requests and Errors チャートはアプリケーション内のリクエスト数と問題の傾向を示しています。 これは、Javascriptのエラーや、バックエンドサービスへのネットワーク呼び出しに失敗した可能性があります。\n上の例では、Networkチャートではネットワーク呼び出しに失敗していないことがわかりますが、Page Viewsチャートでは多くのページで何らかのエラーが発生していることが確認できます。このようなエラーは一般ユーザーからは見えないことが多いのですが、Web サイトのパフォーマンスに重大な影響を与える可能性があります。\nチャート上にカーソルをホバーすると Page Views / Network Requests / Errors の件数を確認できます。\n2.2. JavaScript Errors 2番目のセクションでは、アプリケーションで発生したJavaScriptエラーの概要と、各エラーの件数が表示されます。 上の例では、3種類のJavaScriptエラーがあることがわかります。1つは選択した時間帯に29回発生し、他の2つはそれぞれ12回発生しています。\nエラーの一つをクリックすると、ポップアウトが開き、時系列でエラーの概要（下図）が表示されます。また、JavaScript エラーのスタックトレースが表示され、問題が発生した場所を知ることができます（詳細については、次のセクションで説明します）。\n2.3. Web Vitals 3番目のセクションでは、Googleがランキングシステムで使用する3つのメトリクスである重要な（Google）Web Vitalsを表示しており、エンドユーザーにとってのサイトの表示速度を非常によく表しています。\nご覧の通り、当サイトは3つのメトリクスすべてで Good スコアを獲得し、良好な動作をしています。これらのメトリクスは、アプリケーションの変更がもたらす影響を特定し、サイトのパフォーマンスを向上させるために使用することができます。\nWeb Vitalsペインに表示されているメトリクスをクリックすると、対応する Tag Spotlight ダッシュボードに移動します。例えば Largest Contentful Paint (LCP) をクリックすると、以下のスクリーンショットのようなダッシュボードが表示され、このメトリクスのパフォーマンスに関するタイムラインとテーブルビューを見ることができます。これにより、OS やブラウザーのバージョンなど、より一般的な問題の傾向を把握することができます。\n2.4. Most Recent Detectors 4番目であり最後のセクションでは、アプリケーションでトリガーされたディテクターの概要を表示することにフォーカスしています。このスクリーンショット用にディテクターを作成しているため、皆さんのペインでは何も表示されていないはずです。次のセクションで実際にディテクターを追加し、トリガーされるようにします。\n下のスクリーンショットでは、 RUM Aggregated View Detector のクリティカルアラートと、選択した時間ウィンドウでこのアラートが何回トリガーされたかを示す件数が表示されています。アラートが表示されている場合は、アラートの名前（青いリンクで表示されている）をクリックすると、アラートの詳細を表示するアラート概要ページに移動します（注意：この操作を行うと、現在のページから離れることになります。）\n 次のセクションに進む前に、RUM Application Summaryダッシュボードとその基礎となるチャートとダッシュボードを数分間試してみてください。\n","categories":"","description":"","excerpt":" ランディングページで利用できるUIとオプションに慣れる ページビュー/エラー、リクエスト/エラー、およびJavaScriptエラーを1つの …","ref":"/observability-workshop/v4.41/ja/rum/docs/browserapp-summary/","tags":"","title":"ブラウザーアプリケーションの健全性を一目で確認"},{"body":" ミューティングルールを設定する 通知を再開する   1. ミューティングルールの設定 特定の通知をミュートする必要がある場合があります。例えば、サーバーやサーバー群のメンテナンスのためにダウンタイムを設定したい場合や、新しいコードや設定をテストしている場合などがあります。このような場合には、Splunk Observability Cloud でミューティングルールを使用できます。それでは作成してみましょう。\nナビバーにある ボタンをクリックし、Detectors を選択します。現在設定されているディテクターの一覧が表示されます。フィルタを使ってディテクターを探すこともできます。\nCreating a Detector でディテクターを作成した場合は、右端の3つの点 ... をクリックすると、そのディテクターが表示されます。\nドロップダウンから Create Muting Rule… をクリックします。\nMuting Rule ウィンドウで、 Mute Indefinitely をチェックし、理由を入力します。\nImportant\nこの操作をすると、ここに戻ってきてこのボックスのチェックを外すか、このディテクターの通知を再開するまで、通知が永久的にミュートされます。   Next をクリックして、新しいモーダルウィンドウでミュートルールの設定を確認します。\n Mute Indefinitely    をクリックして、設定を確定させます。\nこれで、通知を再開するまで、ディテクターからのEメール通知は受け取ることがなくなりました。では、再開する方法を見てみましょう。\n 2. 通知を再開する Muting Rules をクリックして、Detector の見出しの下に、通知をミュートしたディテクターの名前が表示されます。\n右端にあるドット ... を開いて、Resume Notifications をクリックします。\n Resume    をクリックして、このディテクターの通知を確認し、再開します。\nおめでとうございます！ これでアラート通知が再開されました。\n","categories":"","description":"","excerpt":" ミューティングルールを設定する 通知を再開する   1. ミューティングルールの設定 特定の通知をミュートする必要がある場合があります。例 …","ref":"/observability-workshop/v4.41/ja/imt/docs/detectors/muting/","tags":"","title":"ミューティングルールを利用する"},{"body":" See RUM Metrics and Session information in the RUM UI See correlated APM traces in the RUM \u0026 APM UI   1. RUM Overview Pages From your RUM Application Summary Dashboard you can see detailed information by opening the Application Overview Page via the tripple dot menu on the right by selecting Open Application Overview or by clicking the link with your application name which is jmcj-rum-app in the example below.\nThis will take you to the RUM Application Overview Page screen as shown below.\n2. RUM Browser Overview 2.1. Header The RUM UI consists of 6 major sections. The first is the selection header, where you can set/filter a number of options:\n A drop down for the time window you’re reviewing (You are looking at the past hour in this case) A drop down to select the Comparison window (You are comparing current performance on a rolling window - in this case compared to 1 hour ago) A drop down with the available Environments to view: (Choose the one provided by the workshop host or All like in the example) A drop down list with the Various Web apps (You can use the one provided by the workshop host or use All) Optionally a drop down to select Browser or Mobile metrics (Might not be available in your workshop)  2.2. Overview Pane The Overview Panes, down the left hand side of the page, give you a summary of the pages which have increased load times.\nIn the example here you can see that the checkout and cart pages have errors due to the yellow triangles, and you can see that the load time has increased by 2.38 to 5.50 seconds.\nYou also see an overview of the number of Front end Error and Backend Errors per minute, and we appear to have three JavaScript errors on our site.\nThe last two panes show you the Top Page Views and the Top Network Requests.\n2.3. Key Metrics Pane The Key Metrics View is the location where you will find the metrics for the number of JavaScript Errors per second, Network Errors per second an the Backend/Resource Request Duration. These Metrics are very useful to guide you to the location of an issue if you are experiencing problems with your site.\n2.4. Web Vitals Pane The Web Vitals view is the location where you go if you wish to get insight into the experience you are delivering to your End users based on Web Vitals metrics. Web Vitals is an initiative by Google to provide unified guidance for quality signals that are essential to delivering a great user experience on the web and focuses on three key parameters:\n Largest Contentful Paint (LCP), measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID), measures interactivity. To provide a good user experience, pages should have a FID of 100 milliseconds or less. Cumulative Layout Shift (CLS), measures visual stability. To provide a good user experience, pages should maintain a CLS of 0.1. or less.  2.5. Other Metrics Pane The Other Metrics Pane is the location where you find other performance metrics, with a focus on initial load time of your page or tasks that are taking too long to complete.\n Time To First Byte (TTFB), measures how long it takes for a client’s browser to receive the first byte of the response from the server. The longer it takes for the server to process the request and send a response, the slower your visitors' browser is at displaying your page. Long Task Duration, a performance metric that can be used help developers to understand the bad user experience on the website, or can be an indication of a problem. Long Task Count, a metric to indicate how often a long task occurs, again used for exploring user experiences or problem detection.  2.6. Custom Event Pane The Custom Event View is the location where you will find the metrics for any event you may have added yourself to the web pages you are monitoring.\nAs we have seen in the RUM enabled website, we have added the following two lines:\nconst Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); These lines will automatically create custom Events for every new Page, and you can also add these to pieces of custom code that are not part of a framework or an event you created so you can better understand the flow though your application. We support Custom Event Requests, Custom Event Error Rates and Custom Event Latency metrics.\n","categories":"","description":"","excerpt":" See RUM Metrics and Session information in the RUM UI See correlated …","ref":"/observability-workshop/v4.41/rum/docs/analyzing-metrics/","tags":"","title":"Analyzing RUM Metrics"},{"body":"Code to Kubernetes - Python Objective: Understand activities to instrument a python application and run it on Kubernetes.\n Verify the code Containerize the app Deploy the container in Kubernetes  Note: these steps do not involve Splunk\nDuration: 15 Minutes\nVerify the code - Review service Inspect review.py (workshop/flask_apps_start/review)\nfrom flask import Flask, jsonify import random import subprocess review = Flask(__name__) num_reviews = 8635403 num_reviews = 100000 reviews_file = '/var/appdata/yelp_academic_dataset_review.json' @review.route('/') def hello_world(): return jsonify(message='Hello, you want to hit /get_review. We have ' + str(num_reviews) + ' reviews!') @review.route('/get_review') def get_review(): random_review_int = str(random.randint(1,num_reviews)) line_num = random_review_int + 'q;d' command = [\"sed\", line_num, reviews_file] # sed \"7997242q;d\" \u003cfile\u003e random_review = subprocess.run(command, stdout=subprocess.PIPE, text=True) return random_review.stdout if __name__ == \"__main__\": review.run(host ='0.0.0.0', port = 5000, debug = True) Inspect requirements.txt\nFlask==2.0.2 Create a virtual environment and Install the necessary python packages\ncd Workshop/flask_apps_start/review python3 -m venv rtapp-workshop source rtapp-workshop/bin/activate pip freeze #note output pip install -r requirements.txt pip freeze #note output Start the REVIEW service. Note: You can stop the app with control+C\npython3 review.py * Serving Flask app 'review' (lazy loading) * Environment: production ...snip... * Running on http://10.160.145.246:5000/ (Press CTRL+C to quit) * Restarting with stat 127.0.0.1 - - [17/May/2022 22:46:38] \"GET / HTTP/1.1\" 200 - 127.0.0.1 - - [17/May/2022 22:47:02] \"GET /get_review HTTP/1.1\" 200 - 127.0.0.1 - - [17/May/2022 22:47:58] \"GET /get_review HTTP/1.1\" 200 - Verify that the service is working\n Hit the URL http://localhost:5000 and http://localhost:5000/get_review with a browser Or, use curl in your terminal  curl localhost:5000 { \"message\": \"Hello, you want to hit /get_review. We have 100000 reviews!\" } curl localhost:5000/get_review {\"review_id\":\"NjbiESXotcEdsyTc4EM3fg\",\"user_id\":\"PR9LAM19rCM_HQiEm5OP5w\",\"business_id\":\"UAtX7xmIfdd1W2Pebf6NWg\",\"stars\":3.0,\"useful\":0,\"funny\":0,\"cool\":0,\"text\":\"-If you're into cheap beer (pitcher of bud-light for $7) decent wings and a good time, this is the place for you. Its generally very packed after work hours and weekends. Don't expect cocktails. \\n\\n-You run into a lot of sketchy characters here sometimes but for the most part if you're chilling with friends its not that bad. \\n\\n-Friendly bouncer and bartenders.\",\"date\":\"2016-04-12 20:23:24\"}  Workshop Question\n What does this application do? Do you see the yelp dataset being used? Why did the output of pip freeze differ each time you ran it? Which port is the REVIEW app listening on? Can other python apps use this same port?    }\nCreate a REVIEW container To create a container image, you need to create a Dockerfile, run docker build to build the image referencing the Docker file and push it up to a remote repository so it can be pulled by other sources.\n Create a Dockerfile Creating a Dockerfile typically requires you to consider the following:  Identify an appropriate container image  ubuntu vs. python vs. alpine/slim ubuntu - overkill, large image size, wasted resources when running in K8 this is a python app, so pick an image that is optimized for it avoid alpine for python   Order matters  you’re building layers. re-use the layers as much as possible have items that change often towards the end   Other Best practices for writing Dockerfiles    Dockerfile for review\nFROMpython:3.10-slimWORKDIR/appCOPY requirements.txt /appRUN pip install -r requirements.txtCOPY ./review.py /appEXPOSE5000CMD [ \"python\", \"review.py\" ]Create a container image (locally) Run ‘docker build’ to build a local container image referencing the Dockerfile\n(venv)% docker build -f Dockerfile -t localhost:8000/review:0.01 . [+] Building 35.5s (11/11) FINISHED =\u003e [internal] load build definition from Dockerfile 0.0s ...snip... =\u003e [3/5] COPY requirements.txt /app 0.0s =\u003e [4/5] RUN pip install -r requirements.txt 4.6s =\u003e [5/5] COPY ./review.py /app 0.0s =\u003e exporting to image 0.2s =\u003e =\u003e exporting layers 0.2s =\u003e =\u003e writing image sha256:61da27081372723363d0425e0ceb34bbad6e483e698c6fe439c5 0.0s =\u003e =\u003e naming to docker.io/localhost:8000/review:0.1 0.0 Push the container image into a container repository Run ‘docker push’ to place a copy of the REVIEW container to a remote location\ndocker push localhost:8000/review:0.01 The push refers to repository [docker.io/localhost:8000/review] 02c36dfb4867: Pushed ...snip... fd95118eade9: Pushed 0.1: digest: sha256:3651f740abe5635af95d07acd6bcf814e4d025fcc1d9e4af9dee023a9b286f38 size: 2202 Verify that the image is in Docker Hub. The same info can be found in Docker Desktop\ncurl -s http://localhost:8000/v2/_catalog {\"repositories\":[\"review\"]} Run REVIEW in Kubernetes Create K8 deployment yaml file for the REVIEW app Reference: Creating a Deployment\nreview.deployment.yaml\napiVersion:apps/v1kind:Deploymentmetadata:name:reviewlabels:app:reviewspec:replicas:1selector:matchLabels:app:reviewtemplate:metadata:labels:app:reviewspec:imagePullSecrets:- name:regcredcontainers:- image:localhost:8000/review:0.01name:reviewvolumeMounts:- mountPath:/var/appdataname:appdatavolumes:- name:appdatahostPath:path:/var/appdataNotes regarding review.deployment.yaml:\n labels - K8 uses labels and selectors to tag and identify resources  In the next step, we’ll create a service and associate it to this deployment using the label   replicas = 1  K8 allows you to scale your deployments horizontally We’ll leverage this later to add load and increase our ingestion rate   regcred provides this deployment with the ability to access your dockerhub credentials which is necessary to pull the container image. The volume definition and volumemount make the yelp dataset visible to the container  Create a K8 service yaml file for the review app. Reference: Creating a service:\nreview.service.yaml\napiVersion:v1kind:Servicemetadata:name:reviewspec:type:NodePortselector:app:reviewports:- port:5000targetPort:5000nodePort:30000Notes about review.service.yaml:\n the selector associates this service to pods with the label app with the value being review the review service exposes the review pods as a network service  other pods can now ping ‘review’ and they will hit a review pod. a pod would get a review if it ran ‘curl http://review:5000’   NodePort service  the service is accessible to the K8 host by the nodePort, 30000 Another machine that has this can get a review if it ran ‘curl http://:30000’    Apply the review deployment and service\nkubectl apply -f review.service.yaml -f review.deployment.yaml Verify that the deployment and services are running:\nubuntu@ip-10-0-1-54:/tmp$ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE review 1/1 1 1 19h ubuntu@ip-10-0-1-54:/tmp$ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE review NodePort 10.43.175.21 \u003cnone\u003e 5000:30000/TCP 154d ubuntu@ip-10-0-1-54:/tmp$ curl localhost:30000 { \"message\": \"Hello, you want to hit /get_review. We have 100000 reviews!\" } ubuntu@ip-10-0-1-54:/tmp$ curl localhost:30000/get_review {\"review_id\":\"Vv9rHtfBrFc-1M1DHRKN9Q\",\"user_id\":\"EaNqIwKkM7p1bkraKotqrg\",\"business_id\":\"TA1KUSCu8GkWP9w0rmElxw\",\"stars\":3.0,\"useful\":1,\"funny\":0,\"cool\":0,\"text\":\"This is the first time I've actually written a review for Flip, but I've probably been here about 10 times. \\n\\nThis used to be where I would take out of town guests who wanted a good, casual, and relatively inexpensive meal. \\n\\nI hadn't been for a while, so after a long day in midtown, we decided to head to Flip. \\n\\nWe had the fried pickles, onion rings, the gyro burger, their special burger, and split a nutella milkshake. I have tasted all of the items we ordered previously (with the exception of the special) and have been blown away with how good they were. My guy had the special which was definitely good, so no complaints there. The onion rings and the fried pickles were greasier than expected. Though I've thought they were delicious in the past, I probably wouldn't order either again. The gyro burger was good, but I could have used a little more sauce. It almost tasted like all of the ingredients didn't entirely fit together. Something was definitely off. It was a friday night and they weren't insanely busy, so I'm not sure I would attribute it to the staff not being on their A game...\\n\\nDon't get me wrong. Flip is still good. The wait staff is still amazingly good looking. They still make delicious milk shakes. It's just not as amazing as it once was, which really is a little sad.\",\"date\":\"2010-10-11 18:18:35\"}  Workshop Question\n What changes are required if you need to make an update to your Dockerfile now?    END OF TKO LAB We hope you found this session and lab useful. We have optional exercise you can do if you finish ahead of schedule, or if you would like to run this at home. Remember this resource can be used at customers to show the value / ease of OTEL.\nPlease be sure to review our session and provide feedback so we may improve your experience.\nHappy Splunking!!\n","categories":"","description":"","excerpt":"Code to Kubernetes - Python Objective: Understand activities to …","ref":"/observability-workshop/v4.41/tko/session-2/docs/code_to_python/","tags":"","title":"Code to Kubernetes - Python"},{"body":"","categories":"","description":"**20 minutes**\n","excerpt":"**20 minutes**\n","ref":"/observability-workshop/v4.41/imt/docs/dashboards/","tags":"","title":"Working with Dashboards"},{"body":"Now to see how the autoscaler reacts to increased load. To do this, you’ll start a different Pod to act as a client. The container within the client Pod runs in an infinite loop, sending queries to the php-apache service.\n1. Create loadgen YAML In the terminal window create a new called loadgen.yaml and copy the following YAML into the file:\nloadgen.yaml   apiVersion:apps/v1kind:Deploymentmetadata:name:loadgenlabels:app:loadgenspec:replicas:1selector:matchLabels:app:loadgentemplate:metadata:name:loadgenlabels:app:loadgenspec:containers:- name:infinite-callsimage:busyboxcommand:- /bin/sh- -c- \"while true; do wget -q -O- http://php-apache.apache.svc.cluster.local; done\"  2. Create a new namespace kubectl create namespace loadgen 3. Deploy the load generator kubectl apply -f loadgen.yaml --namespace loadgen  Workshop Question\nWhich metrics in the Kubernetes Navigator and the Apache dashboard have been instantly impacted by the deployment of the load generator?   4. Scale the load generator A ReplicaSet is a process that runs multiple instances of a Pod and keeps the specified number of Pods constant. Its purpose is to maintain the specified number of Pod instances running in a cluster at any given time to prevent users from losing access to their application when a Pod fails or is inaccessible.\nReplicaSet helps bring up a new instance of a Pod when the existing one fails, scale it up when the running instances are not up to the specified number, and scale down or delete Pods if another instance with the same label is created. A ReplicaSet ensures that a specified number of Pod replicas are running continuously and helps with load-balancing in case of an increase in resource usage.\nkubectl scale deployment/loadgen --replicas 4 -n loadgen Let the load generator run for around 5 minutes and keep observing the metrics in the Kubernetes Navigator and the Apache dashboard.\nWorkshop Question\nAnother Auto-Detect Detector has fired, which one is it this time?   ","categories":"","description":"","excerpt":"Now to see how the autoscaler reacts to increased load. To do this, …","ref":"/observability-workshop/v4.41/tko/session-5/docs/deploy-loadgen/","tags":"","title":"Deploy Load Generator"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/labs/","tags":"","title":"Labs"},{"body":"Make sure that you still have the Python Flask server from the Python Lab running. If you accidentally shut it down follow steps from the Python lab to restart the Python Flask server.\nStart in the Node example directory Open a new terminal window\ncd ~/otelworkshop/host/node Configure Node.js environment During npm init below you can use all defaults when prompted:\nnpm init \u0026\u0026 \\ npm install @splunk/otel --save \u0026\u0026 \\ npm install @opentelemetry/instrumentation-http --save Run .js HTTP.get requests client Set up environment and run the node app with HTTP.get requests !!! important If you are doing this workshop as part of a group, before the next step, add your initials do the APM environment: edit the run-client.sh script below and add your initials to the environment i.e. change:\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=apm-workshop\nto export OTEL_RESOURCE_ATTRIBUTES=deployment.environment=sjl-apm-workshop\nsource run-client.sh You will see requests printed to the window\nAPM Dashboard Traces / services will now be viewable in the APM dashboard. A new service takes about 90 seconds to register for the firs time, and then all data will be available in real time.\nAdditionally span IDs will print in the terminal where flask-server.py is running. You can use ++ctrl+c++ to stop the requests and server any time. You should now see a Node requests service alongside the Python and Java ones.\nWhere is the OpenTelemetry Instrumentation? You can see in the run-client.sh how the environment has been set up for OpenTelemtry and where the autoinstrumentation takes place as the node app runs.\nSplunk’s Otel autoinstrumentation for node.js is here\n","categories":"","description":"","excerpt":"Make sure that you still have the Python Flask server from the Python …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_single_host/node/","tags":"","title":"Node.js- Deploy HTTP Client"},{"body":"Splunk Real User Monitoring For the Real User Monitoring (RUM) instrumentation, we will add the Open Telemetry Javascript https://github.com/splunk/splunk-otel-js-web snippet in the pages, we will use the wizard again Data Management → Add Integration → RUM Instrumentation → Browser Instrumentation.\nSelect the preconfigured RUM ACCESS TOKEN from the dropdown, click Next. Enter App name and Environment using the following syntax:\n \u003chostname\u003e-petclinic-service - replacing  with your actual hostname. \u003chostname\u003e-petclinic-env - replacing  with your actual hostname.  Then you’ll need to select the workshop RUM token and define the application and environment names. The wizard will then show a snipped of HTML code that needs to be place at the top at the pages in the \u003chead\u003e section. In this example we are using:\n Application Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env  Copy the generated code snippet in the wizard or copy and edit the snippet below accordingly:\n\u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: \"https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum\", rumAuth: \"\u003cRUM_ACCESS_TOKEN\u003e\", app: \"\u003chostname\u003e-petclinic-service\", environment: \"\u003chostname\u003e-petclinic-env\" }); \u003c/script\u003e The Spring PetClinic application uses a single HTML page as the “layout” page, that is reused across all pages of the application. This is the perfect location to insert the Splunk RUM Instrumentation Library as it will be loaded in all pages automatically.\nLet’s then edit the layout page:\nvi src/main/resources/templates/fragments/layout.html and let’s insert the snipped we generated above in the \u003chead\u003e section of the page. Now we need to rebuild the application and run it again:\nRebuild PetClinic run the maven command to compile/build/package PetClinic:\n./mvnw package -Dmaven.test.skip=true java \\ -Dotel.service.name=$(hostname)-petclinic.service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Then let’s visit the application again to generate more traffic http://\u003cVM_IP_ADDRESS\u003e:8080, now we should see RUM traces being reported\nLet’s visit RUM and see some of the traces and metrics Hamburger Menu → RUM and you will see some of the Spring PetClinic URLs showing up in the UI.\n","categories":"","description":"","excerpt":"Splunk Real User Monitoring For the Real User Monitoring (RUM) …","ref":"/observability-workshop/v4.41/pet-clinic/docs/rum/","tags":"","title":"Real User Monitoring"},{"body":" RUM UIでRUMメトリクスとセッション情報を見る RUM \u0026 APM UIで相関するAPMトレースを見る   1. RUM Overview Pages RUM Application Summaryダッシュボードの右側のトリプルドット メニューから Open Application Overview を選択するか、アプリケーション名のリンク（以下の例では jmcj-rum-app ）をクリックして Application Overviewページを開き、詳細情報を確認することができます。\n以下のような RUM Application Overview ページが表示されます。\n2. RUM Browserの概要 2.1. ヘッダー RUMのUIは、大きく6つのセクションで構成されています。一つ目は選択ヘッダーで、多くのオプションを設定/フィルタリングすることができます。\n レビューする時間ウィンドウを選択するドロップダウン（この場合は過去15分）。 比較ウィンドウを選択するためのドロップダウン（現在のパフォーマンスをローリングウィンドウで比較します - この場合は1時間前と比較）。 Environmentを選択するドロップダウン (ワークショップ講師が提供するもの、またはこの例のように All を選択）。 様々なWebアプリのドロップダウン（ワークショップ講師が提供するものか、 All を使用）。 オプション ブラウザまたはモバイルメトリクスを選択するドロップダウン（ワークショップでは恐らく利用できません)   2.2. 概要ペイン ページの左側にある概要ペインでは、ロード時間が長くなったページの概要を確認することができます。\nこの例では checkout と cart ページに黄色の三角形でエラーを示しており、ロード時間が 2.38 秒から 5.50 秒に増加したことがわかります。\nまた、1分あたりのFrontend ErrorとBackend Errorsの件数の概要が表示され、このサイトでは3種類のJavaScriptエラーが発生していることが分かります。\n最後の2つのペインでは、Top Page Views と Top Network Requests が表示されます。\n2.3. Key Metricsペイン Key Metricsペインでは、毎分の JavaScript Errors と Network Errors の件数、また Backend/Resource Request Duration を確認できます。これらのメトリクスはサイトで問題が発生した場合に、発生個所を特定するのに非常に便利です。\n2.4. Web Vitalsペイン Web Vitalsペインは、Web Vitalのメトリクスに基づいてエンドユーザーに提供しているエクスペリエンスに関する洞察を得たい場合に使用する場所です。 Web Vitalは、ウェブ上で優れたユーザーエクスペリエンスを提供するために不可欠な品質シグナルの統一ガイダンスを提供するGoogleのイニシアチブであり、3つの主要なパラメーターに焦点を当てています。\n Largest Contentful Paint (LCP) （最大コンテンツの描画）：読み込みのパフォーマンスを測定するものです。良いユーザーエクスペリエンスを提供するために、LCPはページが読み込まれてから2.5秒以内に発生する必要があります。 First Input Delay (FID) （初回入力までの遅延時間）：インタラクティブ性を評価するものです。良いユーザーエクスペリエンスを提供するために、ページのFIDは100ミリ秒以下であるべきです。 Cumulative Layout Shift (CLS) （累積レイアウトシフト数）：視覚的な安定性を測定します。良いユーザーエクスペリエンスを提供するためには、CLSを 0.1 以下で維持する必要があります。  2.5. Other Metricsペイン Other Metricsペインでは、ページの初期ロード時間や完了までに時間がかかりすぎているタスクなどを中心に、その他のパフォーマンスメトリクスを確認することができます。\n Time To First Byte (TTFB) ：クライアントのブラウザーがサーバーからレスポンスの最初のバイトを受信するまでの時間を測定します。サーバーがリクエストを処理し、レスポンスを送信するまでの時間が長いほど、訪問者のブラウザーがページを表示する際の速度が遅くなります。 Long Task Duration ：開発者がユーザーエクスペリエンス悪化を理解するために使用できるパフォーマンスメトリクスであり、問題の兆候である可能性もあります。 Long Task Count ：長いタスクの発生頻度を示すメトリクスで、これもユーザーエクスペリエンスの調査や問題の検出に使用されます。  2.6. Custom Eventペイン Custom Eventペインでは、監視しているウェブページに自分で追加したイベントのメトリクスが表示されます。\nRUMを有効化したサイトで見れるように、以下の2行を追加しています。\nconst Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); これらの行は、すべての新しいページに対して自動的にカスタムイベントを作成します。また、フレームワークや作成したイベントの一部ではないカスタムコードにこれらを追加することで、アプリケーションのフローをより良く理解することができます。 Custom Event Requests 、 Custom Event Error Rates 、 Custom Event Latency をサポートしています。\n","categories":"","description":"","excerpt":" RUM UIでRUMメトリクスとセッション情報を見る RUM \u0026 APM UIで相関するAPMトレースを見る   1. RUM …","ref":"/observability-workshop/v4.41/ja/rum/docs/analyzing-metrics/","tags":"","title":"RUMメトリクスの分析"},{"body":"Splunk RUM is the industry’s only end to end, full fidelity Real User Monitoring solution. It is built to optimize performance and aid in faster troubleshooting, giving you full visibility into end-user experiences.\nSplunk RUM allows you to identify performance problems in your Web and or Mobile applications that impact the customer experience. We support benchmarking and measuring page performance with core web vitals. This includes but not limited to: W3C timings, the ability to identify long running tasks, along with everything that can impact your page load.\nWith Splunk’s end to end monitoring capabilities you are able to view the latency between all of the services that make up your application, from the service itself through to infrastructure metrics such as database calls and everything in between.\nOur full fidelity end to end monitoring solution captures 100% of your span data. We do not sample, we are framework agnostic and Open Telemetry standardized.\nMore often than not we find that the frontend and backend application’s performance are interdependent. Fully understanding and being able to visualize the link between your backend services and your user experience is increasingly important. To see the full picture, Splunk RUM provides seamless correlation between our front end and back end microservices. If your users are experiencing less than optimal conditions on your web based application due to an issue related to your microservice or infrastructure, Splunk will be able to detect this issue and alert you.\nTo complete the picture and offer full visibility, Splunk is also able to show in-context logs and events to enable deeper troubleshooting and root-cause analysis.\n","categories":"","description":"","excerpt":"Splunk RUM is the industry’s only end to end, full fidelity Real User …","ref":"/observability-workshop/v4.41/rum/","tags":"","title":"Splunk RUM, an introduction"},{"body":"Splunk RUM は、業界唯一のエンド・ツー・エンドで完全忠実なリアルユーザーモニタリングソリューションです。パフォーマンスを最適化し、トラブルシューティングを迅速に行い、エンドユーザーエクスペリエンスを完全に可視化するために構築されています。\nSplunk RUM は、ユーザーエクスペリエンスに影響を与える Web およびモバイルアプリケーションのパフォーマンス問題を特定することができます。Core Web Vitalによるページパフォーマンスのベンチマークと計測をサポートします。W3C タイミング、長時間実行されるタスクの特定、ページロードに影響を与える可能性のあるあらゆるものが含まれますが、これらに限定されるものではありません。\nSplunk のエンドツーエンドモニタリング機能を使用すると、アプリケーションを構成する、サービス自身を始めとしてデータベースコール数などのインフラメトリクスやその他関与するすべてに対して、サービス間の遅延を表示することができます。\n私たちの完全忠実なエンドツーエンドモニタリングソリューションは、お客様のSpanデータを100％取得します。サンプリングは行わず、フレームワークにとらわれず、Open Telemetryに標準化されています。\nフロントエンドとバックエンドのアプリケーションのパフォーマンスは相互に依存していることがよくあります。バックエンドサービスとユーザーエクスペリエンスとの関連性を十分に理解し、可視化できることがますます重要になっています。 全体像を把握するために、Splunk RUM は当社のフロントエンドとバックエンドのマイクロサービス間のシームレスな相関関係を提供します。マイクロサービスやインフラストラクチャに関連する問題によって、ユーザーが Web ベースのアプリケーションで最適とは言えない状態を経験している場合、Splunk はこの問題を検出して警告することができます。\nまた、Splunk は、より深いトラブルシューティングと根本原因の分析を可能にするために、インコンテキストログとイベントを表示することができます。\n","categories":"","description":"","excerpt":"Splunk RUM は、業界唯一のエンド・ツー・エンドで完全忠実なリアルユーザーモニタリングソリューションです。パフォーマンスを最適化し、 …","ref":"/observability-workshop/v4.41/ja/rum/","tags":"","title":"Splunk RUM のご紹介"},{"body":"Tag Spotlight On the right hand side of the screen scroll down on Tag Spotlight, ensure Top Across All Indexed Tags is selected in the dropdown click the full screen button as indicated in the screenshot below.\nThe Tag Spotlight Page will be displayed. From this page you can view the top tags in your application and their corresponding error rates and request rates.\nNote that for the version span tag it appears that version 350.10 has a 100% error rate and for our tenant.level span tag it shows that all three tenants (Gold, Silver \u0026 Bronze) have errors present.\nThe Tag Spotlight page is interactive and allows you to add a tag as a filter by simply clicking on your desired tag. Click on gold under tenant.level to add it as a filter. Once this is done the page will now only display data with gold as it’s tenant.level.\nTag Spotlight is very useful for analysing your data and spotting trends. We can see that for the Gold Tenant that out of the total number of requests, 55 of them are in error (this number will vary in your workshop).\nIf we correlate this to the version tag, we can see that version 350.10 served 55 requests and version 350.9 served 17 requests. This means that all of the requests that went through version 350.10 ended up in an error state.\nIn order to test this theory further that all of the requests from paymentservice version 350.10 result in an error, we can change our filter to another tenant by using the tag selector. Change your filter from gold tenant to silver tenant.\nNow we can perform a similar analysis by looking at the number of requests in error for the silver tenant and correlating that with the version number. Note the amount of errors for the silver tenant match the amount of requests for version 350.10.\nTag Spotlight not only allows you to look at request and error rates but also at the latency per service. In order to do this just select the latency button and remove your Silver Tenant Tag so that you can see the latency for all of the Payment Service.\nGo back to your service map by pressing the X button on the far right underneath Clear All.\nClick anywhere on the pink line in the Services by Error Rate graph in the top right hand corner. Once selected you should see a list of example traces. Click on one of the example traces with an initiating operation of frontend: POST /cart/checkout.\n","categories":"","description":"","excerpt":"Tag Spotlight On the right hand side of the screen scroll down on Tag …","ref":"/observability-workshop/v4.41/apm/docs/using-splunk-apm/tag_spotlight/","tags":"","title":"Tag Spotlight"},{"body":"サービスマップ サービスマップの paymentservice をクリックし、paymentservice の下にあるbreakdownのドロップダウンフィルタから version を選択します。これにより、カスタムスパンタグの version でサービスマップがフィルタリングされます。\nこれで、サービスマップが以下のスクリーンショットのように更新され、paymentservice の異なるバージョンが表示されていることがわかります。\n","categories":"","description":"","excerpt":"サービスマップ サービスマップの paymentservice をクリックし、paymentservice の下にあるbreakdownのド …","ref":"/observability-workshop/v4.41/ja/apm/docs/using-splunk-apm/service_map/","tags":"","title":"サービスマップ"},{"body":"","categories":"","description":"**20 分**\n","excerpt":"**20 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/","tags":"","title":"ダッシュボードを利用する"},{"body":"Checkout the milestone for this task. See the introduction for a brief howto.\nShell Command   git reset --hard \u0026\u0026 git clean -fdx \u0026\u0026 git checkout 01service  Let’s get python sorted first. On a provided AWS instance, python3 is already available.\nIf you are on a Mac:\nShell Command   brew install python@3  On another system, install a recent version of python (i.e. 3.x) with your package manager.\nNavigate to o11y-bootcamp/bootcamp/service/src and run the provided python service:\nShell Command: python3  Example Output python3   python3 -m venv .venv source .venv/bin/activate pip install -r requirements.txt python3 app.py * Serving Flask app 'app' (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on all addresses. WARNING: This is a development server. Do not use it in a production deployment. * Running on http://10.42.1.202:5000/ (Press CTRL+C to quit)  Then test the service in a separate shell in the ~/o11y-bootcamp/bootcamp/service/src directory with:\nShell Command: curl  Example Output: curl   curl -X POST http://127.0.0.1:5000/wordcount -F text=@hamlet.txt [[\"in\", 436], [\"hamlet\", 484], [\"my\", 514], [\"a\", 546], [\"i\", 546], [\"you\", 550], [\"of\", 671], [\"to\", 763], [\"and\", 969], [\"the\", 1143]]%  The bootcamp contains other text files at ~/nlp/resources/corpora. To use a random example:\nShell Command   SAMPLE=$(find ~/nlp/resources/corpora/gutenberg -name '*.txt' | shuf -n1) curl -X POST http://127.0.0.1:5000/wordcount -F text=@$SAMPLE  To generate load:\nShell Command   FILES=$(find ~/nlp/resources/corpora/gutenberg -name '*.txt') while true; do SAMPLE=$(shuf -n1 \u003c\u003c\u003c \"$FILES\") curl -X POST http://127.0.0.1:5000/wordcount -F text=@${SAMPLE} sleep 1 done  ","categories":"","description":"","excerpt":"Checkout the milestone for this task. See the introduction for a brief …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/monolith/","tags":"","title":"Create a Monolith Service"},{"body":"Example Trace You should now see the entire trace along with the spans for the example trace that was selected. Spans which have errors are indicated by a red exclamation mark beside it. If you have a number such as x6 in a grey box, click it to expand the compacted paymentservice spans.\nNow click one of the paymentservice spans with the red exclamation mark to expand it and see the associated metadata and some error details. Note that we are able to see that this error is caused by a 401 error and other useful information such as ‘tenant’ and ‘version’ is also displayed.\nSo we now know that the error is caused by an Invalid Request but we don’t know what exact request. At the bottom of the page you should see a contextual link to Logs, clink on this link to view the logs associated with this span.\nYou should now be looking at a Log Observer dashboard simialar to the image below.\nWe can use the filter to display only the error logs. Click on ERROR in the top right hand corner, then Add to filter\nYou should now have a shorter list of log entries which have a severity of ERROR\nSelect any of the entries to view the details. We can now see how the error was caused by the use of an Invalid API Token that our developers have accidentally pushed to production!\nCongratulations, you have now completed this APM Workshop.\n","categories":"","description":"","excerpt":"Example Trace You should now see the entire trace along with the spans …","ref":"/observability-workshop/v4.41/apm/docs/using-splunk-apm/example_trace/","tags":"","title":"Example trace"},{"body":"Splunk Log Observer For the Splunk Log Observer component, we will configure the Spring PetClinic application to write logs to a file in the filesystem and configure the Splunk OpenTelemetry Collect to read (tail) that log file and report the information to the Splunk Observability Platform.\nFluentD Configuration We need to configure the Splunk OpenTelemetry Collector to tail the Spring Pet Clinic log file and report the data to the Splunk Observability Cloud endpoint.\nThe Splunk OpenTelemetry Collector uses FluentD to consume/report logs and to configure the proper setting to report Spring PetClinic logs, we just need to add a FluentD configuration file in the default directory (/etc/otel/collector/fluentd/conf.d/).\nHere’s the sample FluentD configuration file (petclinic.conf, reading the file /tmp/spring-petclinic.log)\n\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e So we need to create the file\nsudo vi /etc/otel/collector/fluentd/conf.d/petclinic.conf We also need to change permission and ownership of the petclinic.conf file\nsudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf And paste the contents from the snippet above. Once the file is created, we need to restart the FluentD process\nsudo systemctl restart td-agent PetClinic Logback Settings The Spring PetClinic application can be configure to use a number of different java logging libraries. In this scenario, we are using logback. Here’s a sample logback configuration file:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE xml\u003e \u003cconfiguration scan=\"true\" scanPeriod=\"30 seconds\"\u003e \u003ccontextListener class=\"ch.qos.logback.classic.jul.LevelChangePropagator\"\u003e \u003cresetJUL\u003etrue\u003c/resetJUL\u003e \u003c/contextListener\u003e \u003clogger name=\"org.springframework.samples.petclinic\" level=\"debug\"/\u003e \u003cappender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003cfile\u003e/tmp/spring-petclinic.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003cfileNamePattern\u003espringLogFile.%d{yyyy-MM-dd}.log\u003c/fileNamePattern\u003e \u003cmaxHistory\u003e5\u003c/maxHistory\u003e \u003ctotalSizeCap\u003e1GB\u003c/totalSizeCap\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e %d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg trace_id=%X{trace_id} span_id=%X{span_id} trace_flags=%X{trace_flags} service.name=%property{otel.resource.service.name}, deployment.environment=%property{otel.resource.deployment.environment} %n \u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level=\"debug\"\u003e \u003cappender-ref ref=\"file\" /\u003e \u003c/root\u003e \u003c/configuration\u003e We just need to create a file named logback.xml in the configuration folder.\nvi src/main/resources/logback.xml and paste the XML content from the snippet above. After that, we need to rebuild the application and run it again:\n./mvnw package -Dmaven.test.skip=true java \\ -Dotel.service.name=$(hostname)-petclinic.service \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Then let’s visit the application again to generate more traffic, now we should see log messages being reported http://\u003cVM_IP_ADDRESS\u003e:8080 (feel free to navigate and click around).\nThen visit: Hamburger Menu \u003e Log Observer\nAnd you can add a filter to select only log messages from your host and the Spring PetClinic Application:\n Add Filter → Fields → host.name → \u003cyour host name\u003e Add Filter → Fields → service.name → \u003cyour host name\u003e-petclinic.service  Summary This the end of the exercise and we have certainly covered a lot of ground. At this point you should have metrics, traces, logs, database query performance and code profiling being reported into Splunk Observability Cloud. Congratulations!\n","categories":"","description":"","excerpt":"Splunk Log Observer For the Splunk Log Observer component, we will …","ref":"/observability-workshop/v4.41/pet-clinic/docs/logobserver/","tags":"","title":"Log Observer"},{"body":"The development team has broken up the monolithic service into microservices baesd on the docker-compose setup. Switch to the provided milestone 10microservices with the instructions from “Getting Started”.\nTest the service with:\nShell Command   curl -X POST http://127.0.0.1:8000/api -F text=@hamlet.txt  Add auto-instrumentation to the public_api microservice using the Splunk distribution of OpenTelemetry Python. Review the documentation and the getting Started steps and apply it to Dockerfile.\nTake into account the trace exporter settings and add the required environment variables to the .env file for docker-compose. Use the configuration to send traces directly to Splunk Observability Cloud.\nThe milestone for this task is 10microservices-autoi. It has auto-instrumentation applied for all microservices.\n","categories":"","description":"","excerpt":"The development team has broken up the monolithic service into …","ref":"/observability-workshop/v4.41/bootcamp/docs/apm/autoi/","tags":"","title":"Microservices Auto-instrumentation"},{"body":"We are going to work in the directory bootcamp/service/src. Your first task: Write a python app to count words in a text file.\nNo, wait - we’ve already done that for you.\nThis section will introduce the format for this workshop.\n  First, we will introduce a challenge or task for you to complete, e.g. “Task 1: Service”.\n  There will be concepts and references for you to review.\n  We will timebox self-paced content during a live workshop.\n  We provide copies of solutions for the tasks in the workshop. They are called milestones and live in their own directory at ~/milestones.\n  If you did not complete a specific task, you can use these milestones to proceed to the next task or review the solution. Some tasks also instruct you to use a specific milestone as a basis. Let’s look at how this works, and remember: milestones are just directories on the file system and you can copy over content into your working directory as needed.\nGetting started The task is to write a python app to count words in a text file. Here is how to get to the milestone that completes this step:\nShell Command   git checkout 01service  This will put you on the first milestone.\nIn case you have already worked on a milestone, you might see an error like:\nExample Output   error: Your local changes to the following files would be overwritten by checkout: app.py Please commit your changes or stash them before you switch branches. Aborting  This is because your work conflicts with changes on the milestone. You have the following options:\n  If you have worked on a task and want to progress to the next one and DROP all your changes: Shell Command: Git Reset   git reset --hard \u0026\u0026 git clean -fdx \u0026\u0026 git checkout service  You will have to re-apply any local changes like settings tokens or names.\n  To preserve your work but move it out of the way, you can use\nShell Command: Git Stash   git stash \u0026\u0026 git checkout service  To restore your work, switch to the previous milestone (main in this case) and retrieve the stashed changes:\n Shell Command: Git Checkout   git checkout main \u0026\u0026 git stash pop  Sometimes you run into conflicting changes with this approach. We recommend you use the first option in this case.\n  During development changes are recorded by adding and commiting to the repository. This is not necessary for this workshop.\n  Use the first option and proceed.\nTo compare two milestones, use\nShell Command: Git Checkout   git diff main..01service  To compare what you have with a milestone, , e.g. the milestone service use\nShell Command: Git Checkout  Example Output (excerpt)   git diff ..01service ... diff --git a/bootcamp/service/src/app.py b/bootcamp/service/src/app.py index 9bcae83..b7fc141 100644 --- a/bootcamp/service/src/app.py +++ b/bootcamp/service/src/app.py @@ -1,10 +1,12 @@ +import json import re -from unicodedata import category +from flask import Flask, request, Response ...  Future Tasks TODO YOUR Idea here? Let us know!\nTODO metrics method being traced - how to disable?\nfrom opentelemetry.context import attach, detach, set_value token = attach(set_value(\"suppress_instrumentation\", True)) TODO autodetect metrics with k8s labels: prometheus.io/scrape: true - run prometheus on separate port 9090.\nTODO tracing examples\n","categories":"","description":"","excerpt":"We are going to work in the directory bootcamp/service/src. Your first …","ref":"/observability-workshop/v4.41/bootcamp/","tags":"","title":"Welcome to the Observability Bootcamp"},{"body":"Goals  Understand components involved for GDI, e.g.:  OpenTelemetry Collector Prometheus exporters   Understand how Developers, DevOps and SREs work with infrastructure and microservices Ability to ingest data from common stacks:  Virtual Machines Containers and Container Orchestration (e.g. Docker, Docker Compose) Container Orchestration Platforms (e.g. Kubernetes)   Understand troubleshooting 101 for components (commands)  We are going to work in the directory o11y-bootcamp/bootcamp/service/src. Your first task: Write a python app to count words in a text file.\nNo, wait - we’ve already done that for you.\n","categories":"","description":"","excerpt":"Goals  Understand components involved for GDI, e.g.:  OpenTelemetry …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/","tags":"","title":"Lab: OpenTelemetry \u0026 Get Data In (GDI)"},{"body":"1. Saving a chart To start saving your chart, lets give it a name and description. Click the name of the chart Copy of Latency Histogram and rename it to “Active Latency”.\nTo change the description click on Spread of latency values across time. and change this to Overview of latency values in real-time.\nClick the Save As    button. Make sure your chart has a name, it will use the name Active Latency the you defined in the previous step, but you can edit it here if needed.\nPress the Ok    button to continue.\n2. Creating a dashboard In the Choose dashboard dialog, we need to create a new dashboard, click on the New Dashboard    button.\nYou will now see the New Dashboard Dialog. In here you can give you dashboard a name and description, and set Read and Write Permissions.\nPlease use your own name in the following format to give your dashboard a name e.g. YOUR_NAME-Dashboard.\nPlease replace YOUR_NAME with your own name, change the dashboard permissions to Restricted Read and Write access, and verify your user can read/write.\nYou should see you own login information displayed, meaning you are now the only one who can edit this dashboard. Of course you have the option to add other users or teams from the drop box below that may edit your dashboard and charts, but for now make sure you change it back to Everyone can Read or Write to remove any restrictions and press the Save    Button to continue.\nYour new dashboard is now available and selected so you can save your chart in your new dashboard.\nMake sure you have your dashboard selected and press the Ok    button.\nYou will now be taken to your dashboard like below. You can see at the top left that your YOUR_NAME-DASHBOARD is part of a Dashboard Group YOUR_NAME-Dashboard. You can add other dashboards to this dashboard group.\n 3. Add to Team page It is common practice to link dashboards that are relevant to a Team to a teams page. So let’s add your dashboard to the team page for easy access later. Use the from the navbar again.\nThis will bring you to your teams dashboard, We use the team Example Team as an example here, the workshop one will be different.\nPress the +    Add Dashboard Group button to add you dashboard to the team page.\nThis will bring you to the Select a dashboard group to link to this team dialog. Type your name (that you used above) in the search box to find your Dashboard. Select it so its highlighted and click the Ok button to add your dashboard.\nYour dashboard group will appear as part of the team page. Pleasu note during the course of the workshop many more will appear here.\n Now click on the link for your Dashboard to add more charts!\n","categories":"","description":"","excerpt":"1. Saving a chart To start saving your chart, lets give it a name and …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/savingcharts/","tags":"","title":"Saving charts"},{"body":"In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.\nHorizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.\nIf the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.\n1. Setup HPA Create an autoscaling deployment for when the CPU usage for php-apache deployment goes above 50% with a minimum of 1 pod and a maximum of 4 pods.\nkubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=4 -n apache  Workshop Question\nHow many additional php-apache pods are created?   2. Validate HPA kubectl get hpa -n apache  Workshop Question\nWhich metrics in the Apache Dashboards have significantly increased?   ","categories":"","description":"","excerpt":"In Kubernetes, a HorizontalPodAutoscaler automatically updates a …","ref":"/observability-workshop/v4.41/tko/session-5/docs/setup-hpa/","tags":"","title":"Setup Horizontal Pod Autoscaler"},{"body":"タグスポットライト 画面の右側にある Tag Spotlight をスクロールダウンし、ドロップダウンから Top Across All Indexed Tags を選択します。選択したら、下のスクリーンショットにあるように をクリックします。\nタグスポットライトのページが表示されます。このページでは、アプリケーションの上位のタグと、それに対応するエラー率や秒間リクエスト数を確認できます。\nversion スパンタグでは、バージョン 350.10 のエラー率が100%であることがわかります。また、tenant.level スパンタグでは、3つのテナント（Gold、Silver、Bronze）すべてにエラーがあることがわかります。\nタグスポットライトのページはインタラクティブに、目的のタグをクリックするだけでフィルタとしてタグを追加することができます。tenant.level の下の gold をクリックして、フィルターとして追加します。これを行うと、ページには tenant.level が gold のデータのみが表示されます。\nタグスポットライトは、データを分析して傾向を見極めるのに非常に便利です。Gold Tenantでは、リクエストの総数のうち55件がエラーであることがわかります。（この数字はワークショップの実施時刻により異なります）\nこれをバージョンタグと関連付けると、バージョン 350.10 が55件、バージョン 350.9 が17件のリクエストに対応していることがわかります。つまり、バージョン 350.10 を経由したリクエストは、すべてエラー状態になったということになります。\npaymentservice のバージョン 350.10 からのすべてのリクエストがエラーになるというこの理論をさらに検証するために、タグセレクタを使用して、フィルタを別のテナントに変更することができます。フィルターを gold テナントから silver テナントに変更します。\nここで、silver テナントのエラーのあるリクエスト数を見て、バージョン番号と相関させることで、同様の分析を行うことができます。silver テナントのエラー数は、バージョン 350.10 のリクエスト数と一致していることに注目してください。\nタグスポットライトでは、秒間リクエスト数やエラー率だけでなく、サービスごとのレイテンシーも見ることができます。これを行うには、レイテンシーボタンを選択し、silver テナントタグを削除することで、すべての paymentservice のレイテンシーを確認することができます。\n右端の Clear All の下にある X ボタンを押して、サービスマップに戻りましょう。\n","categories":"","description":"","excerpt":"タグスポットライト 画面の右側にある Tag Spotlight をスクロールダウンし、ドロップダウンから Top Across All …","ref":"/observability-workshop/v4.41/ja/apm/docs/using-splunk-apm/tag_spotlight/","tags":"","title":"Tag Spotlight"},{"body":" より深く分析のために様々なエンドポイントのメトリクスビューを調査したりTag spotlightに送信されたTagを使用します。   1. CartエンドポイントのURLを探す RUMの概要ページから、Cart エンドポイントのURLを選択し、このエンドポイントで利用可能な情報をさらに深く掘り下げてみてください。\n青色のURLをクリックすると、 Tag Spotlight の概要に遷移します。\nここでは、RUM トレースの一部として Splunk RUM に送信されたすべてのタグが表示されます。表示されるタグは、あなたが選択した概要に関連するものです。これらはトレースが送信されたときに自動的に作成された一般的なタグと、ウェブサイトの設定の一部でトレースに追加した追加タグです。\n追加タグ\n既に2つの追加タグを送信しています。それは皆さんのウェブサイトに追加された Beacon url に定義されている app: “[nodename]-rum-app”, environment: “[nodename]-rum-env” です（詳しくは後で確認します）。同様の方法で、タグを追加することができます。   この例では、以下のように Document Load Latency ビューを選択しています。\n特定のメトリクスにフォーカスした以下のタグビューのいずれかを選択することができます。\n 2. Tag Spotlight内の情報を探索 Tag Spotlightは、チャートビューで異常値を確認したり、タグで問題を特定するのに役立つように設計されています。\nDocument Load Latency ビューで、Browser 、 Browser Version 、 OS Name タグビューを見ると、様々なブラウザーの種類とバージョン、そして基盤となるOSを確認することができます。 これにより、特定のブラウザやOSのバージョンに関連する問題が強調表示されるため、特定が容易になります。\n上記の例では、Firefoxのレスポンスが最も遅く、様々なバージョンのブラウザ（Chrome）のレスポンスが異なること、Android端末のレスポンスが遅いことが分かります。\nさらに、ISPや場所などに関連する問題を特定するために使用できる地域タグがあります。ここでは、Online Boutiqueにアクセスするために使用している場所を見つけることができます。以下のように、Online Boutiqueにアクセスしている都市や国をクリックしてドリルダウンしてください（City内のAmsterdam）。\n以下のように選択した都市に関連するトレースのみが選択されます。\n様々なタグを選択することでフィルターを構築することができ、現在の選択項目も確認できます。\nフィルタを解除してすべてのトレースを表示するには、ページ右上の Clear All をクリックしてください。\n概要ページが空であるか、 と表示されている場合、選択したタイムスロットでトレースが受信されていないことを示します。 左上のタイムウィンドウを広げる必要があります。例えば、Last 12 hours で調べることができます。\n下の図のように表示したい時間帯を選択し、小さな虫眼鏡のアイコンをクリックして時間フィルタをセットにすることができます。\n","categories":"","description":"","excerpt":" より深く分析のために様々なエンドポイントのメトリクスビューを調査したりTag spotlightに送信されたTagを使用します。   1. …","ref":"/observability-workshop/v4.41/ja/rum/docs/tag-spotlight/","tags":"","title":"Tag Spotlightの使用"},{"body":" Look into the Metrics views for the various endpoints and use the Tags sent via the Tag spotlight for deeper analysis   1. Find an url for the Cart endpoint From the RUM Overview page, please select the url for the Cart endpoint to dive deeper into the information available for this endpoint.\nOnce you have selected and clicked on the blue url, you will find yourself in the Tag Spotlight overview\nHere you will see all of the tags that have been sent to Splunk RUM as part of the RUM traces. The tags displayed will be relevant to the overview that you have selected. These are generic Tags created automatically when the Trace was sent, and additional Tags you have added to the trace as part of the configuration of your website.\nAdditional Tags\nWe are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website: app: “[nodename]-rum-app”, environment: “[nodename]-rum-env” in the first section of this workshop! You can add additional tags in a similar way.   In our example we have selected the Document Load Latency view as shown here:\nYou can select any of the following Tag views, each focused on a specific metric.\n 2. Explore the information in the Tag Spotlight view The Tag spotlight is designed to help you identify problems, either through the chart view,, where you may quickly identify outliers or via the TAGs.\nIn the Document Load Latency view, if you look at the Browser, Browser Version \u0026 OS Name Tag views,you can see the various browser types and versions, as well as for the underlying OS.\nThis makes it easy to identify problems related to specific browser or OS versions, as they would be highlighted.\nIn the above example you can see that Firefox had the slowest response, various Browser versions ( Chrome) that have different response times and the slow response of the Android devices.\nA further example are the regional Tags that you can use to identify problems related to ISP or locations etc. Here you should be able to find the location you have been using to access the Online Boutique. Drill down by selecting the town or country you are accessing the Online Boutique from by clicking on the name as shown below (City of Amsterdam):\nThis will select only the traces relevant to the city selected as shown below:\nBy selecting the various Tag you build up a filter, you can see the current selection below\nTo clear the filter and see every trace click on Clear All at the top right of the page.\nIf the overview page is empty or shows , no traces have been received in the selected timeslot. You need to increase the time window at the top left. You can start with the Last 12 hours for example.\nYou can then use your mouse to select the time slot you want like show in the view below and activate that time filter by clicking on the little spyglass icon.\n","categories":"","description":"","excerpt":" Look into the Metrics views for the various endpoints and use the …","ref":"/observability-workshop/v4.41/rum/docs/tag-spotlight/","tags":"","title":"Analyzing RUM Tags in the Tag Spotlight view"},{"body":"1. チャートの保存 チャートの保存するために、名前と説明をつけましょう。チャートの名前 Copy of Latency Histogram をクリックして、名前を “現在のレイテンシー” に変更します。\n説明を変更するには、 Spread of latency values across time. をクリックし、 リアルタイムでのレイテンシー値 に変更します。\n Save As    ボタンをクリックします。チャートに名前が付いていることを確認します。前のステップで定義した 現在のレイテンシー という名前が使用されますが、必要に応じてここで編集することができます。\n Ok    ボタンを押して続行します。\n2. ダッシュボードの作成 Choose dashboard ダイアログでは、新しいダッシュボードを作成する必要があります。 New Dashboard    ボタンをクリックしてください。\nこれで、New Dashboard ダイアログが表示されます。ここでは、ダッシュボードの名前と説明を付け、Write Permissions で書き込み権限を設定します。\nダッシュボードの名前には、自分のお名前を使って YOUR_NAME-Dashboard の形式で設定してください。\nYOUR_NAME を自分の名前に置き換えてから、編集権限をEveryone can Read or Write からRestricted Read and Write access に変更してみてください。\nここには、自分のログイン情報が表示されます。つまり、このダッシュボードを編集できるのは自分だけということになります。もちろん、ダッシュボードやチャートを編集できる他のユーザーやチームを下のドロップボックスから追加することもできますが、今回は、Everyone can Read or Write に 再設定 して制限を解除し、 Save    ボタンを押して続行してください。\n新しいダッシュボードが利用可能になり、選択されましたので、チャートを新しいダッシュボードに保存することができます。\nダッシュボードが選択されていることを確認して、 Ok    ボタンを押します。\nすると、下図のようにダッシュボードが表示されます。左上に、YOUR_NAME-DASHBOARD がダッシュボードグループ YOUR_NAME-Dashboard の一部であることがわかります。このダッシュボードグループに他のダッシュボードを追加することができます。\n 3. チームページへの追加 チームに関連するダッシュボードは、チームページにリンクさせるのが一般的です。そこで、後で簡単にアクセスできるように、ダッシュボードをチームページに追加してみましょう。左上のハンバーガーメニューを使い、サイドメニューから Dashboards を選択します。\nここでは、チーム Example Team を例にしていますが、ワークショップのものは異なります。\n +    を押し、 Add Dashboard Group ボタンを押して、チームページにダッシュボードを追加します。\nすると、 Select a dashboard group to link to this team ダイアログが表示されます。 検索ボックスにご自身のお名前（上記で使用したお名前）を入力して、ダッシュボードを探します。ダッシュボードがハイライトされるように選択し、Ok ボタンをクリックしてダッシュボードを追加します。\nダッシュボードグループがチームページの一部として表示されます。ワークショップを進めていくと、さらに多くのダッシュボードがここに表示されていくはずです。\n 次のモジュールでは、ダッシュボードのリンクをクリックして、チャートをさらに追加していきます！\n","categories":"","description":"","excerpt":"1. チャートの保存 チャートの保存するために、名前と説明をつけましょう。チャートの名前 Copy of Latency Histogram …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/savingcharts/","tags":"","title":"チャートを保存する"},{"body":"","categories":"","description":"**10 分**\n","excerpt":"**10 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/detectors/","tags":"","title":"ディテクターを利用する"},{"body":" Dive into RUM Session information in the RUM UI Identify Javascript errors in the Span of an user interaction   1. Again select the cart URL After you have focussed the time slot with the time selector, you need to reselect the cart url from Url Name view, as shown below:\nIn the example above we selected http://34.246.124.162:81/cart\n2. Drill down in the Sessions After you have analyzed the information and drilled down via the Tag Spotlight to a subset of the traces, you can view the actual session as it was run by the end-user’s browser.\nYou do this by clicking on the link Example Sessions as shown below:\nThis will give you a list of sessions that matched both the time filter and the subset selected in the Tag Profile.\nSelect one by clicking on the session ID, It is a good idea to select one that has the longest duration (preferably over 700 ms).\nOnce you have selected the session, you will be taken to the session details page. As you are selecting a specific action that is part of the session, you will likely arrive somewhere in the middle of the session, at the moment of the interaction.\nYou can see the URL http://34.246.124.162:81/cart, the one you selected earlier, is where we are focusing on in the session stream.\nScroll down a little bit on the page, so you see the end of the operation as shown below.\nYou can see that we have received a few Javascript Console errors that may not have been detected or visible to the end users. To examine these in more detail click on the middle one that says: *Cannot read properties of undefined (reading ‘Prcie’)\nThis will cause the page to expand and show the Span detail for this interaction, It will contain a detailed error.stack you can pass on the developer to solve the issue. You may have noticed when buying in the Online Boutique that the final total always was $0.00.\n","categories":"","description":"","excerpt":" Dive into RUM Session information in the RUM UI Identify Javascript …","ref":"/observability-workshop/v4.41/rum/docs/rum-sessions/","tags":"","title":"Analyzing RUM Sessions"},{"body":"","categories":"","description":"**10 minutes**\n","excerpt":"**10 minutes**\n","ref":"/observability-workshop/v4.41/imt/docs/monitoring-as-code/","tags":"","title":"Monitoring as Code"},{"body":"","categories":"","description":"**10 分**\n","excerpt":"**10 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/monitoring-as-code/","tags":"","title":"Monitoring as Code"},{"body":" Terraform1 を使用して Observability Cloud のダッシュボードとディテクターを管理します。 Terraform のSplunk Provider2 を初期化します Terraformを実行して、Splunk Terraform Provider を使用してコードからディテクターとダッシュボードを作成します。 Terraformでディテクターやダッシュボードを削除する方法を確認します。   1. 初期設定 Monitoring as Codeは、infrastructure as Codeと同じアプローチを採用しています。アプリケーション、サーバー、その他のインフラコンポーネントと同じようにモニタリングを管理できます。\nMonitoring as Codeでは、可視化したり、何を監視するか定義したり、いつアラートを出すかなどを管理します。つまり、監視設定、プロセス、ルールをバージョン管理、共有、再利用することができます。\nSplunk Terraform Providerの完全なドキュメントはこちら にあります。\nAWS/EC2 インスタンスにログインして、signalfx-jumpstart ディレクトリに移動します\nChange directory   cd ~/signalfx-jumpstart  必要な環境変数は、Helmによるインストール ですでに設定されているはずです。そうでない場合は、以下の Terraform のステップで使用するために、以下の環境変数を作成してください。\nEnvironment Variables   export ACCESS_TOKEN=\u003creplace_with_O11y-Workshop-ACCESS_token\u003e export REALM=\u003creplace_with_splunk_realm\u003e  Terraform を初期化し、Splunk Terraform Provider を最新版にアップグレードします。\nNote: SignalFx Terraform Provider のアップグレード\nSplunk Terraform Provider の新バージョンがリリースされるたびに、以下のコマンドを実行する必要があります。リリース情報は GitHub で確認できます。\n  Initialise Terraform  Initialise Output   terraform init -upgrade Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kafka in modules/kafka - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Finding latest version of splunk-terraform/signalfx... - Installing splunk-terraform/signalfx v6.7.10... - Installed splunk-terraform/signalfx v6.7.10 (signed by a HashiCorp partner, key ID 8B5755E223754FC9) Partner and community providers are signed by their developers. If you'd like to know more about provider signing, you can read about it here: https://www.terraform.io/docs/cli/plugins/signing.html Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \"terraform init\" in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary.  2. プランの作成 terraform plan コマンドで、実行計画を作成します。デフォルトでは、プランの作成は以下のように構成されています。\n 既に存在するリモートオブジェクトの現在の状態を読み込み、Terraform の状態が最新であることを確認します 現在の設定を以前の状態と比較し、相違点を抽出します 適用された場合にリモートオブジェクトと設定とを一致させるための、一連の変更アクションを提案します  plan コマンドだけでは、提案された変更を実際に実行はされなません。変更を適用する前に、以下のコマンドを実行して、提案された変更が期待したものと一致するかどうかを確認しましょう。\nExecution Plan  Execution Plan Output   terraform plan -var=\"access_token=$ACCESS_TOKEN\" -var=\"realm=$REALM\" -var=\"sfx_prefix=[$(hostname)]\" Plan: 92 to add, 0 to change, 0 to destroy.  プランが正常に実行されれば、そのまま apply することができます。\n 3. プランの適用 terraform apply コマンドは、上記の Terraform プランで提案されたアクションを実行します。\nこの場合、新しい実行プランが自動的に作成され（terraform planを実行したときと同様です）、指示されたアクションを実行する前にAccess Token、Realm（プレフィックスのデフォルトはSplunk）の提供とプランの承認を求められます。\nこのワークショップでは、プレフィックスがユニークである必要があります。以下の terraform apply を実行してください。\nApply Plan  Apply Plan Output   terraform apply -var=\"access_token=$ACCESS_TOKEN\" -var=\"realm=$REALM\" -var=\"sfx_prefix=[$(hostname)]\" Apply complete! Resources: 92 added, 0 changed, 0 destroyed.  適用が完了したら、 Alerts → Detectors でディテクターが作成されたことを確認してください。ディテクターのプレフィックスには、インスタンスのホスト名が入ります。プレフィックスの値を確認するには以下を実行してください。\nEcho Hostname   echo $(hostname)  新しいディテクターのリストが表示され、上から出力されたプレフィックスを検索することができます。\n4. 苦労して作ったもの全てを壊す terraform destroy コマンドは、Terraform の設定で管理されているすべてのリモートオブジェクトを破壊する便利な方法です。\n通常、本番環境では長期保存可能なオブジェクトを破棄することはありませんが、Terraformでは開発目的で一時的なインフラを管理するために使用されることがあり、その場合は作業が終わった後に terraform destroy を実行して、一時的なオブジェクトをすべてクリーンアップすることができます。\nそれでは、ここまでで適用したダッシュボードとディテクターを全て破壊しましょう！\nDestroy  Destroy Output   terraform destroy -var=\"access_token=$ACCESS_TOKEN\" -var=\"realm=$REALM\" Destroy complete! Resources: 92 destroyed.  Alerts → Detectors に移動して、すべてのディテクターが削除されたことを確認してください。\n  Terraform は、インフラを安全かつ効率的に構築、変更、バージョン管理するためのツールです。Terraform は、既存の一般的なサービスプロバイダーだけでなく、様々なカスタムソリューションも管理できます。\nTerraform の設定ファイルには、単一のアプリケーションまたはデータセンター全体を実行するために必要なコンポーネントをに記述します。Terraform はそれを受けて、望ましい状態に到達するために何をするかを記述した実行プランを生成し、記述されたインフラを構築するために実行します。設定が変更されても、Terraform は何が変更されたかを判断し、差分の実行プランを作成して適用することができます。\nTerraform が管理できるインフラには、計算機インスタンス、ストレージ、ネットワークなどのローレベルのコンポーネントや、DNSエントリ、SaaS機能などのハイレベルのコンポーネントが含まれます。 ↩︎\n プロバイダーは、APIのインタラクションを理解し、リソースを公開する責務があります。一般的にプロバイダーは、IaaS（Alibaba Cloud、AWS、GCP、Microsoft Azure、OpenStackなど）、PaaS（Herokuなど）、またはSaaSサービス（Splunk、Terraform Cloud、DNSimple、Cloudflareなど）があります。 ↩︎\n   ","categories":"","description":"","excerpt":" Terraform1 を使用して Observability Cloud のダッシュボードとディテクターを管理します。 Terraform …","ref":"/observability-workshop/v4.41/ja/imt/docs/monitoring-as-code/terraform/","tags":"","title":"Monitoring as Code"},{"body":"Below are helpful resources about Splunk and the DevOps use case. Topics covered are Observability Cloud, Splunk On-Call, OpenTelemetry, Observability and Incident Response.\nDocumentation   IMT    Splunk Infrastructure Monitoring  APM    Splunk Application Performance Monitoring (APM)  LO    Splunk Log Observer  RUM    Splunk Real User Monitoring (RUM)  Synthetics    Splunk Synthetics Monitoring  API    Splunk Observability Cloud API Docs  Blog Posts   APM    How Splunk Does Site Reliability Engineering (SRE)  APM    Application Performance Redefined: Meet the New Splunk’s Microservices APM  Splunk    Splunk is Lambda Ready: Announcing a New Partnership with AWS  APM    Supporting APM for .NET Applications  OpenTelemetry    OpenTelemetry Consolidates Data for Observability  Observability    Using Observability as a Proxy for User Happiness  Observability    Observability is key to the future of software (and your DevOps career)  OpenTelemetry    Why to Use OpenTelemetry Processors to Change Collected Backend Data  APM    What Is Distributed Tracing and Why You Need It  APM    Understanding Cardinality in a Monitoring System and Why It’s Important  Observability    How to Monitor Your AWS Workloads  Observability    How to Maximize the Performance of Your Kubernetes Deployment  Webinars \u0026 Podcasts   Splunk    .conf Online  OpenTelemetry    OpenTelemetry Agent and Collector: Telemetry Built-in Into All Software  APM    Future of Microservices and APM  DevOps    Dissecting DevOps PlayList  Observability    A murder mystery: who killed our user experience?  ","categories":"","description":"","excerpt":"Below are helpful resources about Splunk and the DevOps use case. …","ref":"/observability-workshop/v4.41/resources/","tags":"","title":"Additional Splunk for DevOps Resources"},{"body":" RUM UIでRUM Sessionの情報を調査する ユーザーインタラクションのSpanでJavascriptのエラーを特定する   1. cart URLを再び選択 タイムセレクタで時間帯を選択した後、以下のように Url Nameビューから cart URLを再選択する必要があります。\n上の例では http://34.246.124.162:81/cart を選択しました。\n2. Sessionsにドリルダウン Tag Spotlightで情報を分析し、トレースのサブセットをドリルダウンした後、エンドユーザーのブラウザーで実行された実際のセッションを表示することができます。\n以下のように Example Sessions というリンクをクリックすることで行います。\nこれにより、時間フィルタとタグプロファイルで選択したサブセットの両方に一致するセッションのリストが表示されます。\nセッションIDをクリックします。最も長い時間（700 ミリ秒以上が望ましい）のものを選択するとよいでしょう。\nセッションを選択すると、セッションの詳細ページが表示されます。セッションの一部である特定のアクションを選択しているため、セッション内のどこかのインタラクションにたどり着く可能性が高いです。 先ほど選択したURL http://34.246.124.162:81/cart が、セッションストリームでフォーカスしている場所であることがわかります。\nページを少し下にスクロールすると、以下のように操作の終わりが表示されます。\nエンドユーザーには検出されなかったか、または表示されなかった可能性のあるいくつかのJavaScript Consoleエラーが発生していることがわかります。これらのエラーを詳しく調べるには、真ん中のエラー Cannot read properties of undefined (reading ‘Prcie’) をクリックしてください。\nこれによってページが展開され、このインタラクションのSpanの詳細が表示されます。このページには、問題を解決するために開発者に渡すことができる詳細な error.stack が含まれます。Online Boutiqueで商品を購入した際、最終的な合計金額が常に0ドルであることにお気づきでしょうか。\n","categories":"","description":"","excerpt":" RUM UIでRUM Sessionの情報を調査する ユーザーインタラクションのSpanでJavascriptのエラーを特定する   1. …","ref":"/observability-workshop/v4.41/ja/rum/docs/rum-sessions/","tags":"","title":"RUM Sessionの分析"},{"body":"サンプルトレース 右上にある「Services by Error Rate」グラフのピンク色の線上をクリックします。選択すると、サンプルトレースのリストが表示されます。Initiating Operation ofが frontend: POST /cart/checkout であるサンプルトレースの1つをクリックしてください。\nスパンとともに、選択したトレースの全体が表示されます。エラーが発生したスパンは、その横に赤い！マークが表示されます。グレーのボックスにx6などの数字が表示されている場合は、それをクリックするとpaymentservice スパンを展開することができます。\n赤い！マークが表示されたpaymentservice スパンの一つをクリックすると展開され、関連するメタデータやエラーの詳細が表示されます。このエラーが401エラーによるものであることがわかります。また、「テナント」や「バージョン」などの有用な情報も表示されています。\nエラーの原因が 無効なリクエスト であることがわかりましたが、正確なリクエストが何であるかはわかりません。ページの下部に、ログへのコンテキストリンクが表示されます。このリンクをクリックすると、このスパンに関連付けられているログが表示されます。\n下の画像と同様の Log Observer ダッシュボードが表示されます。\nフィルタを使用して、エラーログのみを表示できます。右上にあるERRORをクリックしてから、Add to filterをクリックします。\nYou should now have a shorter list of log entries which have a severity of ERROR severityがERRORであるログエントリに絞り込まれます。\nいずれかのエントリを選択して詳細を表示します。これで、開発者が誤って本番環境にプッシュした 無効なAPIトークン の使用によってエラーがどのように発生したかを確認できます。\nおめでとうございます。これで、このAPMワークショップは完了です。\n","categories":"","description":"","excerpt":"サンプルトレース 右上にある「Services by Error Rate」グラフのピンク色の線上をクリックします。選択すると、サンプルト …","ref":"/observability-workshop/v4.41/ja/apm/docs/using-splunk-apm/example_trace/","tags":"","title":"サンプルトレース"},{"body":"","categories":"","description":"**10 分**\n","excerpt":"**10 分**\n","ref":"/observability-workshop/v4.41/ja/imt/docs/servicebureau/","tags":"","title":"管理機能"},{"body":" Continue with the RUM Session information in the RUM UI See correlated APM traces and logs in the APM \u0026 Log Observer UI   1. Finding backend service issues Click on the to close the Span view. Now continue to scroll down and find the POST /cart/checkout line.\nClick on the blue link, this should pop up a dialog showing information on the backend services that were part of the checkout action taken by the end user.\nIn this popup, there are multiple sections available, providing you with a quick insight in the behavior of your backend services. For example the Performance Summary section will tell you where the time was spent during the backend call.\nIn the above example you can see that more than 77,9% was spent in external services.\nIf you scroll down to the bottom of the dialog, you can see the complete Trace and Services section like shown below:\nin the Services map, you can see two services flagged red, the Checkout Service and the Payment Service in both in dark red. Light red means it received an error and dark red means an error originated from that service.\nSo already it is obvious there is a problem in the back end services.\nLet’s investigate!\n2. Follow the Trace to the Backend service You can now click on the Trace Id link:\nThis will bring you to the Waterfall APM view that will show you what occurred in detail in a call to the backend services. On the right you see the Trace Id: and again the Performance Summary, as we saw before. In the waterfall, you can identify the various backend services that were part of this call from the frontend.\nAs you can see there are red error indicators before the Checkout Service and the Payment Service.\nClick on the after the paymentservice: grpc.hipstershop.PaymentService/Charge line.\nThis will open the span detail page to show you the detailed information about this service call. You wil see that the call returned a 401 error code or Invalid Request.\n3. Use the Related Content - Logs As the Splunk Observability cloud suite correlates trace metrics and logs automatically, the system will show you in the related content bar at the bottom of the page, the corresponding logs for this trace.\nClick on the Log link to see the logs.\nWhen the logs are shown, notice that the filter at the top of the page contains the logs for the trace. Next select one of the lines indicating an error for the payment service. This should open the log message on the right.\nIt clearly shows the reason why the payment service fails: we are using an invalid token towards the service:\n*Failed payment processing through ButtercupPayments: Invalid API Token (test-20e26e90-356b-432e-a2c6-956fc03f5609)\n4. Conclusion In the workshop, you have seen how to add RUM functionality to you website. We investigate the performance of your Website using RUM Metrics. Using the Tag profile, you have searched for your own session, and with the session waterfall, you identified two problems:\n A Java script error that caused your price calculation to be zero. An issue in the payment backend service that caused payments to fail.  Using the ability to correlate RUM traces with the Backend APM trace and Logs, you have found the reason for the payment failure.\nThis concludes the RUM workshop.\n","categories":"","description":"","excerpt":" Continue with the RUM Session information in the RUM UI See …","ref":"/observability-workshop/v4.41/rum/docs/apm-correlation/","tags":"","title":"Correlate between Splunk RUM and APM backend services"},{"body":"1. Increase the HPA replica count Increase the maxReplicas to 8\nkubectl edit hpa php-apache -n apache  Workshop Question\nHow many pods are now in a running state? How many are pending? Why are they pending?   2. Stop the load test kubectl delete -f loadgen.yaml --namespace loadgen  Workshop Question\nWhat eventually happens to the php-apache pods when the load test is stopped?   ","categories":"","description":"","excerpt":"1. Increase the HPA replica count Increase the maxReplicas to 8 …","ref":"/observability-workshop/v4.41/tko/session-5/docs/edit-hpa/","tags":"","title":"Increase HPA Replicas"},{"body":" RUM UIでRUM Sessionの情報を続けます APM \u0026 Log Observer UI で相関する APM トレースとログを確認します   1. バックエンドサービスの問題を発見 をクリックして、Spanビューを閉じます。 次に下にスクロールし、 POST /cart/checkout の行を見つけます。\n青色の リンクをクリックすると、エンドユーザが行ったチェックアウト操作の一部であるバックエンドサービスに関する情報を示すダイアログがポップアップ表示されます。\nこのポップアップでは複数のセクションが用意されており、バックエンドサービスの挙動を素早く把握することができます。例えば、Performance Summaryセクションでは、バックエンドの呼び出し中にどこに時間が費やされたかを知ることができます。\n上記の例では77.9%以上が外部サービスに費やされていることがわかります。\nダイアログの一番下までスクロールすると、下図のような「トレースとサービス」セクションが表示されます。\nCheckout サービスと Payment サービスが、両方とも濃い赤色で表示されています。薄い赤はエラーを受け取ったことを意味し、濃い赤はそのサービスから発生したエラーを意味します。\nつまり、すでにバックエンドのサービスに問題があることは明白なのです。\n調査してみましょう！\n2. Backendサービスまでのトレースをたどる Trace Idリンクをクリックすることができます。\nこれにより、バックエンドサービスへの呼び出しで何が起こったかを詳細に示すウォーターフォールAPMビューが表示されます。 右側には、Trace IDと、前に見たように、Performance Summuryが表示されています。 ウォーターフォールでは、フロントエンドからの呼び出しの一部である様々なバックエンドサービスを特定することができます。\nご覧のように、 Checkout サービスと Payment サービスの前に赤いエラーインジケータ が見えます。\npaymentservice: grpc.hipstershop.PaymentService/Charge の行の後にある をクリックしてください。\nSpanの詳細ページが表示され、このサービスコールの詳細情報が表示されます。 401 エラーコード、つまり Invalid Request が返されたことが確認できます。\n3. 関連するログを確認 Splunk Observability Cloudは、トレースメトリクスとログを自動的に関連付けるため、ページ下部の関連コンテンツバーに、このトレースに対応するログが表示されます。\nLogのリンクをクリックすると、ログが表示されます。\nログが表示されたら、ページの上部にあるフィルターにクリック元のTrace IDがセットされ、このトレースに関連するログが表示されていることに注意してください。 次にPaymentサービスのエラーを示す行の1つを選択すると右側にログメッセージが表示されます。\nここにPaymentサービスが失敗した理由が明確に示されています。サービスに対して無効なトークンを使用しているのです。\n*Failed payment processing through ButtercupPayments: Invalid API Token (test-20e26e90-356b-432e-a2c6-956fc03f5609)\n4. まとめ このワークショップではRUMをWebサイトに追加する方法を確認しました。 RUMメトリクスを使用してWebサイトのパフォーマンスを調査しました。 Tag Profileを使用して、自分のセッションを検索し、セッションウォーターフォールを使用して、2つの問題を特定しました。\n JavaScriptのエラーにより、価格の計算が 0 になっていました。 支払いバックエンドサービスに問題があり支払いに失敗することがありました。  RUMのトレースとバックエンドAPMのトレースおよびログを関連付ける機能を使用して、支払い失敗の原因を発見しました。\n","categories":"","description":"","excerpt":" RUM UIでRUM Sessionの情報を続けます APM \u0026 Log Observer UI で相関する APM トレースとログを確認 …","ref":"/observability-workshop/v4.41/ja/rum/docs/apm-correlation/","tags":"","title":"Splunk RUM と APM バックエンドサービスの相関"},{"body":"1 Creating a new chart Let’s now create a new chart and save it in our dashboard!\nSelect the plus icon (top right of the UI) and from the drop down, choose the option Chart. Or click on the + New Chart    Button to create a new chart.\nYou will now see a chart template like the following.\nLet’s enter a metric to plot. We are still going to use the metric demo.trans.latency.\nIn the Plot Editor tab under Signal enter demo.trans.latency.\nYou should now have a familiar line chart. Please switch the time to 15 mins.\n2. Filtering and Analytics Let’s now select the Paris datacenter to do some analytics - for that we will use a filter.\nLet’s go back to the Plot Editor tab and click on Add Filter    , wait until it automatically populates, choose demo_datacenter, and then Paris.\nIn the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm).\nFor info on the Percentile function and the other functions see Chart Analytics.\n 3. Using Timeshift analytical function Let’s now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A.\nYou will see a new row identical to A, called B, both visible and plotted.\nFor Signal B, in the F(x) column add the analytic function Timeshift and enter 1w (or 7d for 7 days), and click outside to confirm.\nClick on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B.\nClick on Close.\nWe now see plots for Signal A (the past 15 minutes) as a blue plot, and the plots from a week ago in pink.\nIn order to make this clearer we can click on the Area chart icon to change the visualization.\nWe now can see when last weeks latency was higher!\nNext, click into the field next to Time on the Override bar and choose Past Hour from the dropdown.\n 4. Using Formulas Let’s now plot the difference of all metric values for a day with 7 days in between.\nClick on Enter Formula    then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C.\nWe now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time.\nLets look at the Signalflow that drives our Charts and Detectors!\n","categories":"","description":"","excerpt":"1 Creating a new chart Let’s now create a new chart and save it in our …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/filtering/","tags":"","title":"Using Filters \u0026 Formulas"},{"body":"1 新しいチャートの作成 それでは、新しいチャートを作成し、ダッシュボードに保存してみましょう。\nUIの右上にある + アイコンを選択し、ドロップダウンから Chart を選択します。 または、 + New Chart    ボタンをクリックすると、新しいチャートが作成されます。\nこれで、以下のようなチャートのテンプレートが表示されます。\nプロットするメトリックを入力してみましょう。ここでは、demo.trans.latency というメトリックを使用します。\nPlot Editor タブの Signal に demo.trans.latency を入力します。\nすると、折れ線グラフが表示されるはずです。時間を15分に切り替えてみてください。\n2. フィルタリングと分析 次に、Paris データセンターを選択して分析を行ってみましょう。そのためにはフィルタを使用します。\nPlot Editor タブに戻り、 Add Filter    をクリックして、入力補助として選択肢が出てくるので、そこから demo_datacenter を選択し、Paris を選択します。\nF(x) 欄に分析関数 Percentile:Aggregation を追加し、値を 95 にします（枠外をクリックすると設定が反映されます）。\nPercentile 関数やその他の関数の情報は、Chart Analytics を参照してください。\n 3. タイムシフト分析を追加 それでは、以前のメトリックと比較してみましょう。... をクリックして、ドロップダウンから Clone をクリックし、Signal A をクローンします。\nA と同じような新しい行が B という名前で表示され、プロットされているのがわかります。\nシグナル B に対して、F(x) 列に分析関数 Timeshift を追加し、1w（もしくは 7d でも同じ意味です）と入力し、外側をクリックして反映させます。\n右端の歯車をクリックして、Plot Color を選択（例：ピンク）すると、 B のプロットの色を変更できます。\nClose をクリックして、設定を終えます。\nシグナル A （過去15分）のプロットが青、1週間前のプロットがピンクで表示されています。\nより見やすくするために、Area chart アイコンをクリックして表示方法を変更してみましょう。\nこれで、前週にレイテンシーが高かった時期を確認することができます。\n次に、Override バーの Time の隣にあるフィールドをクリックし、ドロップダウンから **Past Hour**を 選択してみましょう。\n 4. 計算式を使う ここでは、1日と7日の間のすべてのメトリック値の差をプロットしてみましょう。\n Enter Formula    をクリックして、A-B （AからBを引いた値）を入力し、C を除くすべてのシグナルを隠します（目アイコンの選択を解除します）。\nこれで、 A と B のすべてのメトリック値の差だけがプロットされているのがわかります。B のメトリック値が、その時点での A のメトリック値よりも何倍か大きな値を持っているためです。\n次のモジュールで、チャートとディテクターを動かすための SignalFlow を見てみましょう。\n","categories":"","description":"","excerpt":"1 新しいチャートの作成 それでは、新しいチャートを作成し、ダッシュボードに保存してみましょう。\nUIの右上にある + アイコンを選択し、ド …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/filtering/","tags":"","title":"フィルタと数式の使い方"},{"body":" Use RUM Metrics to set up Alerts to be warned in case of an issue Create a Custom Chart based on RUM Metrics   1. Overview The fact that Splunk’s RUM is designed as a full fidelity solution, and thus can take 100% of your traces, allows it to detect and alert you to any change to the behavior of your website. It also give you the ability to to give you accurate insight in how your website is behaving by allowing you to creating custom Chart and Dashboards. This allows you to combine data from your Website, Backend service and underlying Infrastructure. Allowing you to observe the complete stack that makes up your application/solution.\nCreating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert.\nIf you previously done the Splunk IMT Part of the Workshop, you will find this section very familiar. If you have not done the Splunk IMT workshop before, it is recommended that you run though the Dashboards and Detectors modules after completing the RUM workshop to get a better understanding of the capabilities.\n2. Create an alert on one of the RUM Metrics From the top left hamburger menu icon click Alerts in the menu and then select Detectors.\n3. Create a Chart based on Rum Metrics 3.1 Overview Creating charts or alerts for RUM Metrics are done in the same way as we do for Infrastructure Metrics. In this section we will create a simple chart, detector and alert If you previously done the Splunk IMT Part of the Workshop, you will find this section very familiar.\nu have added to the trace as part of the configuration of your website.\nAddtional Tags\nWe are already sending two additional tags, you have seen them defined in the Beacon url that was added to your website in the first section of this workshop! You can add additional tag in a similar way.\napp: \"[nodename]-rum-app\", environment: \"[nodename]-rum-env\"    ","categories":"","description":"","excerpt":" Use RUM Metrics to set up Alerts to be warned in case of an issue …","ref":"/observability-workshop/v4.41/rum/docs/alerting/","tags":"","title":"Custom Charts and Alerts based on RUM Metrics"},{"body":" RUMメトリクスを使用して、問題が発生した場合に警告するAlertsを設定する RUMメトリクスに基づくカスタムチャートを作成する   1. 概要 SplunkのRUMは完全忠実なソリューションとして設計されているため、お客様のトレースを100％取得することができ、Webサイトの動作の変化を検知して警告することができます。また、カスタムチャートとダッシュボードを作成することで、Webサイトの挙動を正確に把握することができます。 これにより、ウェブサイト、バックエンド・サービス、基盤となるインフラストラクチャからのデータを組み合わせることができます。これにより、お客様のアプリケーションやソリューションを構成する完全なスタックを観察することができます。\nRUMメトリクスのチャートまたはアラートの作成は、インフラストラクチャのメトリクスと同じ方法で行います。このセクションでは、簡単なチャート、ディテクター、およびアラートを作成します。\nSplunk IMT ワークショップを受講したことがある方は、このセクションをよくご存知でしょう。Splunk IMT ワークショップの経験がない場合は、RUM ワークショップの終了後に ダッシュボード と ディテクター モジュールを参照して、機能をよりよく理解することをお勧めします。\n","categories":"","description":"","excerpt":" RUMメトリクスを使用して、問題が発生した場合に警告するAlertsを設定する RUMメトリクスに基づくカスタムチャー …","ref":"/observability-workshop/v4.41/ja/rum/docs/alerting/","tags":"","title":"RUMメトリクスに基づくカスタムチャートとアラート"},{"body":"You will need an access token for Splunk Observability Cloud. Set them up as environment variables:\nexport SPLUNK_ACCESS_TOKEN=YOURTOKEN export SPLUNK_REALM=YOURREALM Start with the default configuration for the OpenTelemetry Collector and name it collector.yaml in the src directory.\nYou can also start with a blank configuration, which is what the milestone does for clarity.\nThen run OpenTelemetry Collector with this configuration in a docker container:\nShell Command   docker run --rm \\  -e SPLUNK_ACCESS_TOKEN=${SPLUNK_ACCESS_TOKEN} \\  -e SPLUNK_REALM=${SPLUNK_REALM} \\  -e SPLUNK_CONFIG=/etc/collector.yaml \\  -p 13133:13133 -p 14250:14250 -p 14268:14268 -p 4317:4317 \\  -p 6060:6060 -p 8888:8888 -p 9080:9080 -p 9411:9411 -p 9943:9943 \\  -v \"${PWD}/collector.yaml\":/etc/collector.yaml:ro \\  --name otelcol quay.io/signalfx/splunk-otel-collector:0.41.1  The milestone for this task is 03service-metrics-otel.\n","categories":"","description":"","excerpt":"You will need an access token for Splunk Observability Cloud. Set them …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/otel/","tags":"","title":"Deploy OpenTelemetry in Docker"},{"body":" Short introduction to Mobile RUM See an overview of the performance of your Mobile Application(s) in the Application Summary Dashboard   1. Visit your RUM Application Summary Dashboard Visit and login into your Splunk IMT/APM/RUM Website. From the left side menu bar select RUM . This will bring you to your RUM Application Summary Page.\nThe goal of this page is to give you in a single pane/dashboard, a clear indication of the health, performance and potential errors found in your application(s) and allow you dive deeper into the information about your User Session ran against your web site.\nYou will have a pane for each of your active RUM applications. (The view below is the default expanded view)\nIf you have multiple applications, the pane view may be automatically reduced by collapsing the panes as shown below:\nYou can expanded a condensed RUM Application Summary View to the full dashboard by clicking on the small browser or Mobile icon. (Depending on the type of application: Mobile or Browser based) on the left in front of the applications name, highlighted by the red arrow.\n2. RUM Mobile Overview Splunk RUM supports Native Mobile RUM, for Apple iPhone and Android Phones. You can use this to see the End-user experience of your native Smartphone app.\nThe above screen is to show you the various metrics and data Splunk Mobile RUM can track. For example:\n Custom events, similar to the Browser version. App Errors , with App Errors \u0026 Crashes per minute. App Lifecycle Performance, with Cold Startup Time, Hot Startup Time per OS. Request/Response, similar to the Browser version.  At this point we will not go deeper into Mobile RUM, due to the need to run either a native app on a phone, or run an emulation. We can provide more information in a deep dive demo if needed.\n","categories":"","description":"","excerpt":" Short introduction to Mobile RUM See an overview of the performance …","ref":"/observability-workshop/v4.41/rum/docs/mobile-app-summary/","tags":"","title":"Mobile Applications (Introduction)"},{"body":"1. Introduction Let’s take a look at SignalFlow - the analytics language of Observability Cloud that can be used to setup monitoring as code.\nThe heart of Splunk Infrastructure Monitoring is the SignalFlow analytics engine that runs computations written in a Python-like language. SignalFlow programs accept streaming input and produce output in real time. SignalFlow provides built-in analytical functions that take metric time series (MTS) as input, perform computations, and output a resulting MTS.\n Comparisons with historical norms, e.g. on a week-over-week basis Population overviews using a distributed percentile chart Detecting if the rate of change (or other metric expressed as a ratio, such as a service level objective) has exceeded a critical threshold Finding correlated dimensions, e.g. to determine which service is most correlated with alerts for low disk space  Infrastructure Monitoring creates these computations in the Chart Builder user interface, which lets you specify the input MTS to use and the analytical functions you want to apply to them. You can also run SignalFlow programs directly by using the SignalFlow API.\nSignalFlow includes a large library of built-in analytical functions that take a metric time series as an input, performs computations on its datapoints, and outputs time series that are the result of the computation.\nInfo\nFor more information on SignalFlow see Analyze incoming data using SignalFlow.   2. View SignalFlow In the chart builder, click on View SignalFlow.\nYou will see the SignalFlow code that composes the chart we were working on. You can now edit the SignalFlow directly within the UI. Our documentation has the full list of SignalFlow functions and methods.\nAlso, you can copy the SignalFlow and use it when interacting with the API or with Terraform to enable Monitoring as Code\nSignalFlow   A = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).publish(label='A', enable=False) B = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).timeshift('1w').publish(label='B', enable=False) C = (A-B).publish(label='C')  Click on View Builder to go back to the Chart Builder UI.\nLet’s save this new chart to our Dashboard!\n","categories":"","description":"","excerpt":"1. Introduction Let’s take a look at SignalFlow - the analytics …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/signalflow/","tags":"","title":"SignalFlow"},{"body":"1. はじめに ここでは、Observability Cloud の分析言語であり、Monitoring as Codeを実現するために利用する SignalFlow について見てみましょう。\nSplunk Infrastructure Monitoring の中心となるのは、Python ライクな、計算を実行する SignalFlow 分析エンジンです。SignalFlow のプログラムは、ストリーミング入力を受け取り、リアルタイムで出力します。SignalFlow には、時系列メトリック（MTS）を入力として受け取り、計算を実行し、結果の MTS を出力する分析関数が組み込まれています。\n 過去の基準との比較する（例：前週との比較） 分布したパーセンタイルチャートを使った母集団の概要を表示する 変化率（またはサービスレベル目標など、比率で表されるその他の指標）が重要な閾値を超えたかどうか検出する 相関関係にあるディメンジョンの発見する（例：どのサービスの挙動がディスク容量不足の警告と最も相関関係にあるかの判断する）  Infrastructure Monitoring は、Chart Builder ユーザーインターフェイスでこれらの計算を行い、使用する入力 MTS とそれらに適用する分析関数を指定できます。また、SignalFlow API を使って、SignalFlow のプログラムを直接実行することもできます。\nSignalFlow には、時系列メトリックを入力とし、そのデータポイントに対して計算を行い、計算結果である時系列メトリックを出力する、分析関数の大規模なライブラリが組み込まれています。\nInfo\nSignalFlow の詳細については、 Analyze incoming data using SignalFlow を参照してください。\n  2. SignalFlow の表示 チャートビルダーで View SignalFlow をクリックします。\n作業していたチャートを構成する SignalFlow のコードが表示されます。UI内で直接 SignalFlow を編集できます。ドキュメントには、SignalFlow の関数やメソッドの 全てのリスト が掲載されています。\nまた、SignalFlow をコピーして、API や Terraform とやり取りする際に使用して、Monitoring as Code を実現することもできます。\nSignalFlow   A = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).publish(label='A', enable=False) B = data('demo.trans.latency', filter=filter('demo_datacenter', 'Paris')).percentile(pct=95).timeshift('1w').publish(label='B', enable=False) C = (A-B).publish(label='C')  View Builder をクリックすると、Chart Builder の UI に戻ります。\nこの新しいチャートをダッシュボードに保存してみましょう!\n","categories":"","description":"","excerpt":"1. はじめに ここでは、Observability Cloud の分析言語であり、Monitoring as Codeを実現するために利用 …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/signalflow/","tags":"","title":"SignalFlow"},{"body":" Mobile RUMの簡単な紹介 Application Summary ダッシュボードで、モバイルアプリケーションの\nパフォーマンスの概要を確認できます   1. RUM Application Summary ダッシュボードにアクセス 左側のメニューバーから RUM を選択します。これで、RUM Application Summryページが表示されます。\nこのページの目的は、アプリケーションの健全性、パフォーマンス、潜在的なエラーを1つのペイン/ダッシュボードに表示し、Webサイトに対して実行されたユーザーセッションに関する情報を深く掘り下げることができるようにすることです。\nアクティブな RUM アプリケーションごとにペインが表示されます。(以下のビューは、デフォルトの拡張ビューです。）\n複数のアプリケーションを使用している場合、以下のようにペインが自動的に折りたたまれ、ペインビューが縮小されることがあります。\nアプリケーション名の前にある左側の赤い矢印で強調されている または アイコン(アプリケーションの種類が モバイル か ブラウザー かによる）をクリックすると、RUM Application Summryビューをフルダッシュボードに展開することが可能です。\n2. RUM Mobileの概要 Splunk RUM は Apple iPhone と Android Phone 向けの Native Mobile RUM をサポートしています。スマートフォンのネイティブアプリのエンドユーザーエクスペリエンスを確認するために使用することができます。\n上の画面は、Splunk Mobile RUM が追跡できるさまざまなメトリクスやデータを表示するものです。例えば、以下のようなものです。\n Custom events ：ブラウザーアプリケーションのものと同様です。 App Errors ：1分あたりの アプリエラー と クラッシュ 。 App Lifecycle Performance ：OSごとの コールドスタートアップ時間 、 ホットスタートアップ時間 。 Request/Response ：ブラウザーアプリケーションのものと同様です。  この時点では、スマートフォン上でネイティブアプリを実行するか、エミュレーションを実行する必要があるため、Mobile RUMについて深く掘り下げることはしません。必要に応じて、より詳細な情報をデモで提供することができます。\n","categories":"","description":"","excerpt":" Mobile RUMの簡単な紹介 Application Summary ダッシュボードで、モバイルアプリケーションの\nパフォーマンスの概 …","ref":"/observability-workshop/v4.41/ja/rum/docs/mobileapp-summary/","tags":"","title":"モバイルアプリケーション (紹介)"},{"body":"Let’s now save our chart.\n 1. Save to existing dashboard Check that you have YOUR_NAME-Dashboard: YOUR_NAME-Dashboard in the top left corner.\nThis means you chart will be saved in this Dashboard.\nName the Chart Latency History and add a Chart Description if you wish.\nClick on Save And Close   . This returns you to your dashboard that now has two charts!\nNow let’s quickly add another Chart based on the previous one.\n 2. Copy and Paste a chart Click on the three dots ... on the Latency History chart in your dashboard and then on Copy.\nYou see the chart being copied, and you should now have a red circle with a white 1 next to the + on the top left of the page.\nClick on the at the top of the page, and then in the menu on Paste Charts (There should also be a red dot with a 1 visible at the end of the line).\nThis will place a copy of the previous chart in your dashboard.\n 3. Edit the pasted chart Click on the three dots ... on one of the Latency History charts in your dashboard and then on Open (or you can click on the name of the chart which here is Latency History).\nThis will bring you to the editor environment again.\nFirst set the time for the chart to -1 hour in the Time box at the top right of the chart. Then to make this a different chart, click on the eye icon in front of signal “A” to make it visible again, and then hide signal “C” via the eye icon and change the name for Latency history to Latency vs Load.\nClick on the Add Metric Or Event    button. This will bring up the box for a new signal. Type and select demo.trans.count for Signal D.\nThis will add a new Signal D to your chart, It shows the number of active requests. Add the filter for the demo_datacenter:Paris, then change the Rollup type by clicking on the Configure Plot button and changing the roll-up from Auto (Delta) to Rate/sec. Change the name from demo.trans.count to Latency vs Load.\nFinally press the Save And Close    button. This returns you to your dashboard that now has three different charts!\nLet’s add an “instruction” note and arrange the charts!\n","categories":"","description":"","excerpt":"Let’s now save our chart.\n 1. Save to existing dashboard Check that …","ref":"/observability-workshop/v4.41/imt/docs/dashboards/adding-charts/","tags":"","title":"Adding charts to dashboards"},{"body":"Add a prometheus receiver to the OpenTelemetry Collector configuration so that it captures the metrics introduced in Task 2 from the application.\nHint: The hostname host.docker.internal allows you to access the host from within a docker container. Add\n--add-host=host.docker.internal:host-gateway to the docker run command for the OpenTelemetry collector. TODO test instructions\nValidate that you are getting data for the custom metric characters_recv_total introduced in Task 2.\nThe milestone for this task is 04service-metrics-prom.\n","categories":"","description":"","excerpt":"Add a prometheus receiver to the OpenTelemetry Collector configuration …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/otel-prometheus/","tags":"","title":"Capture Prometheus metrics"},{"body":"それでは、チャートを保存してみましょう。\n 1. 既存のダッシュボードに保存する 右上に YOUR_NAME-Dashboard と表示されていることを確認しましょう\nこれは、あなたのチャートがこのダッシュボードに保存されることを意味します。\nチャートの名前を Latency History とし、必要に応じてチャートの説明を追加します。\n Save And Close    をクリックします。これで、ダッシュボードに戻ると2つのチャートが表示されているはずです！\nでは、先ほどのチャートを元に、もう一つのチャートをさくっと追加してみましょう。\n 2. チャートのコピー＆ペースト ダッシュボードの Latency History チャート上の3つのドット ... をクリックし、 Copy をクリックします。\nページ左上の + の横に赤い円と白い1が表示されていれば、チャートがコピーされているということになります。\nページ上部の をクリックし、メニューの Paste Charts をクリックしてください (また、右側に 1 が見える赤い点があるはずです)。\nこれにより、先程のチャートのコピーがダッシュボードに配置されます。\n 3. 貼り付けたチャートを編集する ダッシュボードの Latency History チャートの3つの点 ... をクリックし、Open をクリックします（または、チャートの名前（ここでは Latency History）をクリックすることもできます）。\nすると、再び編集できる環境になります。\nまず、チャートの右上にあるタイムボックスで、チャートの時間を -1h（1時間前から現在まで） に設定します。そして、シグナル「A」の前にある目のアイコンをクリックして再び表示させ、「C」 を非表示にし、Latency history の名前を Latency vs Load に変更します。\n Add Metric Or Event    ボタンをクリックします。これにより、新しいシグナルのボックスが表示されます。シグナル D に demo.trans.count と入力・選択します。\nこれにより、チャートに新しいシグナル D が追加され、アクティブなリクエストの数が表示されます。demo_datacenter:Paris のフィルタを追加してから、 Configure Plot ボタンをクリックしロールアップを Auto (Delta) から Rate/sec に変更します。名前を demo.trans.count から Latency vs Load に変更します。\n最後に Save And Close    ボタンを押します。これでダッシュボードに戻り、3つの異なるチャートが表示されます。\n次のモジュールでは、「説明」のメモを追加して、チャートを並べてみましょう!\n","categories":"","description":"","excerpt":"それでは、チャートを保存してみましょう。\n 1. 既存のダッシュボードに保存する 右上に YOUR_NAME-Dashboard と表示され …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/adding-charts/","tags":"","title":"ダッシュボードにチャートを追加する"},{"body":"Dockerize the service. Use this Dockerfile as a skeleton:\nARG APP_IMAGE=python:3FROM$APP_IMAGE as baseFROMbase as builderWORKDIR/appRUN python -m venv .venv \u0026\u0026 .venv/bin/pip install --no-cache-dir -U pip setuptoolsCOPY requirements.txt .RUN .venv/bin/pip install -r requirements.txt --no-cache-dir -r requirements.txtFROMbaseWORKDIR/appCOPY --from=builder /app /appCOPY app.py .ENV PATH=\"/app/.venv/bin:$PATH\"Add the appropriate CMD at the end to launch the app.\nStop other instances of the app if you had any running.\nThen build and run the image:\nShell Command   docker build . -t wordcount docker run -p 5000:5000 wordcount:latest  Test the service in another shell:\nShell Command   curl -X POST http://127.0.0.1:5000/wordcount -F text=@hamlet.txt  The milestone for this task is 05docker.\n","categories":"","description":"","excerpt":"Dockerize the service. Use this Dockerfile as a skeleton:\nARG …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/docker/","tags":"","title":"Dockerize the Service"},{"body":"1. メモの追加 ダッシュボードには、ダッシュボードの利用者を支援するための短い「説明」ペインを配置することがよくあります。\nここでは、 New Text Note    ボタンをクリックして、ノートを追加してみましょう。\nすると、ノートエディターが開きます。\nノートに単なるテキスト以外のものを追加できるように、Splunk ではこれらのノート/ペインで Markdown を使用できるようにしています。 Markdown は、ウェブページでよく使われるプレーンテキストを使ってフォーマットされたテキストを作成するための軽量なマークアップ言語です。\nたとえば、以下のようなことができます (もちろん、それ以外にもいろいろあります)。\n ヘッダー (様々なサイズで) 強調スタイル リストとテーブル リンク: 外部の Web ページ (ドキュメントなど) や他の Splunk IMT ダッシュボードへの直接リンクできます  以下は、ノートで使用できる上記のMarkdownオプションの例です。\nSample Markdown text   # h1 Big headings  ###### h6 To small headings  ##### Emphasis  **This is bold text**, *This is italic text* , ~~Strikethrough~~ ##### Lists  Unordered + Create a list by starting a line with `+`, `-`, or `*` - Sub-lists are made by indenting 2 spaces: - Marker character change forces new list start: * Ac tristique libero volutpat at + Facilisis in pretium nisl aliquet * Very easy! Ordered 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa ##### Tables  | Option | Description | | ------ | ----------- | | chart | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | #### Links  [link to webpage](https://www.splunk.com) [link to dashboard with title](https://app.eu0.signalfx.com/#/dashboard/EaJHrbPAEAA?groupId=EaJHgrsAIAA\u0026configId=EaJHsHzAEAA \"Link to the Sample chart Dashboard!\")  上記をコピーボタンでコピーして、Edit ボックスにペーストしてみてください。 プレビューで、どのように表示されるか確認できます。\n 2. チャートの保存 ノートチャートに名前を付けます。この例では、Example text chart としました。そして、 Save And Close    ボタンを押します。\nこれでダッシュボードに戻ると、メモが追加されました。\n 3. チャートの順序や大きさを変更 デフォルトのチャートの順番やサイズを変更したい場合は、ウィンドウをドラッグして、チャートを好きな場所に移動したり、サイズを変更したりすることができます。\nチャートの 上側の枠 にマウスポインタを移動すると、マウスポインタがドラッグアイコンに変わります。これで、チャートを任意の場所にドラッグすることができます。\nここでは、 Latency vs Load チャートを Latency History と Example text chart の間に移動してください。\nチャートのサイズを変更するには、側面または底面をドラッグします。\n最後の練習として、ノートチャートの幅を他のチャートの3分の1程度にしてみましょう。チャートは自動的に、サポートしているサイズの1つにスナップします。他の3つのチャートの幅を、ダッシュボードの約3分の1にします。ノートを他のチャートの左側にドラッグして、他の23個のチャートに合わせてサイズを変更します。\n最後に、時間を -1h に設定すると、以下のようなダッシュボードになります。\n次は、ディテクターの登場です！\n","categories":"","description":"","excerpt":"1. メモの追加 ダッシュボードには、ダッシュボードの利用者を支援するための短い「説明」ペインを配置することがよくあります。\nここでは、 …","ref":"/observability-workshop/v4.41/ja/imt/docs/dashboards/dashboarding/","tags":"","title":"ノートの追加とダッシュボードのレイアウト"},{"body":"The development team wants to use a containerized redis cache to improve performance of the service.\nStop any other running containers from this app or the OpenTelemetry Collector.\nAdd a docker-compose.yaml file for the python app to prepare us for running multiple containers.\nA skeleton to run the service on port 8000 might look like this. What port do you need to map 8000 to for the service to work?\nversion: '3'services: yourservicename: build: . expose: - \"8000\" ports: - \"8000:XXXX\"Build the service:\nShell Command   docker-compose build  Then run the whole stack:\nShell Command   docker-compose up  Test the service with curl by hitting the exposed port.\nThe milestone for this task is 06docker-compose.\n","categories":"","description":"","excerpt":"The development team wants to use a containerized redis cache to …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/docker-compose/","tags":"","title":"Container Orchestration"},{"body":"Add the OpenTelemetry Collector service definition to the docker-compose setup.\nRebuild the docker-compose stack and run it.\nThe milestone for this task is 07docker-compose-otel.\n","categories":"","description":"","excerpt":"Add the OpenTelemetry Collector service definition to the …","ref":"/observability-workshop/v4.41/bootcamp/docs/gdi/otel-docker-compose/","tags":"","title":"Deploy OpenTelemetry in Docker Compose"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/apm_ecs_demos/","tags":"","title":"ECS Demos"},{"body":" How to keep track of the usage of Observability Cloud in your organization Learn how to keep track of spend by exploring the Subscription Usage interface Creating Teams Adding notification rules to Teams Controlling usage   1. Understanding engagement To fully understand Observability Cloud engagement inside your organization, click on the » bottom left and select the Settings → Organization Overview, this will provide you with the following dashboards that shows you how your Observability Cloud organization is being used:\nYou will see various dashboards such as Throttling, System Limits, Entitlements \u0026 Engagement. The workshop organization you’re using now may have less data to work with as this is cleared down after each workshop.\nTake a minute to explore the various dashboards and charts in the Organization Overview of this workshop instance.\n2. Subscription Usage If you want to see what your usage is against your subscription you can select Subscription Usage.\nThis screen may take a few seconds to load whilst it calculates and pulls in the usage.\n3. Understanding usage You will see a screen similar to the one below that will give you an overview of the current usage, the average usage and your entitlement per category: Hosts, Containers, Custom Metrics and High Resolution Metrics.\nFor more information about these categories please refer to Monitor Splunk Infrastructure Monitoring subscription usage.\n 4. Examine usage in detail The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below).\nAlso, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart).\nIn this example you can see that there are 25 Hosts, 0 Containers, 100 Custom Metrics and 0 High Resolution Metrics.\nIn the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart).\nThe blue line marked Average Usage indicates what Observability Cloud will use to calculate your average usage for the current Subscription Usage Period.\nInfo\nAs you can see from the screenshot, Observability Cloud does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges.   To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the Subscription Usage Period with the drop down on the right.\nPlease take a minute to explore the different time periods \u0026 categories and their views.\nFinally, the pane on the right shows you information about your Subscription.\n","categories":"","description":"","excerpt":" How to keep track of the usage of Observability Cloud in your …","ref":"/observability-workshop/v4.41/imt/docs/servicebureau/billing-and-usage/","tags":"","title":"Subscription Usage"},{"body":" 組織におけるObservability Cloudの利用状況を把握する Subscription Usage（サブスクリプション使用量）インターフェースを使って、使用量を追跡する チームを作成する チームへの通知ルールを管理する 使用量をコントロールする   1. 利用状況を把握する 組織内のObservability Cloudのエンゲージメントを完全に把握するには、左下 » を開き、Settings → Organization Overview を選択すると、Observability Cloud の組織がどのように使用されているかを示す以下のダッシュボードが表示されます。\n左側のメニューには、メンバーのリストが表示され、右側には、ユーザー数、チーム数、チャート数、ダッシュボード数、ダッシュボードグループの作成数、様々な成長傾向を示すチャートが表示されます。\n現在お使いのワークショップ組織では、ワークショップごとにデータが消去されるため、作業できるデータが少ないかもしれません。\nこのワークショップインスタンスの Organization Overview にある様々なチャートをじっくりとご覧ください。\n2. Subscription Usage 契約に対する使用量を確認したい場合は、 Subscription Usage を選択します。\nこの画面では、使用量を計算して取り込むため、読み込みに数秒かかることがあります。\n3. 使用量を理解する 下図のような画面が表示され、現在の使用量、平均使用量、およびホスト、コンテナ、カスタムメトリクス、高解像度メトリクスの各カテゴリごとの権利の概要が表示されます。\nこれらのカテゴリの詳細については、Monitor Splunk Infrastructure Monitoring subscription usage を参照してください。\n 4. 使用状況を詳しく調べる 一番上のチャートには、カテゴリーごとの現在のサブスクリプションレベルが表示されます（下のスクリーンショットでは、上部の赤い矢印で表示されています）。\nまた、4つのカテゴリーの現在の使用状況も表示されます（チャート下部の赤い線で示されています）。\nこの例では、「ホスト」が25個、「コンテナ」が0個、「カスタムメトリクス」が100個、「高解像度メトリクス」が0個であることがわかります。\n下のグラフでは、現在の期間のカテゴリごとの使用量が表示されています（グラフの右上のドロップダウンボックスに表示されています）。\nAverage Usage と書かれた青い線は、Observability Cloudが現在のサブスクリプション期間の平均使用量を計算するために使用するものを示しています。\nInfo\nスクリーンショットからわかるように、Observability Cloudはコスト計算には最大値や95パーセンタイル値ではなく、実際の平均時間使用量を使用しています。これにより、超過料金のリスクなしに、パフォーマンステストやBlue/Greenスタイルのデプロイメントなどを行うことができます。   オプションを確認するには、左の Usage Metric ドロップダウンから異なるオプションを選択して表示するメトリックを変更するか、右のドロップダウンで Billing Period を変更します。\nまた、右側のドロップダウンでサブスクリプション期間を変更することもできます。\n最後に、右側のペインには、お客様のサブスクリプションに関する情報が表示されます。\n","categories":"","description":"","excerpt":" 組織におけるObservability Cloudの利用状況を把握する Subscription Usage（サブスクリプション使用量）イ …","ref":"/observability-workshop/v4.41/ja/imt/docs/servicebureau/billing-and-usage/","tags":"","title":"サブスクリプション使用量"},{"body":" チームの管理 チームの作成とメンバーの追加   1. チームの管理 Observability Cloudを使用する際に、ユーザーに関連するダッシュボードやアラートが表示されるようにするために、ほとんどの組織ではObservability Cloudのチーム機能を使用して、メンバーを1つまたは複数のチームに割り当てます。\nこれは、仕事に関連した役割と一致するのが理想的で、たとえば、DevOpsグループやプロダクトマネジメントグループのメンバーは、Observability Cloudの対応するチームに割り当てられます。\nユーザーがObservability Cloudにログインすると、どのチームダッシュボードをホームページにするかを選択することができ、通常は自分の主な役割に応じたページを選択します。\n以下の例では、ユーザーは開発、運用、プロダクトマネジメントの各チームのメンバーであり、現在は運用チームのダッシュボードを表示しています。\nこのダッシュボードには、NGINX、Infra、K8s用の特定のダッシュボード・グループが割り当てられていますが、どのダッシュボード・グループもチーム・ダッシュボードにリンクすることができます。\n左上のメニューを使って割り当てられたチーム間を素早く移動したり、右側の ALL TEAMS ドロップダウンを使って特定のチームのダッシュボードを選択したり、隣のリンクを使って ALL Dashboards に素早くアクセスしたりすることができます。\nアラートを特定のチームにリンクすることで、チームは関心のあるアラートだけをモニターすることができます。上記の例では、現在1つのアクティブなクリティカルアラートがあります。\nチームダッシュボードの説明文はカスタマイズ可能で、チーム固有のリソースへのリンクを含むことができます（Markdownを使用します）。\n 2. 新しいチームの作成 Splunk のチーム UI を使用するには、左下の » を開き、 Settings → Teams を選択します。\nTeam を選択すると、現在のチームのリストが表示されます。\n新しいチームを追加するには、 Create New Team    ボタンをクリックします。これにより、Create New Team ダイアログが表示されます。\n独自のチームを作ってみましょう。チーム名を [あなたのイニシャル]-Team のように入力し、あなた自身のユーザー選んで、Add リンクからチームに追加してみましょう。上手くいくと、次のような表示になるはずです。\n選択したユーザーを削除するには、Remove または x を押します。\n自分のイニシャルでグループを作成し、自分がメンバーとして追加されていることを確認して、 Done    をクリックします。\nこれでチームリストに戻り、自分のチームと他の人が作成したチームが表示されます。\nNote\n自分がメンバーになっているチームには、グレーの Member アイコンが前に表示されています。   自分のチームにメンバーが割り当てられていない場合は、メンバー数の代わりに青い Add Members のリンクが表示されます。このリンクをクリックすると、Edit Team ダイアログが表示され、自分を追加することができます。\n自分のチームの行末にある3つのドット … を押しても、Edit Team と同じダイアログが表示されます。\n… メニューでは、チームの編集、参加、離脱、削除を行うことができます（離脱と参加は、あなたが現在メンバーであるかどうかによって異なります）。\n 3. 通知ルールの追加 チームごとに特定の通知ルールを設定することができます。Notification Policy タブをクリックすると、通知編集メニューが表示されます。\nデフォルトでは、システムはチームの一般的な通知ルールを設定する機能を提供します。\nNote\nEmail all team members オプションは、アラートの種類に関わらず、このチームのすべてのメンバーにアラート情報のメールが送信されることを意味します。   3.1 受信者の追加  Add Recipient    をクリックすると、他の受信者を追加することができます。これらの受信者は Observability Cloud のユーザーである必要はありません。\nConfigure separate notification tiers for different severity alerts をクリックすると、各アラートレベルを個別に設定できます。\n上の画像のように、異なるアラートレベルに対して異なるアラートルールを設定することができます。\nCritical と Major は Splunk On-Call インシデント管理ソリューションを使用しています。Minor のアラートはチームの Slack チャンネルに送信し、Warning と Info はメールで送信する、という管理もできるようになります。\n3.2 通知機能の統合 Observability Cloud では、アラート通知をメールで送信するだけでなく、以下のようなサービスにアラート通知を送信するように設定することができます。\nチームの事情に合わせて、通知ルールを作成してください。\n","categories":"","description":"","excerpt":" チームの管理 チームの作成とメンバーの追加   1. チームの管理 Observability Cloudを使用する際に、ユーザーに関連す …","ref":"/observability-workshop/v4.41/ja/imt/docs/servicebureau/teams/","tags":"","title":"チーム"},{"body":" 個別のアクセストークンを作成し、制限を設けることで利用を制限する方法を紹介します  1. アクセストークン ホスト、コンテナ、カスタムメトリクス、高解像度メトリクスの使用量をコントロールしたい場合は、複数のアクセストークンを作成し、組織内の異なる部分に割り当てることができます。\n左下の » を開いて、General Settings 配下の Settings → Access Tokens を選択します。\nAccess Tokens インターフェースでは、生成されたアクセストークンのリストで概要が表示されます。すべての組織では、最初のセットアップ時に Default のトークンが生成され、その他のトークンを追加・削除できるようになっています。\n各トークンは一意であり、消費できるホスト、コンテナ、カスタムメトリクス、高解像度メトリクスの量に制限を設けることができます。\nUsage Status 欄は、トークンが割り当てられた制限値を上回っているか下回っているかを素早く表示します。\n2. 新しいトークンの作成  New Token    ボタンをクリックして、新しいトークンを作成しましょう。Name Your Access Token ダイアログが表示されます。\nここでは、Ingest Token と API Token の両方のチェックボックスにチェックを入れてください。\n OK    を押すと、Access Token のUIに戻ります。ここでは、既存のトークンの中に、あなたの新しいトークンが表示されているはずです。\n名前を間違えたり、トークンを無効/有効にしたり、トークンの制限を設定したい場合は、トークンの制限の後ろにある省略記号(…)のメニューボタンをクリックして、トークンの管理メニューを開きます。\nタイプミスがあった場合は、Rename Token オプションを使用して、トークンの名前を修正することができます。\n3. トークンの無効化 トークンがメトリクスの送信に使用できないようにする必要がある場合は、トークンを無効にすることができます。\nDisable ボタンを押すことで、トークンを無効化できます。これにより、トークンがSplunk Observability Cloudへのデータ送信に使用できなくなります。\n以下のスクリーンショットのように、トークンの行がグレーになり、無効化されたことを示しています。\n省略記号(…)のメニューボタンをクリックして、トークンの無効化と有効化を行ってください。\n4. トークンの使用制限の管理 … メニューの Manage Token Limit をクリックして、使用量を制限してみましょう。\nトークン制限管理ダイアログが表示されます。\nこのダイアログでは、カテゴリごとに制限を設定することができます。\n先に進み、各使用指標に対して以下のように制限を指定してください。\n   リミット 値     ホストの制限 5   コンテナ制限 15   カスタムメトリクスの制限 20   高解像度メトリックの制限 0    また、上の表に示すように、ダイアログボックスに正しい数字が表示されていることを再確認してください。\nトークンリミットは、5分間の使用量がリミットの90％を超えたときに、1人または複数の受信者に通知するアラートのトリガーとして使用されます。\n受信者を指定するには、 Add Recipient    をクリックして、使用する受信者または通知方法を選択します（受信者の指定は任意ですが、強くお勧めします）。\nトークンアラートの重要度は常に「Critical」です。\n Update    をクリックすると、アクセストークンの制限とアラートの設定が保存されます。\nNote: トークンの上限を超えると、何が起こるのか\nトークンが使用カテゴリの上限に達したとき、または上限を超えたとき、その使用カテゴリの新しいメトリクスはObservability Cloudに保存されず、処理されません。これにより、チームが無制限にデータを送信することによる予期せぬコストが発生しないようになります。   Note: 高度なアラート通知\n90%に達する前にアラートを取得したい場合は、必要な値を使用して追加のディテクターを作成できます。これらのディテクターは、特定のアクセストークンを消費しているチームをターゲットにすることができ、管理者が関与する必要がある前に行動を起こすことができます。   これらの新しいアクセストークンを様々なチームに配布し、Observability Cloudに送信できる情報やデータの量をコントロールできるようになります。\nこれにより、Observability Cloudの使用量を調整することができ、過剰な使用を防ぐことができます。\nおめでとうございます！ これで、管理機能のモジュールは終わりです！\n","categories":"","description":"","excerpt":" 個別のアクセストークンを作成し、制限を設けることで利用を制限する方法を紹介します  1. アクセストークン ホスト、コンテナ、カスタムメト …","ref":"/observability-workshop/v4.41/ja/imt/docs/servicebureau/tokens/","tags":"","title":"使用量を管理する"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/appendix/","tags":"","title":"Appendix"},{"body":"OTEL COLLECTOR and SMART AGENT COMMANDS   The snippets assume a Splunk Observability Cloud Access Token is set as an environment variable named ACCESS_TOKEN.\n  To run checks in a Kubernetes cluster, we recommend you use a “swiss-army knife” container like netshoot:\nkubectl run tshoot -i --rm --restart=Never --image nicolaka/netshoot -- ACTUAL COMMAND HERE e.g. for a Trace connectivity check:\nkubectl run tshoot -i --rm --restart=Never --image nicolaka/netshoot -- curl -v -d'[]' -H'Content-Type:application/json' https://ingest.us1.signalfx.com/v2/trace If you already have Splunk OpenTelemetry collector installed, you can use its container and the bundled curl:\nkubectl exec -it $(kubectl get po -A -l 'app=splunk-otel-collector,!component' -o name) --container otel-collector -- /usr/lib/splunk-otel-collector/agent-bundle/bin/curl -v -d'[]' -H'Content-Type:application/json' https://ingest.us1.signalfx.com/v2/trace   CONNECTIVITY CHECK curl https://ingest.us1.signalfx.com/healthz INGEST CHECK Metrics curl -qs -H\"X-SF-Token:$ACCESS_TOKEN\" https://ingest.us1.signalfx.com/v2/datapoint -X POST -v -d '{}' -H \"Content-Type: application/json\" Traces curl -H \"Content-Type: application/json\" -H \"X-SF-Token: $ACCESS_TOKEN\" -d '[]' -i https://ingest.eu0.signalfx.com/v2/trace SMART AGENT CHECK AGENT STATUS sudo signalfx-agent status service signalfx-agent status systemctl signalfx-agent status SMART AGENT CHECK AGENT LOGS journalctl -u signalfx-agent | tail -f tail -f /var/log/signalfx-agent.log SPLK-OTEL-COLL CHECK AGENT LOGS journalctl -u splunk-otel-collector -f tail -100 /var/log/messages SMART AGENT START/STOP/RESTART sudo systemctl restart signalfx-agent sudo systemctl start signalfx-agent sudo systemctl stop signalfx-agent SPLK-OTEL-COLL START/STOP/RESTART sudo systemctl restart splunk-otel-collector sudo systemctl start splunk-otel-collector sudo systemctl stop splunk-otel-collector SPLK-OTEL-COLL FLUENTD START/STOP/RESTART sudo systemctl restart td-agent sudo systemctl start td-agent sudo systemctl stop td-agent SMART AGENT DEFAULT CONFIG /etc/signalfx/agent.yaml SPLK-OTEL-COLL DEFAULT CONFIG /etc/otel/collector/agent_config.yaml SPLK-OTEL-COLL ENVIRONMENT FILE WITH REQUIRED VARIABLES/VALUES FOR SERVICE /etc/otel/collector/splunk-otel-collector.conf SPLK-OTEL-COLL FLUENTD CONFIG /etc/otel/collector/fluentd/fluent.conf SPLK-OTEL-COLL FLUENTD CONFIG DIRECTORY FOR ADDING FILES WITH .CONF EXT /etc/otel/collector/fluentd/conf.d SMART AGENT TAIL METRIC DATAPOINTS BEING SENT signalfx-agent tap-dps -h signalfx-agent tap-dps -metric 'jenkins_*’ SMART AGENT ENDPOINTS SET signalfx-agent status endpoints SELINUX SETTING chcon -t bin_t /usr/lib/signalfx-agent/bin/signalfx-agent SMART AGENT STANDARD PORTS ARE 9080 and 8095\nKUBERNETES SMART AGENT CHECK AGENT STATUS kubectl get pods kubectl exec \u003csignalfx-agent-PODNAME\u003e -- signalfx-agent status OTEL AGENT CHECK AGENT STATUS kubectl exec -it YOURAGENTPODHERE -- curl localhost:55679/debug/tracez | lynx -stdin kubectl exec -it splunk-otel-collector-agent-f4gwg -- curl localhost:55679/debug/tracez | lynx -stdin OTEL INITIAL CONFIG kubectl exec -it my-splunk-otel-collector-agent-hg4gk -- curl http://localhost:55554/debug/configz/initial OTEL effective CONFIG kubectl exec -it my-splunk-otel-collector-agent-hg4gk -- curl http://localhost:55554/debug/effective SMART AGENT CHECK AGENT LOGS kubectl logs -l app=signalfx-agent -f SPLK-OTEL-COLL CHECK AGENT LOGS sudo kubectl logs -l app=splunk-otel-collector -f sudo kubectl logs -l app=splunk-otel-collector -f -c otel-collector MODIFY EITHER AGENT CONFIGMAP kubectl get configmap kubectl edit cm splunk-otel-collector-otel-agent sudo kubectl create configmap \u003cnginxconfig\u003e --from-file=workshop/k3s/nginx/nginx.conf SMART AGENT CONFIGMAP REFERENCE https://github.com/splunk/signalfx-agent/blob/main/deployments/k8s/configmap.yaml\nMODIFY EITHER AGENT DAEMONSET kubectl get ds kubectl edit ds splunk-otel-collector-agent SMART AGENT DAEMONSET REFERENCE https://github.com/splunk/signalfx-agent/blob/main/deployments/k8s/daemonset.yaml\nSMART AGENT HELM helm repo add signalfx https://dl.signalfx.com/helm-repo \u0026\u0026 helm repo update helm delete signalfx-agent helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=\u003cMY-CLUSTER\u003e \\ --set kubeletAPI.url=https://localhost:10250 \\ --set signalFxRealm=$REALM \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ --set gatherDockerMetrics=false \\ signalfx-agent signalfx/signalfx-agent \\ -f ~/workshop/k3s/values.yaml SPLK-OTEL-COLL HELM helm repo add splunk-otel-collector-chart https://splunk.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update helm delete splunk-otel-collector helm uninstall splunk-otel-collector helm install splunk-otel-collector \\ --set=\"splunkRealm=$REALM\" \\ --set=\"splunkAccessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=\u003cMY-CLUSTER\u003e\" \\ --set=\"logsEnabled=false\" \\ --set=\"environment=$\u003cMY-ENV\u003e\" \\ splunk-otel-collector-chart/splunk-otel-collector \\ -f ~/workshop/k3s/otel-collector.yaml kubectl get pods kubectl get pods -n kube-system kubectl get svc kubectl describe pod signalfx-agent-86zg4 kubectl delete pod,service baz foo CREATE/DELETE DEPLOYMENT FROM FILE sudo kubectl create -f nginx-deployment.yaml sudo kubectl delete -f nginx-deployment.yaml CHECK SYSTEM CONFIGS kubectl describe -n kube-system pod \u003cmetrics-server-6d684c7b5-gm778\u003e SHOW KUBECONFIG SETTINGS kubectl config view SAVE NAMESPACE FOR ALL SUBSEQUENT KUBECTL COMMANDS IN CONTEXT kubectl config set-context --current --namespace=ggckad-s2 USE MULTIPLE KUBECONFIG FILES KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 get the password for the e2e user kubectl config view -o jsonpath='{.users[?(@.name == \"e2e\")].user.password}' kubectl config view -o jsonpath='{.users[].name}' # display the first user kubectl config view -o jsonpath='{.users[*].name}' # get a list of users kubectl config get-contexts # display list of contexts kubectl config current-context # display the current-context kubectl config use-context my-cluster-name # set the default context to my-cluster-name add a new user to your kubeconf that supports basic auth kubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword set a context utilizing a specific username and namespace kubectl config set-context gce --user=cluster-admin --namespace=foo \\  \u0026\u0026 kubectl config use-context gce Return snapshot logs from pod nginx with only one container kubectl logs nginx Return snapshot logs from pod nginx with multi containers kubectl logs nginx --all-containers=true Return snapshot logs from all containers in pods defined by label app=nginx kubectl logs -l app=nginx --all-containers=true Return snapshot of previous terminated ruby container logs from pod web-1 kubectl logs -p -c ruby web-1 Begin streaming the logs of the ruby container in pod web-1 kubectl logs -f -c ruby web-1 Begin streaming the logs from all containers in pods defined by label app=nginx kubectl logs -f -lapp=nginx --all-containers=true Display only the most recent 20 lines of output in pod nginx kubectl logs --tail=20 nginx Show all logs from pod nginx written in the last hour kubectl logs --since=1h nginx Show logs from a kubelet with an expired serving certificate kubectl logs --insecure-skip-tls-verify-backend nginx Return snapshot logs from first container of a job named hello kubectl logs job/hello Return snapshot logs from container nginx-1 of a deployment named nginx kubectl logs deployment/nginx -c nginx-1 # LOGS ## log ingest test ```bash curl -v -X POST -H \"Content-Type: application/json\" -H \"Authorization: Splunk ${ACCESS_TOKEN}\" https://ingest.us1.signalfx.com/v1/log -d '{\"event\": \"hello world\", \"fields\": {\"foo\": \"bar\"}}' curl -H \"Authorization: Splunk ${ACCESS_TOKEN}\" -H \"Content-Type: application/json\" https://ingest.eu0.signalfx.com/v1/log -d '{\"sourcetype\": \"iracing\", \"event\": \"Cory into the Pits, lap 12\"}' ","categories":"","description":"","excerpt":"OTEL COLLECTOR and SMART AGENT COMMANDS   The snippets assume a Splunk …","ref":"/observability-workshop/v4.41/bootcamp/cheatsheet/","tags":"","title":""},{"body":"APM with AWS Lambda (Developer Focused) !!! important “Enabling APM”\n**If you recently signed up for the 14 day free trial then this section of the workshop cannot be completed!** An Organization needs to be pre-provisioned as a APM entitlement is required for the purposes of this module. Please contact someone from Splunk's Observability team to get a trial instance with APM enabled if you don’t have one already. To check if you have an Organization with APM enabled, just login to Splunk's observability suite and check that you have the APM tab on the top navbar next to Dashboards.   1. AWS Lambda exercise \u0026 APM overview This workshop section is focused on developer’s of serverless/Lambda application/functions. This workshop is going to guide them through the steps to add Tracing to Python and Node-Js Lambda Functions, and see traces flow from an on-prem Java application though the various Python and Node-Js Lambda Functions in Splunk APM.\nSplunk APM captures end-to-end distributed transactions from your applications, including serverless apps (Lambda’s) with trace spans sent directly to Splunk or via an optional OpenTelemetry Collector that act as a central aggregation point prior to sending trace spans to Splunk. (recommended, and show in the workshop).\nIn addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment.\nThe following illustration shows the recommended deployment model: Splunk’s auto-instrumentation libraries send spans to the OpenTelemetry Collector; the OpenTelemetry Collector forwards the spans to Observability Cloud.\n![Lambda-Architecture](/images/lambda/Lambda Architecture.png)\n 2. AWS Lambda exercise requirements flow During this workshop you will perform the following activities:\n Perform a test run of the Splunk Mobile Phone Web shop and its services Enable Tracing on local SpringBoot App Enable Tracing on First Python \u0026 Node-js Lambda Functions Enable Tracing on the other functions Enrich the spans Look at configuring options for the OpenTelemetry Collector   3. AWS Lambda exercise requirements This workshop section assumes that you have access to the following features as they are required for the workshop:\n AWS account: Access to EC2 Instances Ability to create/run AWS Lambda’s  ","categories":"","description":"","excerpt":"APM with AWS Lambda (Developer Focused) !!! important “Enabling APM” …","ref":"/observability-workshop/v4.41/lambda/","tags":"","title":""},{"body":"Make sure to scroll down to see infra metrics for the app\n","categories":"","description":"","excerpt":"Make sure to scroll down to see infra metrics for the app\n","ref":"/observability-workshop/v4.41/otelw/dashboards/servicedashboard/","tags":"","title":""},{"body":"Log in to your Splunk Observability account to identify token/realm For individuals and groups- allow 30-45 minutes of prep time to identify account credentials and prepare a lab environment. When running as a group we recommend doing a separate prep meeting before running the workshop together.\nCheck your Splunk Observability Account (your welcome email has this link) and identify your TOKEN and REALM - these are available in the profile menu in your Splunk Observability account. Note that the realm component i.e. us1 may be different for your account based on how you signed up.\nHow to find realm:\nSplunk Observability Menu -\u003e Your Name -\u003e Account Settings\nHow to find token:\nCreate Lab Environment Splunk Observability is for server environments. This workshop uses Ubuntu Linux as the lab server environment. You can use any Ubuntu platform - bare metal, VM, or cloud VM.\nRecommended Environment For optimal learning we recommend that you use a fresh cloud VM running Ubuntu with minimum 12GB RAM and 20GB disk space.\nIf you chose your own Ubuntu machine, you can set it up with the Workshop software with this command:\nbash \u003c(curl -s https://raw.githubusercontent.com/signalfx/otelworkshop/master/setup-tools/ubuntu.sh) Local Environment If you cannot procure a cloud VM, you can create an Ubuntu Linux environment on a Mac or PC and install the necessary software components:\nMac OS Install Homebrew:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Make sure Homebrew is fully upgraded:\nbrew upgrade Results should be at least 1.5:\nbrew --version We will use Multipass as a hypervisor for Mac:\nbrew cask install multipass If needed, further instructions are here. Do one final brew upgrade before spinning up VM:\nbrew upgrade Windows Follow Multipass Windows installation instructions\nLaunch Multipass Ubuntu VM Create your VM called “primary”:\nmultipass launch -n primary -d 20G -m 12G This will download Ubuntu and may take a few minutes the first time.\nBasic multipass commands:\n Shell into VM: multipass shell primary Exit VM: exit  To manage multipass VM:\n multipass stop primary stops the VM multipass delete primary deletes the VM from the hypervisor multipass purge purges created images but leaves the ubuntu template intace  Install OTel Workshop A bootstrap script will install everything needed and clone this repo.\nThis will take up to 10 minutes to execute- leave it running until complete.\nmultipass shell primary Once in your Multipass Ubuntu VM:\nbash \u003c(curl -s https://raw.githubusercontent.com/signalfx/otelworkshop/master/setup-tools/ubuntu.sh) Key OTel APM concepts Moving parts that make APM happen in OpenTelemetry:\n Application Spans: OpenTelemetry instrumentation causes spans to be emitted by your applications OpenTelmetry auto-instrumentation (no code changes) for most languages is availabile but you can use any framework/library that emits spans in formats accepted by the Otel Collector i.e zipkin, OpenTracing, or OpenTelemetry. The spans are received by the OpenTelemetry Collector which both doubles as an infrastructure metrics collection agent and a telemetry processor. The Collector then forwards all telemetry (metrics/traces/logs) to Splunk Observability Cloud. Instructructure metrics: Infrastructure metrics are collected by your OpenTelemetry Collector which is observing the application’s host or container cluster. The infrastructure agent is lightweight, open source, real-time, and designed for microservices, containers, and cloud as well as on premise servers or cloud virtual machines. Application spans will be sent to the OpenTelemetry Collector running on a host or k8s pod to correlate APM with host/cluster metrics. The Collector then relays the spans to Splunk Observability Cloud APM where they will be assembled into traces. The APM spans flow in real time and there is no sampling. Pre-made default Service Dashboards with application metrics for each app will appear once spans are received by Splunk APM. The APM view has directed troubleshooting. Environment variables control the setup of APM. These names vary based on instrumentation but they always include:\n- Endpoint: destination to send spans\n- Service name: the name of the application as you want it to appear in a service map\n- Environment: a value for segmenting betwen dev/prod etc. Can be set with instrumentation and not necessarily as part of an ENV variable.  ","categories":"","description":"","excerpt":"Log in to your Splunk Observability account to identify token/realm …","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/prep/","tags":"","title":""},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/bootcamp/docs/","tags":"","title":"Bootcamp Labs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/ja/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"Splunk SyntheticsでのReal Browser Check と API Check の作成方法\n","excerpt":"Splunk SyntheticsでのReal Browser Check と API Check の作成方法\n","ref":"/observability-workshop/v4.41/ja/synthetics/docs/","tags":"","title":"Checkの作成"},{"body":"","categories":"","description":"How to create both Real Browser and API checks in Splunk Synthetics \n","excerpt":"How to create both Real Browser and API checks in Splunk Synthetics \n","ref":"/observability-workshop/v4.41/synthetics/docs/","tags":"","title":"Creating checks"},{"body":"Splunk APM Trace Generator Demo For AWS ECS EC2 This repo demonstrates a reference implemenation for a single AWS ECS EC2 task example of Splunk APM that will send spans directly to Splunk Observability Cloud.\nECS works very simply: just add the environment variables required by the Otel APM Instrumentation and the Instrumentation will do the rest.\nTo deploy this example, you must have an ECS environment ready to go with VPC, task roles for logs, etc. Instructions are below:\n  Install ECS CLI: ECS CLI Setup\n  Pay critical attention to setting up VPC in advance: Task Definition Guide\n  Set up log environment here: Cloudwatch\n   Setup Configure ECS CLI Profile:\necs-cli \\ configure profile \\ --access-key YOURAWSKEYHERE \\ --secret-key YOURAWSSECRETKEYHERE \\ --profile-name ecs-ec2-profile Configure ECS EC2 Cluster:\nconfigure ECS Cluster Config: ecs-cli configure \\ --cluster test-cluster \\ --config-name test-cluster \\ --region YOURREGIONHEREi.e.:us-east-1 Deploy ECS EC2 Cluster:\necs-cli up \\ --cluster test-cluster \\ --region YOURREGIONHEREi.e.:us-east-1\\ --size 1 \\ --capability-iam \\ --instance-type t2.xlarge \\ --launch-type EC2 \\ --ecs-profile test-profile \\ --force  Deploy Task Deploy with the following commands- you must change the variables in caps in these task .json files to suit your environment:\naws ecs register-task-definition \\ --cli-input-json file://tracegen-java-otel-ecs-ec2.json Note that the task definition will increment each time you try it- from 1 to 2 etc. To check which version is current use:\naws ecs list-task-definitions Deploy trace generator task to cluster:\naws ecs create-service \\ --cluster test-cluster \\ --launch-type EC2 \\ --scheduling-strategy DAEMON \\ --service-name tracegen-java-otel-ecs-ec2 \\ --task-definition tracegen-java-otel-ecs-ec2:VERSIONHEREi.e.1 After a few seconds check Splunk APM to see the trace generator service.\n Cleanup aws ecs delete-service --cluster test-cluster --service tracegen-java-otel-ecs-ec2 --force ecs-cli down \\ --cluster test-cluster \\ --region us-east-1 aws ecs delete-cluster --cluster test-cluster  Extras The ecs-cli-commands.md file offers helpful commands for ECS Fargate management for the AWS CLI.\n","categories":"","description":"","excerpt":"Splunk APM Trace Generator Demo For AWS ECS EC2 This repo demonstrates …","ref":"/observability-workshop/v4.41/otelw/apm_ecs_demos/index-ec2/","tags":"","title":"ECS-EC2"},{"body":"Splunk APM Trace Generator Demo For AWS ECS Fargate This repo demonstrates reference implemenations for a single AWS ECS Fargate task example of Splunk APM that will send spans to a sidecar OpenTelemetry container.\nECS works very simply: just add the environment variables required by the Otel APM Instrumentation and the Instrumentation will do the rest.\nTo deploy this example, you must have an ECS environment ready to go with VPC, task roles for logs, etc. Instructions are below:\n  Install ECS CLI: ECS CLI Setup\n  Pay critical attention to setting up VPC in advance: Task Definition Guide\n  Set up log environment here: Cloudwatch\n   Setup Configure ECS CLI Profile:\necs-cli \\ configure profile \\ --access-key YOURAWSKEYHERE \\ --secret-key YOURAWSSECRETKEYHERE \\ --profile-name ecs-ec2-profile Configure ECS Cluster:\nconfigure ECS Cluster Config: ecs-cli configure \\ --cluster test-cluster \\ --config-name test-cluster \\ --region YOURREGIONHEREi.e.:us-east-1 Create ECS Cluster:\naws ecs create-cluster --cluster-name test-cluster  Deploy Task The task spins up two ECS Fargate containers:\n splunk-otel-collector - sidecar to observe ECS host metrics and relay application traces to Splunk APM tracegen-fargate - generates traces using a manually instrumented Java app and sends them to the Otel Collector  Deploy with the following commands- you must change the variables in caps in tracegen-java-otel-fargate-otelcolfargate.json to suit your environment:\nCreate cluster\naws ecs create-cluster --cluster-name test-cluster Note that the task definition will increment each time you try it- from 1 to 2 etc. To check which version is current use:\naws ecs list-task-definitions Identify your Security Group and Subnet and change them in the deploy script below and then deploy trace generator / otelcollector task to cluster:\naws ecs create-service \\ --cluster test-cluster \\ --service-name tracegen-fargate \\ --desired-count 1 \\ --launch-type \"FARGATE\" \\ --network-configuration \"awsvpcConfiguration={subnets=[subnet-YOURSUBNETHERE],securityGroups=[sg-YOURSECURITYGROUPHERE],assignPublicIp=ENABLED}\" \\ --task-definition tracegen-java-otel-fargate-otelcol:1 After a few seconds check Splunk APM and Dashboards-\u003eECS-Fargate to see the trace generator service and Otel collector\n Cleanup aws ecs delete-service --cluster test-cluster --service tracegen-java-otel-fargate-otelcol --force  Extras The ecs-cli-commands.md file offers helpful commands for ECS Fargate management for the AWS CLI.\n","categories":"","description":"","excerpt":"Splunk APM Trace Generator Demo For AWS ECS Fargate This repo …","ref":"/observability-workshop/v4.41/otelw/apm_ecs_demos/index-fargate/","tags":"","title":"ECS-Fargate"},{"body":"","categories":"","description":"How to get traces into Observability Cloud and how to use Splunk APM\n","excerpt":"How to get traces into Observability Cloud and how to use Splunk APM\n","ref":"/observability-workshop/v4.41/apm/docs/","tags":"","title":"Get Traces In, Get Data Out"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/labs/apm_for_k8s/examples/","tags":"","title":"Instrumentation Examples"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/otelw/labs/optional/","tags":"","title":"Optional/Advanced"},{"body":"Docker based APM examples  Prep: Make sure you’ve stopped your previous workshop examples and stopped all instances of Otel Collector as to not confuse re-used example names.\nDocker must be installed and current for this lab.\nRepo location: https://github.com/splunk/otelworkshop/tree/main/misc/docker\nStart in k8s directory:\ncd ~/otelworkshop/misc/docker Create environment variables with your Splunk token and realm- substitute yours for the variables in caps:\nexport SPLUNK_ACCESS_TOKEN=YOURTOKENHERE export SPLUNK_REALM=YOURREALMHERE Add initals to environment i.e. sjl-apm-workshop:\nexport SPLUNK_WORKSHOP_ENV=YOURINITIALS-apm-workshop Make sure to re-export these environment variables every time you open a terminal.\n Example 1: Python Microservice w/ Local Otel Collector A local docker network with an OpenTelemetry Collector container and a container with a Python microservice example with a redis client and server in same container.\nStep 1: Create a local docker network called otel-net\nsource setup-docker.sh Step 2: Run Otel Collector docker container in the otel-net docker bridged network:\nsource run-otelcol.sh Step 3: Run the Python Redis client w/ Redis server microservice example container:\nOpen a new terminal window. Re-export your env variables from the prep section.\nsource run-python-autgen.sh Wait a about 60 seconds and check APM Explore map to see the microservices.\nStudy the run scripts to understand how OpenTelemetry environment variables are configured, and the source code for the microservice example is here\nctrl-c in each terminal will stop things and containers can be removed via standard Docker commands.\n Example 2: Python Microservice Sending Telmetry Directly to Splunk Observability Cloud Run the direct-to-ingest docker container:\nsource run-python-autogen-direct.sh Wait a about 60 seconds and check APM Explore map to see the microservices.\n Example 3: .NET Microservice Sending Telemetry Directly to Splunk Observability Cloud Run the direct-to-ingest docker container:\nsource run-dotnet-autogen-direct.sh Wait a about 60 seconds and check APM Explore map to see the microservices.\nMisc Docker container instructions for OpenTelemetry Collector are here\nView Otel Collector trace stats (requires Lynx ascii browser):\ndocker exec -it otelcol curl localhost:55679/debug/tracez | lynx -stdin ","categories":"","description":"","excerpt":"Docker based APM examples  Prep: Make sure you’ve stopped your …","ref":"/observability-workshop/v4.41/otelw/labs/optional/docker/","tags":"","title":"OTel Collector and APM for Docker"},{"body":"","categories":"","description":"Environment Configuration and Hands-On Exercises\n","excerpt":"Environment Configuration and Hands-On Exercises\n","ref":"/observability-workshop/v4.41/pet-clinic/","tags":"","title":"Pet Clinic Java Workshop"},{"body":"","categories":"","description":"Hands-On Exercises\n","excerpt":"Hands-On Exercises\n","ref":"/observability-workshop/v4.41/rum/docs/","tags":"","title":"RUM Workshop"},{"body":"","categories":"","description":"ハンズオン演習\n","excerpt":"ハンズオン演習\n","ref":"/observability-workshop/v4.41/ja/rum/docs/","tags":"","title":"RUM Workshop"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/search/","tags":"","title":"Search Results"},{"body":"  #td-cover-block-0 { background-image: url(/observability-workshop/v4.41/background_hucef8ecfb8c929753b37f58ee610ed71c_306261_960x540_fill_q75_catmullrom_top.jpeg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/observability-workshop/v4.41/background_hucef8ecfb8c929753b37f58ee610ed71c_306261_1920x1080_fill_q75_catmullrom_top.jpeg); } }  Welcome to the Splunk Observability Workshops! Get Started    Download   -- Get insights into your applications and infrastructure in real-time with the help of the monitoring, analytics and response tools of the Splunk Observability Cloud         This workshop is going to take you through the best-in-class observability platform for ingesting, monitoring, visualizing and analyzing metrics, traces and spans.       OpenTelemetry OpenTelemetry is used in this workshop to instrument, generate, collect and export telemetry data (metrics, traces and logs) to help you analyze your application and infrastructure.\n Read more …\n   Contributions welcome! You can contribute to this documentation via issues and pull requests. Please don’t hesitate to help to make the workshops better.\n Read more …\n   Follow us on Twitter! You can find information about updates and interesting reads in the Twitter channel of Splunk.\n Read more …\n    ","categories":"","description":"Learn how to build observability solutions with Splunk","excerpt":"Learn how to build observability solutions with Splunk","ref":"/observability-workshop/v4.41/","tags":"","title":"Splunk"},{"body":"  #td-cover-block-0 { background-image: url(/observability-workshop/v4.41/ja/background_hucef8ecfb8c929753b37f58ee610ed71c_306261_960x540_fill_q75_catmullrom_top.jpeg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/observability-workshop/v4.41/ja/background_hucef8ecfb8c929753b37f58ee610ed71c_306261_1920x1080_fill_q75_catmullrom_top.jpeg); } }  Splunk Observability ワークショップへようこそ！ 始める    Download   -- Splunk Observability Cloud の監視、分析、応答ツールを使用して、アプリケーションとインフラストラクチャをリアルタイムで把握することができます。         このワークショップでは、メトリクス、トレース、スパンを取り込み、監視し、可視化し、分析するためのクラス最高のオブザーバビリティプラットフォームをご紹介します。       OpenTelemetry このワークショップでは、OpenTelemetryを使用して、アプリケーションやインフラの分析に役立つテレメトリデータ（メトリクス、トレース、ログ）の計測、生成、収集、エクスポートを行います。\n 続きを読む …\n   Contributions welcome! このドキュメントには、issue や pull request で貢献することができます。より良いワークショップにするために、遠慮なくご協力ください。\n 続きを読む …\n   Follow us on Twitter! SplunkのTwitterチャンネルでは、アップデート情報や様々な読み物が紹介されています。\n 続きを読む …\n    ","categories":"","description":"Splunkのオブザーバビリティソリューションの構築方法を学びましょう","excerpt":"Splunkのオブザーバビリティソリューションの構築方法を学びましょう","ref":"/observability-workshop/v4.41/ja/","tags":"","title":"Splunk"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/observability-workshop/v4.41/ja/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"Observability Cloudへのトレース取り込み方法とSplunk APMの活用方法\n","excerpt":"Observability Cloudへのトレース取り込み方法とSplunk APMの活用方法\n","ref":"/observability-workshop/v4.41/ja/apm/docs/","tags":"","title":"トレースを取り込み、データを取り出す"}]